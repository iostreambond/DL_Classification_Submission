Libraries imported - ready to use PyTorch 1.13.1+cu117
Training on cuda
Data loaders ready
=============================
BasicNet
=============================
Epoch: 0
Training set [0/6430 (0%)] Loss: 2.075968
Training set [5120/6430 (77%)] Loss: 1.926161
Training set: Average loss: 2.935044
Training set: Average accuracy: 16.14%
Validation set: Average loss: 1.935168, Accuracy: 147/1050 (14%)

Epoch: 1
Training set [0/6430 (0%)] Loss: 1.918452
Training set [5120/6430 (77%)] Loss: 1.903982
Training set: Average loss: 1.910801
Training set: Average accuracy: 19.80%
Validation set: Average loss: 1.933782, Accuracy: 155/1050 (15%)

Epoch: 2
Training set [0/6430 (0%)] Loss: 1.902329
Training set [5120/6430 (77%)] Loss: 1.865622
Training set: Average loss: 1.879027
Training set: Average accuracy: 21.00%
Validation set: Average loss: 1.936990, Accuracy: 201/1050 (19%)

Epoch: 3
Training set [0/6430 (0%)] Loss: 1.868203
Training set [5120/6430 (77%)] Loss: 1.831044
Training set: Average loss: 1.848570
Training set: Average accuracy: 21.94%
Validation set: Average loss: 1.867551, Accuracy: 269/1050 (26%)

Epoch: 4
Training set [0/6430 (0%)] Loss: 1.828895
Training set [5120/6430 (77%)] Loss: 1.776690
Training set: Average loss: 1.811389
Training set: Average accuracy: 24.68%
Validation set: Average loss: 1.820478, Accuracy: 292/1050 (28%)

Epoch: 5
Training set [0/6430 (0%)] Loss: 1.750176
Training set [5120/6430 (77%)] Loss: 1.769709
Training set: Average loss: 1.773566
Training set: Average accuracy: 26.58%
Validation set: Average loss: 1.771392, Accuracy: 311/1050 (30%)

Epoch: 6
Training set [0/6430 (0%)] Loss: 1.794033
Training set [5120/6430 (77%)] Loss: 1.743515
Training set: Average loss: 1.731885
Training set: Average accuracy: 27.23%
Validation set: Average loss: 1.731602, Accuracy: 336/1050 (32%)

Epoch: 7
Training set [0/6430 (0%)] Loss: 1.734194
Training set [5120/6430 (77%)] Loss: 1.673518
Training set: Average loss: 1.667726
Training set: Average accuracy: 30.78%
Validation set: Average loss: 1.724121, Accuracy: 405/1050 (39%)

Epoch: 8
Training set [0/6430 (0%)] Loss: 1.625903
Training set [5120/6430 (77%)] Loss: 1.633747
Training set: Average loss: 1.611621
Training set: Average accuracy: 32.77%
Validation set: Average loss: 1.654345, Accuracy: 411/1050 (39%)

Epoch: 9
Training set [0/6430 (0%)] Loss: 1.563024
Training set [5120/6430 (77%)] Loss: 1.587875
Training set: Average loss: 1.564348
Training set: Average accuracy: 33.79%
Validation set: Average loss: 1.575103, Accuracy: 454/1050 (43%)

Epoch: 10
Training set [0/6430 (0%)] Loss: 1.598802
Training set [5120/6430 (77%)] Loss: 1.503354
Training set: Average loss: 1.537067
Training set: Average accuracy: 35.16%
Validation set: Average loss: 1.407942, Accuracy: 484/1050 (46%)

Epoch: 11
Training set [0/6430 (0%)] Loss: 1.523162
Training set [5120/6430 (77%)] Loss: 1.501486
Training set: Average loss: 1.475006
Training set: Average accuracy: 37.51%
Validation set: Average loss: 1.386619, Accuracy: 470/1050 (45%)

Epoch: 12
Training set [0/6430 (0%)] Loss: 1.445895
Training set [5120/6430 (77%)] Loss: 1.414994
Training set: Average loss: 1.450352
Training set: Average accuracy: 38.82%
Validation set: Average loss: 1.581485, Accuracy: 487/1050 (46%)

Epoch: 13
Training set [0/6430 (0%)] Loss: 1.459342
Training set [5120/6430 (77%)] Loss: 1.430696
Training set: Average loss: 1.421331
Training set: Average accuracy: 39.95%
Validation set: Average loss: 1.378655, Accuracy: 531/1050 (51%)

Epoch: 14
Training set [0/6430 (0%)] Loss: 1.388402
Training set [5120/6430 (77%)] Loss: 1.366808
Training set: Average loss: 1.381622
Training set: Average accuracy: 40.68%
Validation set: Average loss: 1.258722, Accuracy: 559/1050 (53%)

Epoch: 15
Training set [0/6430 (0%)] Loss: 1.404141
Training set [5120/6430 (77%)] Loss: 1.368939
Training set: Average loss: 1.372894
Training set: Average accuracy: 42.02%
Validation set: Average loss: 1.236674, Accuracy: 559/1050 (53%)

Epoch: 16
Training set [0/6430 (0%)] Loss: 1.326716
Training set [5120/6430 (77%)] Loss: 1.390616
Training set: Average loss: 1.336788
Training set: Average accuracy: 43.42%
Validation set: Average loss: 1.278573, Accuracy: 580/1050 (55%)

Epoch: 17
Training set [0/6430 (0%)] Loss: 1.306773
Training set [5120/6430 (77%)] Loss: 1.296953
Training set: Average loss: 1.304416
Training set: Average accuracy: 45.33%
Validation set: Average loss: 1.826475, Accuracy: 451/1050 (43%)

Epoch: 18
Training set [0/6430 (0%)] Loss: 1.281799
Training set [5120/6430 (77%)] Loss: 1.289484
Training set: Average loss: 1.281953
Training set: Average accuracy: 45.47%
Validation set: Average loss: 1.221126, Accuracy: 572/1050 (54%)

Epoch: 19
Training set [0/6430 (0%)] Loss: 1.269059
Training set [5120/6430 (77%)] Loss: 1.167771
Training set: Average loss: 1.240605
Training set: Average accuracy: 46.47%
Validation set: Average loss: 1.671723, Accuracy: 489/1050 (47%)

Epoch: 20
Training set [0/6430 (0%)] Loss: 1.260581
Training set [5120/6430 (77%)] Loss: 1.224958
Training set: Average loss: 1.221446
Training set: Average accuracy: 47.60%
Validation set: Average loss: 1.122140, Accuracy: 634/1050 (60%)

Epoch: 21
Training set [0/6430 (0%)] Loss: 1.195261
Training set [5120/6430 (77%)] Loss: 1.223850
Training set: Average loss: 1.209516
Training set: Average accuracy: 47.17%
Validation set: Average loss: 1.148454, Accuracy: 632/1050 (60%)

Epoch: 22
Training set [0/6430 (0%)] Loss: 1.199222
Training set [5120/6430 (77%)] Loss: 1.224638
Training set: Average loss: 1.194313
Training set: Average accuracy: 48.54%
Validation set: Average loss: 1.145739, Accuracy: 615/1050 (59%)

Epoch: 23
Training set [0/6430 (0%)] Loss: 1.174599
Training set [5120/6430 (77%)] Loss: 1.181051
Training set: Average loss: 1.155592
Training set: Average accuracy: 50.14%
Validation set: Average loss: 1.378388, Accuracy: 581/1050 (55%)

Epoch: 24
Training set [0/6430 (0%)] Loss: 1.188606
Training set [5120/6430 (77%)] Loss: 1.169764
Training set: Average loss: 1.143576
Training set: Average accuracy: 50.70%
Validation set: Average loss: 1.087818, Accuracy: 646/1050 (62%)

Epoch: 25
Training set [0/6430 (0%)] Loss: 1.134407
Training set [5120/6430 (77%)] Loss: 1.065240
Training set: Average loss: 1.125368
Training set: Average accuracy: 51.51%
Validation set: Average loss: 0.983589, Accuracy: 646/1050 (62%)

Epoch: 26
Training set [0/6430 (0%)] Loss: 1.087835
Training set [5120/6430 (77%)] Loss: 1.083385
Training set: Average loss: 1.092964
Training set: Average accuracy: 51.49%
Validation set: Average loss: 1.040393, Accuracy: 659/1050 (63%)

Epoch: 27
Training set [0/6430 (0%)] Loss: 1.111643
Training set [5120/6430 (77%)] Loss: 1.121637
Training set: Average loss: 1.098240
Training set: Average accuracy: 51.31%
Validation set: Average loss: 0.985332, Accuracy: 679/1050 (65%)

Epoch: 28
Training set [0/6430 (0%)] Loss: 1.023926
Training set [5120/6430 (77%)] Loss: 1.064601
Training set: Average loss: 1.088808
Training set: Average accuracy: 52.99%
Validation set: Average loss: 0.976449, Accuracy: 645/1050 (61%)

Epoch: 29
Training set [0/6430 (0%)] Loss: 1.086114
Training set [5120/6430 (77%)] Loss: 1.043270
Training set: Average loss: 1.085538
Training set: Average accuracy: 52.61%
Validation set: Average loss: 1.005511, Accuracy: 663/1050 (63%)

Epoch: 30
Training set [0/6430 (0%)] Loss: 1.137392
Training set [5120/6430 (77%)] Loss: 1.071599
Training set: Average loss: 1.068827
Training set: Average accuracy: 53.78%
Validation set: Average loss: 1.278098, Accuracy: 597/1050 (57%)

Epoch: 31
Training set [0/6430 (0%)] Loss: 1.015768
Training set [5120/6430 (77%)] Loss: 1.019795
Training set: Average loss: 1.049642
Training set: Average accuracy: 55.15%
Validation set: Average loss: 0.968506, Accuracy: 676/1050 (64%)

Epoch: 32
Training set [0/6430 (0%)] Loss: 1.086868
Training set [5120/6430 (77%)] Loss: 1.065722
Training set: Average loss: 1.046223
Training set: Average accuracy: 54.37%
Validation set: Average loss: 0.887190, Accuracy: 733/1050 (70%)

Epoch: 33
Training set [0/6430 (0%)] Loss: 0.969950
Training set [5120/6430 (77%)] Loss: 0.941670
Training set: Average loss: 1.005195
Training set: Average accuracy: 56.49%
Validation set: Average loss: 0.863400, Accuracy: 706/1050 (67%)

Epoch: 34
Training set [0/6430 (0%)] Loss: 0.996769
Training set [5120/6430 (77%)] Loss: 1.021155
Training set: Average loss: 0.996819
Training set: Average accuracy: 56.41%
Validation set: Average loss: 1.181780, Accuracy: 662/1050 (63%)

Epoch: 35
Training set [0/6430 (0%)] Loss: 0.982890
Training set [5120/6430 (77%)] Loss: 0.957459
Training set: Average loss: 0.990903
Training set: Average accuracy: 56.91%
Validation set: Average loss: 1.001534, Accuracy: 707/1050 (67%)

Epoch: 36
Training set [0/6430 (0%)] Loss: 0.979979
Training set [5120/6430 (77%)] Loss: 0.952486
Training set: Average loss: 0.984465
Training set: Average accuracy: 57.09%
Validation set: Average loss: 1.028437, Accuracy: 697/1050 (66%)

Epoch: 37
Training set [0/6430 (0%)] Loss: 0.988939
Training set [5120/6430 (77%)] Loss: 0.892711
Training set: Average loss: 0.956594
Training set: Average accuracy: 58.57%
Validation set: Average loss: 0.846892, Accuracy: 746/1050 (71%)

Epoch: 38
Training set [0/6430 (0%)] Loss: 0.952308
Training set [5120/6430 (77%)] Loss: 1.043759
Training set: Average loss: 0.988276
Training set: Average accuracy: 56.72%
Validation set: Average loss: 1.041574, Accuracy: 717/1050 (68%)

Epoch: 39
Training set [0/6430 (0%)] Loss: 0.934505
Training set [5120/6430 (77%)] Loss: 0.997859
Training set: Average loss: 0.957542
Training set: Average accuracy: 58.29%
Validation set: Average loss: 0.858262, Accuracy: 721/1050 (69%)

Epoch: 40
Training set [0/6430 (0%)] Loss: 0.961165
Training set [5120/6430 (77%)] Loss: 0.974415
Training set: Average loss: 0.968098
Training set: Average accuracy: 56.97%
Validation set: Average loss: 0.924197, Accuracy: 685/1050 (65%)

Epoch: 41
Training set [0/6430 (0%)] Loss: 0.961198
Training set [5120/6430 (77%)] Loss: 1.026289
Training set: Average loss: 0.956212
Training set: Average accuracy: 58.74%
Validation set: Average loss: 1.252652, Accuracy: 703/1050 (67%)

Epoch: 42
Training set [0/6430 (0%)] Loss: 0.984532
Training set [5120/6430 (77%)] Loss: 0.926490
Training set: Average loss: 0.937006
Training set: Average accuracy: 58.79%
Validation set: Average loss: 0.878275, Accuracy: 753/1050 (72%)

Epoch: 43
Training set [0/6430 (0%)] Loss: 0.942395
Training set [5120/6430 (77%)] Loss: 0.912042
Training set: Average loss: 0.924918
Training set: Average accuracy: 59.21%
Validation set: Average loss: 0.889810, Accuracy: 714/1050 (68%)

Epoch: 44
Training set [0/6430 (0%)] Loss: 0.953562
Training set [5120/6430 (77%)] Loss: 0.919133
Training set: Average loss: 0.942852
Training set: Average accuracy: 59.16%
Validation set: Average loss: 1.340038, Accuracy: 645/1050 (61%)

Epoch: 45
Training set [0/6430 (0%)] Loss: 0.999875
Training set [5120/6430 (77%)] Loss: 0.907640
Training set: Average loss: 0.944325
Training set: Average accuracy: 58.60%
Validation set: Average loss: 0.982246, Accuracy: 730/1050 (70%)

Epoch: 46
Training set [0/6430 (0%)] Loss: 0.950837
Training set [5120/6430 (77%)] Loss: 0.950367
Training set: Average loss: 0.916746
Training set: Average accuracy: 59.94%
Validation set: Average loss: 0.823093, Accuracy: 751/1050 (72%)

Epoch: 47
Training set [0/6430 (0%)] Loss: 0.916895
Training set [5120/6430 (77%)] Loss: 0.912735
Training set: Average loss: 0.911593
Training set: Average accuracy: 60.53%
Validation set: Average loss: 0.746823, Accuracy: 768/1050 (73%)

Epoch: 48
Training set [0/6430 (0%)] Loss: 0.928435
Training set [5120/6430 (77%)] Loss: 0.822220
Training set: Average loss: 0.883462
Training set: Average accuracy: 61.52%
Validation set: Average loss: 0.797567, Accuracy: 745/1050 (71%)

Epoch: 49
Training set [0/6430 (0%)] Loss: 0.896395
Training set [5120/6430 (77%)] Loss: 0.931337
Training set: Average loss: 0.892659
Training set: Average accuracy: 60.20%
Validation set: Average loss: 0.755811, Accuracy: 769/1050 (73%)

Epoch: 50
Training set [0/6430 (0%)] Loss: 0.851726
Training set [5120/6430 (77%)] Loss: 0.945921
Training set: Average loss: 0.906946
Training set: Average accuracy: 60.34%
Validation set: Average loss: 0.772690, Accuracy: 750/1050 (71%)

Epoch: 51
Training set [0/6430 (0%)] Loss: 0.872424
Training set [5120/6430 (77%)] Loss: 0.909380
Training set: Average loss: 0.866597
Training set: Average accuracy: 63.02%
Validation set: Average loss: 0.760167, Accuracy: 783/1050 (75%)

Epoch: 52
Training set [0/6430 (0%)] Loss: 0.874882
Training set [5120/6430 (77%)] Loss: 0.844685
Training set: Average loss: 0.856537
Training set: Average accuracy: 62.02%
Validation set: Average loss: 0.808680, Accuracy: 768/1050 (73%)

Epoch: 53
Training set [0/6430 (0%)] Loss: 0.805133
Training set [5120/6430 (77%)] Loss: 0.844186
Training set: Average loss: 0.872956
Training set: Average accuracy: 62.01%
Validation set: Average loss: 0.834156, Accuracy: 739/1050 (70%)

Epoch: 54
Training set [0/6430 (0%)] Loss: 0.901776
Training set [5120/6430 (77%)] Loss: 0.877861
Training set: Average loss: 0.873889
Training set: Average accuracy: 62.27%
Validation set: Average loss: 0.738387, Accuracy: 759/1050 (72%)

Epoch: 55
Training set [0/6430 (0%)] Loss: 0.863989
Training set [5120/6430 (77%)] Loss: 0.882415
Training set: Average loss: 0.877864
Training set: Average accuracy: 61.65%
Validation set: Average loss: 0.704930, Accuracy: 793/1050 (76%)

Epoch: 56
Training set [0/6430 (0%)] Loss: 0.825910
Training set [5120/6430 (77%)] Loss: 0.884748
Training set: Average loss: 0.864897
Training set: Average accuracy: 62.95%
Validation set: Average loss: 0.751283, Accuracy: 770/1050 (73%)

Epoch: 57
Training set [0/6430 (0%)] Loss: 0.932200
Training set [5120/6430 (77%)] Loss: 0.786641
Training set: Average loss: 0.851569
Training set: Average accuracy: 63.03%
Validation set: Average loss: 0.791299, Accuracy: 741/1050 (71%)

Epoch: 58
Training set [0/6430 (0%)] Loss: 0.759852
Training set [5120/6430 (77%)] Loss: 0.942185
Training set: Average loss: 0.839355
Training set: Average accuracy: 63.73%
Validation set: Average loss: 0.775305, Accuracy: 781/1050 (74%)

Epoch: 59
Training set [0/6430 (0%)] Loss: 0.888115
Training set [5120/6430 (77%)] Loss: 0.799729
Training set: Average loss: 0.820754
Training set: Average accuracy: 64.37%
Validation set: Average loss: 0.719274, Accuracy: 795/1050 (76%)

Epoch: 60
Training set [0/6430 (0%)] Loss: 0.804276
Training set [5120/6430 (77%)] Loss: 0.812055
Training set: Average loss: 0.825953
Training set: Average accuracy: 63.45%
Validation set: Average loss: 1.003358, Accuracy: 709/1050 (68%)

Epoch: 61
Training set [0/6430 (0%)] Loss: 0.837157
Training set [5120/6430 (77%)] Loss: 0.883990
Training set: Average loss: 0.812553
Training set: Average accuracy: 63.65%
Validation set: Average loss: 0.954842, Accuracy: 780/1050 (74%)

Epoch: 62
Training set [0/6430 (0%)] Loss: 0.830998
Training set [5120/6430 (77%)] Loss: 0.835900
Training set: Average loss: 0.832648
Training set: Average accuracy: 64.04%
Validation set: Average loss: 0.789476, Accuracy: 759/1050 (72%)

Epoch: 63
Training set [0/6430 (0%)] Loss: 0.870648
Training set [5120/6430 (77%)] Loss: 0.794570
Training set: Average loss: 0.820204
Training set: Average accuracy: 63.90%
Validation set: Average loss: 0.828602, Accuracy: 768/1050 (73%)

Epoch: 64
Training set [0/6430 (0%)] Loss: 0.779243
Training set [5120/6430 (77%)] Loss: 0.783756
Training set: Average loss: 0.820210
Training set: Average accuracy: 63.59%
Validation set: Average loss: 0.735960, Accuracy: 781/1050 (74%)

Epoch: 65
Training set [0/6430 (0%)] Loss: 0.763926
Training set [5120/6430 (77%)] Loss: 0.845689
Training set: Average loss: 0.831678
Training set: Average accuracy: 64.00%
Validation set: Average loss: 0.808827, Accuracy: 756/1050 (72%)

Epoch: 66
Training set [0/6430 (0%)] Loss: 0.864391
Training set [5120/6430 (77%)] Loss: 0.787937
Training set: Average loss: 0.824585
Training set: Average accuracy: 64.68%
Validation set: Average loss: 0.842761, Accuracy: 751/1050 (72%)

Epoch: 67
Training set [0/6430 (0%)] Loss: 0.817993
Training set [5120/6430 (77%)] Loss: 0.795925
Training set: Average loss: 0.830880
Training set: Average accuracy: 64.88%
Validation set: Average loss: 0.690749, Accuracy: 804/1050 (77%)

Epoch: 68
Training set [0/6430 (0%)] Loss: 0.809471
Training set [5120/6430 (77%)] Loss: 0.829323
Training set: Average loss: 0.803902
Training set: Average accuracy: 65.13%
Validation set: Average loss: 0.766151, Accuracy: 795/1050 (76%)

Epoch: 69
Training set [0/6430 (0%)] Loss: 0.857112
Training set [5120/6430 (77%)] Loss: 0.828606
Training set: Average loss: 0.809626
Training set: Average accuracy: 64.06%
Validation set: Average loss: 0.717435, Accuracy: 787/1050 (75%)

Epoch: 70
Training set [0/6430 (0%)] Loss: 0.827963
Training set [5120/6430 (77%)] Loss: 0.747596
Training set: Average loss: 0.791713
Training set: Average accuracy: 65.24%
Validation set: Average loss: 0.778730, Accuracy: 798/1050 (76%)

Epoch: 71
Training set [0/6430 (0%)] Loss: 0.804128
Training set [5120/6430 (77%)] Loss: 0.777112
Training set: Average loss: 0.806601
Training set: Average accuracy: 65.38%
Validation set: Average loss: 0.766088, Accuracy: 783/1050 (75%)

Epoch: 72
Training set [0/6430 (0%)] Loss: 0.782415
Training set [5120/6430 (77%)] Loss: 0.839721
Training set: Average loss: 0.805761
Training set: Average accuracy: 65.94%
Validation set: Average loss: 0.812171, Accuracy: 804/1050 (77%)

Epoch: 73
Training set [0/6430 (0%)] Loss: 0.855564
Training set [5120/6430 (77%)] Loss: 0.869281
Training set: Average loss: 0.841872
Training set: Average accuracy: 64.28%
Validation set: Average loss: 1.102108, Accuracy: 698/1050 (66%)

Epoch: 74
Training set [0/6430 (0%)] Loss: 0.776298
Training set [5120/6430 (77%)] Loss: 0.760999
Training set: Average loss: 0.800096
Training set: Average accuracy: 64.71%
Validation set: Average loss: 0.705870, Accuracy: 806/1050 (77%)

Epoch: 75
Training set [0/6430 (0%)] Loss: 0.828365
Training set [5120/6430 (77%)] Loss: 0.807113
Training set: Average loss: 0.792535
Training set: Average accuracy: 65.93%
Validation set: Average loss: 0.942026, Accuracy: 729/1050 (69%)

Epoch: 76
Training set [0/6430 (0%)] Loss: 0.786459
Training set [5120/6430 (77%)] Loss: 0.754803
Training set: Average loss: 0.780800
Training set: Average accuracy: 66.07%
Validation set: Average loss: 0.810880, Accuracy: 769/1050 (73%)

Epoch: 77
Training set [0/6430 (0%)] Loss: 0.775336
Training set [5120/6430 (77%)] Loss: 0.707067
Training set: Average loss: 0.776913
Training set: Average accuracy: 66.89%
Validation set: Average loss: 0.770783, Accuracy: 796/1050 (76%)

Epoch: 78
Training set [0/6430 (0%)] Loss: 0.740519
Training set [5120/6430 (77%)] Loss: 0.876284
Training set: Average loss: 0.782099
Training set: Average accuracy: 67.08%
Validation set: Average loss: 0.752562, Accuracy: 777/1050 (74%)

Epoch: 79
Training set [0/6430 (0%)] Loss: 0.798723
Training set [5120/6430 (77%)] Loss: 0.804754
Training set: Average loss: 0.766292
Training set: Average accuracy: 66.78%
Validation set: Average loss: 0.779749, Accuracy: 771/1050 (73%)

Epoch: 80
Training set [0/6430 (0%)] Loss: 0.841673
Training set [5120/6430 (77%)] Loss: 0.767666
Training set: Average loss: 0.787163
Training set: Average accuracy: 66.45%
Validation set: Average loss: 0.816156, Accuracy: 802/1050 (76%)

Epoch: 81
Training set [0/6430 (0%)] Loss: 0.812479
Training set [5120/6430 (77%)] Loss: 0.722534
Training set: Average loss: 0.754085
Training set: Average accuracy: 67.31%
Validation set: Average loss: 0.782718, Accuracy: 769/1050 (73%)

Epoch: 82
Training set [0/6430 (0%)] Loss: 0.776915
Training set [5120/6430 (77%)] Loss: 0.849144
Training set: Average loss: 0.768781
Training set: Average accuracy: 67.11%
Validation set: Average loss: 0.942752, Accuracy: 802/1050 (76%)

Epoch: 83
Training set [0/6430 (0%)] Loss: 0.817729
Training set [5120/6430 (77%)] Loss: 0.777152
Training set: Average loss: 0.760834
Training set: Average accuracy: 66.66%
Validation set: Average loss: 0.761139, Accuracy: 795/1050 (76%)

Epoch: 84
Training set [0/6430 (0%)] Loss: 0.877406
Training set [5120/6430 (77%)] Loss: 0.744775
Training set: Average loss: 0.779445
Training set: Average accuracy: 66.17%
Validation set: Average loss: 0.760416, Accuracy: 821/1050 (78%)

Epoch: 85
Training set [0/6430 (0%)] Loss: 0.823016
Training set [5120/6430 (77%)] Loss: 0.745581
Training set: Average loss: 0.759918
Training set: Average accuracy: 67.12%
Validation set: Average loss: 1.197870, Accuracy: 739/1050 (70%)

Epoch: 86
Training set [0/6430 (0%)] Loss: 0.780018
Training set [5120/6430 (77%)] Loss: 0.786490
Training set: Average loss: 0.749337
Training set: Average accuracy: 67.99%
Validation set: Average loss: 0.751896, Accuracy: 793/1050 (76%)

Epoch: 87
Training set [0/6430 (0%)] Loss: 0.750744
Training set [5120/6430 (77%)] Loss: 0.763047
Training set: Average loss: 0.759570
Training set: Average accuracy: 67.74%
Validation set: Average loss: 0.720701, Accuracy: 821/1050 (78%)

Epoch: 88
Training set [0/6430 (0%)] Loss: 0.771538
Training set [5120/6430 (77%)] Loss: 0.758663
Training set: Average loss: 0.744136
Training set: Average accuracy: 67.90%
Validation set: Average loss: 0.890855, Accuracy: 749/1050 (71%)

Epoch: 89
Training set [0/6430 (0%)] Loss: 0.768065
Training set [5120/6430 (77%)] Loss: 0.737863
Training set: Average loss: 0.744062
Training set: Average accuracy: 68.04%
Validation set: Average loss: 0.755807, Accuracy: 803/1050 (76%)

Epoch: 90
Training set [0/6430 (0%)] Loss: 0.666873
Training set [5120/6430 (77%)] Loss: 0.718051
Training set: Average loss: 0.726060
Training set: Average accuracy: 68.69%
Validation set: Average loss: 0.743633, Accuracy: 791/1050 (75%)

Epoch: 91
Training set [0/6430 (0%)] Loss: 0.724919
Training set [5120/6430 (77%)] Loss: 0.754986
Training set: Average loss: 0.727597
Training set: Average accuracy: 68.10%
Validation set: Average loss: 0.855659, Accuracy: 805/1050 (77%)

Epoch: 92
Training set [0/6430 (0%)] Loss: 0.761905
Training set [5120/6430 (77%)] Loss: 0.675524
Training set: Average loss: 0.721469
Training set: Average accuracy: 68.29%
Validation set: Average loss: 0.844955, Accuracy: 782/1050 (74%)

Epoch: 93
Training set [0/6430 (0%)] Loss: 0.723739
Training set [5120/6430 (77%)] Loss: 0.762233
Training set: Average loss: 0.732138
Training set: Average accuracy: 68.77%
Validation set: Average loss: 0.656013, Accuracy: 835/1050 (80%)

Epoch: 94
Training set [0/6430 (0%)] Loss: 0.752875
Training set [5120/6430 (77%)] Loss: 0.669441
Training set: Average loss: 0.720032
Training set: Average accuracy: 69.00%
Validation set: Average loss: 1.005912, Accuracy: 733/1050 (70%)

Epoch: 95
Training set [0/6430 (0%)] Loss: 0.719696
Training set [5120/6430 (77%)] Loss: 0.773901
Training set: Average loss: 0.725088
Training set: Average accuracy: 68.88%
Validation set: Average loss: 0.715620, Accuracy: 805/1050 (77%)

Epoch: 96
Training set [0/6430 (0%)] Loss: 0.700907
Training set [5120/6430 (77%)] Loss: 0.745025
Training set: Average loss: 0.744545
Training set: Average accuracy: 67.25%
Validation set: Average loss: 0.772850, Accuracy: 823/1050 (78%)

Epoch: 97
Training set [0/6430 (0%)] Loss: 0.777291
Training set [5120/6430 (77%)] Loss: 0.743575
Training set: Average loss: 0.734179
Training set: Average accuracy: 68.34%
Validation set: Average loss: 0.673255, Accuracy: 831/1050 (79%)

Epoch: 98
Training set [0/6430 (0%)] Loss: 0.776993
Training set [5120/6430 (77%)] Loss: 0.644564
Training set: Average loss: 0.727774
Training set: Average accuracy: 68.34%
Validation set: Average loss: 1.060101, Accuracy: 765/1050 (73%)

Epoch: 99
Training set [0/6430 (0%)] Loss: 0.817796
Training set [5120/6430 (77%)] Loss: 0.673417
Training set: Average loss: 0.743287
Training set: Average accuracy: 67.92%
Validation set: Average loss: 0.743429, Accuracy: 811/1050 (77%)

Epoch: 100
Training set [0/6430 (0%)] Loss: 0.681385
Training set [5120/6430 (77%)] Loss: 0.745457
Training set: Average loss: 0.714801
Training set: Average accuracy: 68.77%
Validation set: Average loss: 0.774203, Accuracy: 815/1050 (78%)

Epoch: 101
Training set [0/6430 (0%)] Loss: 0.744314
Training set [5120/6430 (77%)] Loss: 0.665702
Training set: Average loss: 0.703901
Training set: Average accuracy: 70.12%
Validation set: Average loss: 0.737785, Accuracy: 807/1050 (77%)

Epoch: 102
Training set [0/6430 (0%)] Loss: 0.652659
Training set [5120/6430 (77%)] Loss: 0.715489
Training set: Average loss: 0.705616
Training set: Average accuracy: 69.66%
Validation set: Average loss: 0.719546, Accuracy: 812/1050 (77%)

Epoch: 103
Training set [0/6430 (0%)] Loss: 0.636658
Training set [5120/6430 (77%)] Loss: 0.760999
Training set: Average loss: 0.721562
Training set: Average accuracy: 68.77%
Validation set: Average loss: 1.232244, Accuracy: 713/1050 (68%)

Epoch: 104
Training set [0/6430 (0%)] Loss: 0.712732
Training set [5120/6430 (77%)] Loss: 0.754915
Training set: Average loss: 0.732938
Training set: Average accuracy: 69.21%
Validation set: Average loss: 0.864735, Accuracy: 746/1050 (71%)

Epoch: 105
Training set [0/6430 (0%)] Loss: 0.690870
Training set [5120/6430 (77%)] Loss: 0.737523
Training set: Average loss: 0.716707
Training set: Average accuracy: 69.22%
Validation set: Average loss: 0.935353, Accuracy: 771/1050 (73%)

Epoch: 106
Training set [0/6430 (0%)] Loss: 0.664017
Training set [5120/6430 (77%)] Loss: 0.778015
Training set: Average loss: 0.702046
Training set: Average accuracy: 70.39%
Validation set: Average loss: 0.816729, Accuracy: 794/1050 (76%)

Epoch: 107
Training set [0/6430 (0%)] Loss: 0.756843
Training set [5120/6430 (77%)] Loss: 0.720547
Training set: Average loss: 0.715865
Training set: Average accuracy: 69.28%
Validation set: Average loss: 0.655787, Accuracy: 814/1050 (78%)

Epoch: 108
Training set [0/6430 (0%)] Loss: 0.624656
Training set [5120/6430 (77%)] Loss: 0.777386
Training set: Average loss: 0.689973
Training set: Average accuracy: 70.28%
Validation set: Average loss: 0.917916, Accuracy: 750/1050 (71%)

Epoch: 109
Training set [0/6430 (0%)] Loss: 0.694775
Training set [5120/6430 (77%)] Loss: 0.704897
Training set: Average loss: 0.681685
Training set: Average accuracy: 71.04%
Validation set: Average loss: 0.734281, Accuracy: 828/1050 (79%)

Epoch: 110
Training set [0/6430 (0%)] Loss: 0.717104
Training set [5120/6430 (77%)] Loss: 0.656425
Training set: Average loss: 0.708684
Training set: Average accuracy: 69.64%
Validation set: Average loss: 0.685807, Accuracy: 817/1050 (78%)

Epoch: 111
Training set [0/6430 (0%)] Loss: 0.717687
Training set [5120/6430 (77%)] Loss: 0.644965
Training set: Average loss: 0.704707
Training set: Average accuracy: 69.56%
Validation set: Average loss: 0.678567, Accuracy: 813/1050 (77%)

Epoch: 112
Training set [0/6430 (0%)] Loss: 0.647061
Training set [5120/6430 (77%)] Loss: 0.626180
Training set: Average loss: 0.692275
Training set: Average accuracy: 69.66%
Validation set: Average loss: 0.796309, Accuracy: 804/1050 (77%)

Epoch: 113
Training set [0/6430 (0%)] Loss: 0.723469
Training set [5120/6430 (77%)] Loss: 0.607653
Training set: Average loss: 0.690030
Training set: Average accuracy: 70.42%
Validation set: Average loss: 0.809762, Accuracy: 786/1050 (75%)

Epoch: 114
Training set [0/6430 (0%)] Loss: 0.719575
Training set [5120/6430 (77%)] Loss: 0.763473
Training set: Average loss: 0.693786
Training set: Average accuracy: 70.08%
Validation set: Average loss: 0.748845, Accuracy: 802/1050 (76%)

Epoch: 115
Training set [0/6430 (0%)] Loss: 0.666762
Training set [5120/6430 (77%)] Loss: 0.730171
Training set: Average loss: 0.696753
Training set: Average accuracy: 69.52%
Validation set: Average loss: 0.719472, Accuracy: 808/1050 (77%)

Epoch: 116
Training set [0/6430 (0%)] Loss: 0.642642
Training set [5120/6430 (77%)] Loss: 0.671162
Training set: Average loss: 0.682456
Training set: Average accuracy: 70.90%
Validation set: Average loss: 0.809431, Accuracy: 822/1050 (78%)

Epoch: 117
Training set [0/6430 (0%)] Loss: 0.656358
Training set [5120/6430 (77%)] Loss: 0.673711
Training set: Average loss: 0.680842
Training set: Average accuracy: 71.03%
Validation set: Average loss: 0.970569, Accuracy: 785/1050 (75%)

Epoch: 118
Training set [0/6430 (0%)] Loss: 0.684518
Training set [5120/6430 (77%)] Loss: 0.610164
Training set: Average loss: 0.667065
Training set: Average accuracy: 71.54%
Validation set: Average loss: 0.723740, Accuracy: 827/1050 (79%)

Epoch: 119
Training set [0/6430 (0%)] Loss: 0.712311
Training set [5120/6430 (77%)] Loss: 0.652652
Training set: Average loss: 0.683408
Training set: Average accuracy: 70.62%
Validation set: Average loss: 0.817694, Accuracy: 820/1050 (78%)

Epoch: 120
Training set [0/6430 (0%)] Loss: 0.700260
Training set [5120/6430 (77%)] Loss: 0.639626
Training set: Average loss: 0.675225
Training set: Average accuracy: 71.49%
Validation set: Average loss: 0.731830, Accuracy: 808/1050 (77%)

Epoch: 121
Training set [0/6430 (0%)] Loss: 0.683991
Training set [5120/6430 (77%)] Loss: 0.708269
Training set: Average loss: 0.692714
Training set: Average accuracy: 70.06%
Validation set: Average loss: 0.750701, Accuracy: 822/1050 (78%)

Epoch: 122
Training set [0/6430 (0%)] Loss: 0.684874
Training set [5120/6430 (77%)] Loss: 0.730069
Training set: Average loss: 0.691757
Training set: Average accuracy: 70.79%
Validation set: Average loss: 0.737956, Accuracy: 838/1050 (80%)

Epoch: 123
Training set [0/6430 (0%)] Loss: 0.685553
Training set [5120/6430 (77%)] Loss: 0.657506
Training set: Average loss: 0.667340
Training set: Average accuracy: 71.85%
Validation set: Average loss: 0.810044, Accuracy: 817/1050 (78%)

Epoch: 124
Training set [0/6430 (0%)] Loss: 0.686833
Training set [5120/6430 (77%)] Loss: 0.702561
Training set: Average loss: 0.694181
Training set: Average accuracy: 70.00%
Validation set: Average loss: 0.702144, Accuracy: 829/1050 (79%)

Epoch: 125
Training set [0/6430 (0%)] Loss: 0.690015
Training set [5120/6430 (77%)] Loss: 0.629814
Training set: Average loss: 0.675710
Training set: Average accuracy: 71.32%
Validation set: Average loss: 0.763169, Accuracy: 775/1050 (74%)

Epoch: 126
Training set [0/6430 (0%)] Loss: 0.720930
Training set [5120/6430 (77%)] Loss: 0.679467
Training set: Average loss: 0.667639
Training set: Average accuracy: 71.65%
Validation set: Average loss: 0.781078, Accuracy: 814/1050 (78%)

Epoch: 127
Training set [0/6430 (0%)] Loss: 0.669500
Training set [5120/6430 (77%)] Loss: 0.713888
Training set: Average loss: 0.687652
Training set: Average accuracy: 70.47%
Validation set: Average loss: 0.966006, Accuracy: 761/1050 (72%)

Epoch: 128
Training set [0/6430 (0%)] Loss: 0.642169
Training set [5120/6430 (77%)] Loss: 0.692829
Training set: Average loss: 0.673556
Training set: Average accuracy: 71.32%
Validation set: Average loss: 0.991605, Accuracy: 780/1050 (74%)

Early stopping: no improvement for 10 epochs
BasicNet
training_loss -- validation_loss
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128]
[2.9350438576478224, 1.9108009796876173, 1.8790273758081288, 1.8485704018519475, 1.8113892078399658, 1.7735664386015673, 1.7318845895620494, 1.6677264617039607, 1.611621462381803, 1.5643484867536104, 1.5370668172836304, 1.475005947626554, 1.4503520452059233, 1.4213307362336378, 1.3816216175372784, 1.3728937552525446, 1.336787801522475, 1.3044160054280207, 1.2819528029515193, 1.2406047215828528, 1.2214457713640654, 1.2095158650324895, 1.194313333584712, 1.155592313179603, 1.1435761543420644, 1.125367595599248, 1.0929641356834998, 1.0982396510931163, 1.0888082064115083, 1.0855381122002234, 1.0688272256117601, 1.049641985159654, 1.0462233607585614, 1.0051953838421748, 0.9968185378954961, 0.9909032995884235, 0.9844645949510428, 0.9565942241595342, 0.9882762569647568, 0.957542176430042, 0.9680982690591079, 0.9562116173597482, 0.9370059600243201, 0.9249183077078599, 0.9428519423191364, 0.9443249014707712, 0.916746410039755, 0.9115931575114911, 0.8834616633561941, 0.8926593615458562, 0.9069462097608126, 0.8665973635820242, 0.8565367643649762, 0.8729559274820181, 0.8738891023855943, 0.8778642461850092, 0.8648965404583857, 0.8515693866289579, 0.8393550698573773, 0.8207536935806274, 0.8259525023973905, 0.8125529105846698, 0.8326483689821683, 0.8202044046842135, 0.820210012105795, 0.8316784913723285, 0.8245850067872268, 0.8308804356134855, 0.8039019061968877, 0.8096255476658161, 0.7917131231381342, 0.8066010337609512, 0.805761117201585, 0.8418719722674444, 0.800095755320329, 0.7925354425723736, 0.7807997006636399, 0.7769130651767437, 0.7820987013670114, 0.7662923794526321, 0.7871626844772925, 0.7540845137376052, 0.7687808871269226, 0.7608338273488559, 0.7794448228982779, 0.7599178827725924, 0.7493367103429941, 0.7595699888009292, 0.7441359299879807, 0.7440618001497709, 0.7260599915797894, 0.727597021139585, 0.7214687970968393, 0.7321377167334924, 0.7200323434976431, 0.725087936107929, 0.744545198403872, 0.7341788732088529, 0.7277742257485023, 0.7432867792936472, 0.7148010363945594, 0.703901272553664, 0.7056158551803002, 0.721561638208536, 0.7329380282988915, 0.7167072112743671, 0.702046288893773, 0.7158647225453303, 0.6899733864344083, 0.6816852963887728, 0.708683614547436, 0.7047074437141418, 0.6922745246153611, 0.6900301483961252, 0.6937857224391057, 0.6967533139082102, 0.6824564842077402, 0.6808417485310481, 0.6670653865887568, 0.6834078201880822, 0.6752252624585078, 0.692713948396536, 0.6917572617530823, 0.6673395954645597, 0.6941809883484473, 0.6757104075871981, 0.6676393839029166, 0.6876520972985488, 0.6735560985711905]
[1.9351683060328166, 1.9337820609410603, 1.9369896252950032, 1.8675508896509807, 1.8204782009124756, 1.7713918685913086, 1.7316024700800579, 1.7241214911142986, 1.6543445587158203, 1.5751033624013264, 1.4079416592915852, 1.3866191705067952, 1.581485390663147, 1.3786548376083374, 1.258722186088562, 1.2366738319396973, 1.2785731951395671, 1.826474666595459, 1.2211264769236247, 1.6717229684193928, 1.1221400101979573, 1.1484535137812297, 1.1457391182581584, 1.3783878087997437, 1.087817947069804, 0.9835886557896932, 1.0403930346171062, 0.9853323300679525, 0.9764489730199178, 1.0055111447970073, 1.2780979871749878, 0.9685060381889343, 0.8871901035308838, 0.863399863243103, 1.1817799806594849, 1.00153382619222, 1.0284374356269836, 0.8468924562136332, 1.0415741801261902, 0.8582618633906046, 0.9241965810457865, 1.2526520093282063, 0.8782751162846884, 0.8898096084594727, 1.3400379021962483, 0.9822464187939962, 0.8230928977330526, 0.7468229929606119, 0.7975666522979736, 0.7558110952377319, 0.7726899186770121, 0.7601670821507772, 0.8086796601613363, 0.8341559569040934, 0.7383872667948405, 0.7049304048220316, 0.7512826919555664, 0.7912985682487488, 0.7753053704897562, 0.7192738254865011, 1.0033581852912903, 0.9548417329788208, 0.789476195971171, 0.8286018371582031, 0.7359601656595866, 0.808826764424642, 0.8427612980206808, 0.6907492180665334, 0.7661505937576294, 0.717435379823049, 0.7787300944328308, 0.7660875717798868, 0.8121706048647562, 1.102107564608256, 0.7058697541554769, 0.9420261780420939, 0.8108802835146586, 0.7707830468813578, 0.7525618076324463, 0.7797489364941915, 0.8161555926005045, 0.7827181816101074, 0.9427515069643656, 0.7611394226551056, 0.7604164481163025, 1.1978697379430134, 0.751895527044932, 0.7207008898258209, 0.8908548951148987, 0.7558070023854574, 0.7436332106590271, 0.855658749739329, 0.8449547092119852, 0.6560129622618357, 1.0059119661649067, 0.7156198422114054, 0.7728504339853922, 0.6732550462086996, 1.0601007143656414, 0.7434293826421102, 0.7742033203442892, 0.7377854983011881, 0.7195464571317037, 1.2322444518407185, 0.8647352755069733, 0.9353532989819845, 0.8167293866475424, 0.6557865838209788, 0.9179164369901022, 0.734281082948049, 0.6858068605264028, 0.6785665651162466, 0.7963086167971293, 0.8097618321577708, 0.7488451103369395, 0.7194717625776926, 0.8094305793444315, 0.9705685575803121, 0.7237404882907867, 0.817693829536438, 0.7318302194277445, 0.7507012883822123, 0.737955907980601, 0.8100443879763285, 0.702144185702006, 0.7631690402825674, 0.7810779213905334, 0.9660062690575918, 0.991604745388031]
BasicNet
training_accuracy -- validation_accuracy
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128]
[16.14307931570762, 19.79782270606532, 20.995334370139968, 21.944012441679625, 24.68118195956454, 26.578538102643858, 27.23172628304821, 30.77760497667185, 32.76827371695179, 33.79471228615863, 35.16329704510109, 37.51166407465008, 38.818040435458784, 39.95334370139969, 40.68429237947123, 42.02177293934681, 43.421461897356146, 45.3343701399689, 45.47433903576983, 46.469673405909795, 47.6049766718507, 47.16951788491446, 48.538102643856924, 50.13996889580093, 50.69984447900467, 51.50855365474339, 51.49300155520995, 51.306376360808706, 52.98600311041991, 52.61275272161742, 53.77916018662519, 55.14774494556765, 54.3701399688958, 56.48522550544323, 56.40746500777605, 56.90513219284603, 57.09175738724728, 58.5692068429238, 56.71850699844479, 58.28926905132193, 56.96734059097978, 58.740279937791605, 58.78693623639191, 59.20684292379471, 59.1601866251944, 58.60031104199067, 59.93779160186625, 60.52877138413686, 61.524105754276825, 60.20217729393468, 60.342146189735615, 63.01710730948678, 62.02177293934681, 62.00622083981337, 62.2706065318818, 61.64852255054432, 62.954898911353034, 63.03265940902022, 63.73250388802489, 64.3701399688958, 63.45256609642302, 63.6547433903577, 64.04354587869362, 63.90357698289269, 63.59253499222395, 63.99688958009331, 64.68118195956454, 64.88335925349922, 65.13219284603421, 64.05909797822706, 65.24105754276827, 65.38102643856921, 65.94090202177294, 64.27682737169518, 64.71228615863141, 65.9253499222395, 66.06531881804044, 66.8895800933126, 67.07620528771385, 66.78071539657854, 66.45412130637636, 67.3094867807154, 67.10730948678072, 66.65629860031105, 66.1741835147745, 67.12286158631416, 67.99377916018662, 67.74494556765163, 67.900466562986, 68.04043545878693, 68.69362363919129, 68.10264385692068, 68.28926905132192, 68.77138413685847, 69.00466562986003, 68.88024883359253, 67.24727838258165, 68.33592534992223, 68.33592534992223, 67.91601866251943, 68.77138413685847, 70.1244167962675, 69.65785381026438, 68.77138413685847, 69.20684292379471, 69.22239502332815, 70.38880248833593, 69.2846034214619, 70.27993779160187, 71.04199066874028, 69.64230171073095, 69.56454121306376, 69.65785381026438, 70.4199066874028, 70.07776049766719, 69.51788491446345, 70.90202177293935, 71.02643856920685, 71.53965785381027, 70.62208398133748, 71.49300155520996, 70.06220839813375, 70.79315707620529, 71.85069984447901, 70.0, 71.32192846034215, 71.64852255054433, 70.46656298600311, 71.32192846034215]
[14.0, 14.761904761904763, 19.142857142857142, 25.61904761904762, 27.80952380952381, 29.61904761904762, 32.0, 38.57142857142857, 39.142857142857146, 43.23809523809524, 46.095238095238095, 44.76190476190476, 46.38095238095238, 50.57142857142857, 53.23809523809524, 53.23809523809524, 55.23809523809524, 42.95238095238095, 54.476190476190474, 46.57142857142857, 60.38095238095238, 60.19047619047619, 58.57142857142857, 55.333333333333336, 61.523809523809526, 61.523809523809526, 62.76190476190476, 64.66666666666667, 61.42857142857143, 63.142857142857146, 56.857142857142854, 64.38095238095238, 69.80952380952381, 67.23809523809524, 63.04761904761905, 67.33333333333333, 66.38095238095238, 71.04761904761905, 68.28571428571429, 68.66666666666667, 65.23809523809524, 66.95238095238095, 71.71428571428571, 68.0, 61.42857142857143, 69.52380952380952, 71.52380952380952, 73.14285714285714, 70.95238095238095, 73.23809523809524, 71.42857142857143, 74.57142857142857, 73.14285714285714, 70.38095238095238, 72.28571428571429, 75.52380952380952, 73.33333333333333, 70.57142857142857, 74.38095238095238, 75.71428571428571, 67.52380952380952, 74.28571428571429, 72.28571428571429, 73.14285714285714, 74.38095238095238, 72.0, 71.52380952380952, 76.57142857142857, 75.71428571428571, 74.95238095238095, 76.0, 74.57142857142857, 76.57142857142857, 66.47619047619048, 76.76190476190476, 69.42857142857143, 73.23809523809524, 75.80952380952381, 74.0, 73.42857142857143, 76.38095238095238, 73.23809523809524, 76.38095238095238, 75.71428571428571, 78.19047619047619, 70.38095238095238, 75.52380952380952, 78.19047619047619, 71.33333333333333, 76.47619047619048, 75.33333333333333, 76.66666666666667, 74.47619047619048, 79.52380952380952, 69.80952380952381, 76.66666666666667, 78.38095238095238, 79.14285714285714, 72.85714285714286, 77.23809523809524, 77.61904761904762, 76.85714285714286, 77.33333333333333, 67.9047619047619, 71.04761904761905, 73.42857142857143, 75.61904761904762, 77.52380952380952, 71.42857142857143, 78.85714285714286, 77.80952380952381, 77.42857142857143, 76.57142857142857, 74.85714285714286, 76.38095238095238, 76.95238095238095, 78.28571428571429, 74.76190476190476, 78.76190476190476, 78.0952380952381, 76.95238095238095, 78.28571428571429, 79.80952380952381, 77.80952380952381, 78.95238095238095, 73.80952380952381, 77.52380952380952, 72.47619047619048, 74.28571428571429]
model saved as model_store_512/cnn_car_BasicNet.pt
Getting predictions from test set...
BasicNet
[[108   0   0  34   6   0   2]
 [ 17  85   5   7   8   6  22]
 [ 11   0 117  14   0   5   3]
 [ 27   0   4 118   0   1   0]
 [  8   0   2   0 134   1   5]
 [ 16   4   3  10   5 109   3]
 [  2   2  21   7   9   0 109]]
=============================
ImprovedNet
=============================
Epoch: 0
Training set [0/6430 (0%)] Loss: 1.946106
Training set [5120/6430 (77%)] Loss: 1.926826
Training set: Average loss: 2.001965
Training set: Average accuracy: 15.65%
Validation set: Average loss: 1.928090, Accuracy: 235/1050 (22%)

Epoch: 1
Training set [0/6430 (0%)] Loss: 1.886318
Training set [5120/6430 (77%)] Loss: 1.751672
Training set: Average loss: 1.818797
Training set: Average accuracy: 27.39%
Validation set: Average loss: 1.766934, Accuracy: 387/1050 (37%)

Epoch: 2
Training set [0/6430 (0%)] Loss: 1.708679
Training set [5120/6430 (77%)] Loss: 1.606474
Training set: Average loss: 1.670051
Training set: Average accuracy: 36.91%
Validation set: Average loss: 1.678085, Accuracy: 426/1050 (41%)

Epoch: 3
Training set [0/6430 (0%)] Loss: 1.645090
Training set [5120/6430 (77%)] Loss: 1.451525
Training set: Average loss: 1.540228
Training set: Average accuracy: 43.09%
Validation set: Average loss: 1.490790, Accuracy: 453/1050 (43%)

Epoch: 4
Training set [0/6430 (0%)] Loss: 1.525908
Training set [5120/6430 (77%)] Loss: 1.389694
Training set: Average loss: 1.422614
Training set: Average accuracy: 47.99%
Validation set: Average loss: 1.460150, Accuracy: 519/1050 (49%)

Epoch: 5
Training set [0/6430 (0%)] Loss: 1.357360
Training set [5120/6430 (77%)] Loss: 1.220031
Training set: Average loss: 1.274107
Training set: Average accuracy: 53.98%
Validation set: Average loss: 1.351357, Accuracy: 558/1050 (53%)

Epoch: 6
Training set [0/6430 (0%)] Loss: 1.184558
Training set [5120/6430 (77%)] Loss: 1.090585
Training set: Average loss: 1.131065
Training set: Average accuracy: 59.66%
Validation set: Average loss: 1.127232, Accuracy: 599/1050 (57%)

Epoch: 7
Training set [0/6430 (0%)] Loss: 1.090389
Training set [5120/6430 (77%)] Loss: 0.960487
Training set: Average loss: 0.997253
Training set: Average accuracy: 64.88%
Validation set: Average loss: 1.154334, Accuracy: 619/1050 (59%)

Epoch: 8
Training set [0/6430 (0%)] Loss: 0.809848
Training set [5120/6430 (77%)] Loss: 0.838528
Training set: Average loss: 0.839907
Training set: Average accuracy: 70.78%
Validation set: Average loss: 1.246183, Accuracy: 664/1050 (63%)

Epoch: 9
Training set [0/6430 (0%)] Loss: 0.780004
Training set [5120/6430 (77%)] Loss: 0.668366
Training set: Average loss: 0.702192
Training set: Average accuracy: 76.44%
Validation set: Average loss: 0.916673, Accuracy: 666/1050 (63%)

Epoch: 10
Training set [0/6430 (0%)] Loss: 0.592982
Training set [5120/6430 (77%)] Loss: 0.499581
Training set: Average loss: 0.570726
Training set: Average accuracy: 81.04%
Validation set: Average loss: 0.993223, Accuracy: 688/1050 (66%)

Epoch: 11
Training set [0/6430 (0%)] Loss: 0.530404
Training set [5120/6430 (77%)] Loss: 0.463519
Training set: Average loss: 0.467427
Training set: Average accuracy: 84.54%
Validation set: Average loss: 0.943610, Accuracy: 687/1050 (65%)

Epoch: 12
Training set [0/6430 (0%)] Loss: 0.382230
Training set [5120/6430 (77%)] Loss: 0.351199
Training set: Average loss: 0.367262
Training set: Average accuracy: 87.85%
Validation set: Average loss: 1.001993, Accuracy: 697/1050 (66%)

Epoch: 13
Training set [0/6430 (0%)] Loss: 0.363364
Training set [5120/6430 (77%)] Loss: 0.289083
Training set: Average loss: 0.306154
Training set: Average accuracy: 89.70%
Validation set: Average loss: 1.062504, Accuracy: 695/1050 (66%)

Epoch: 14
Training set [0/6430 (0%)] Loss: 0.257723
Training set [5120/6430 (77%)] Loss: 0.238839
Training set: Average loss: 0.260429
Training set: Average accuracy: 91.32%
Validation set: Average loss: 0.953690, Accuracy: 712/1050 (68%)

Epoch: 15
Training set [0/6430 (0%)] Loss: 0.192492
Training set [5120/6430 (77%)] Loss: 0.203472
Training set: Average loss: 0.200415
Training set: Average accuracy: 93.50%
Validation set: Average loss: 0.951282, Accuracy: 718/1050 (68%)

Epoch: 16
Training set [0/6430 (0%)] Loss: 0.203335
Training set [5120/6430 (77%)] Loss: 0.135971
Training set: Average loss: 0.159941
Training set: Average accuracy: 95.01%
Validation set: Average loss: 0.935964, Accuracy: 730/1050 (70%)

Epoch: 17
Training set [0/6430 (0%)] Loss: 0.126328
Training set [5120/6430 (77%)] Loss: 0.139483
Training set: Average loss: 0.130388
Training set: Average accuracy: 96.05%
Validation set: Average loss: 1.007103, Accuracy: 732/1050 (70%)

Epoch: 18
Training set [0/6430 (0%)] Loss: 0.115305
Training set [5120/6430 (77%)] Loss: 0.107537
Training set: Average loss: 0.116204
Training set: Average accuracy: 96.38%
Validation set: Average loss: 0.983722, Accuracy: 721/1050 (69%)

Epoch: 19
Training set [0/6430 (0%)] Loss: 0.074447
Training set [5120/6430 (77%)] Loss: 0.090681
Training set: Average loss: 0.099055
Training set: Average accuracy: 97.05%
Validation set: Average loss: 1.015284, Accuracy: 721/1050 (69%)

Epoch: 20
Training set [0/6430 (0%)] Loss: 0.099728
Training set [5120/6430 (77%)] Loss: 0.129267
Training set: Average loss: 0.106618
Training set: Average accuracy: 96.56%
Validation set: Average loss: 0.984228, Accuracy: 733/1050 (70%)

Epoch: 21
Training set [0/6430 (0%)] Loss: 0.108194
Training set [5120/6430 (77%)] Loss: 0.092329
Training set: Average loss: 0.096720
Training set: Average accuracy: 96.81%
Validation set: Average loss: 1.110308, Accuracy: 736/1050 (70%)

Epoch: 22
Training set [0/6430 (0%)] Loss: 0.093697
Training set [5120/6430 (77%)] Loss: 0.080321
Training set: Average loss: 0.081787
Training set: Average accuracy: 97.56%
Validation set: Average loss: 1.048569, Accuracy: 724/1050 (69%)

Epoch: 23
Training set [0/6430 (0%)] Loss: 0.069912
Training set [5120/6430 (77%)] Loss: 0.070044
Training set: Average loss: 0.064054
Training set: Average accuracy: 98.09%
Validation set: Average loss: 1.151258, Accuracy: 720/1050 (69%)

Epoch: 24
Training set [0/6430 (0%)] Loss: 0.053521
Training set [5120/6430 (77%)] Loss: 0.066722
Training set: Average loss: 0.069420
Training set: Average accuracy: 97.74%
Validation set: Average loss: 1.021842, Accuracy: 729/1050 (69%)

Epoch: 25
Training set [0/6430 (0%)] Loss: 0.054760
Training set [5120/6430 (77%)] Loss: 0.072539
Training set: Average loss: 0.069251
Training set: Average accuracy: 97.92%
Validation set: Average loss: 1.130636, Accuracy: 733/1050 (70%)

Epoch: 26
Training set [0/6430 (0%)] Loss: 0.054488
Training set [5120/6430 (77%)] Loss: 0.060338
Training set: Average loss: 0.056616
Training set: Average accuracy: 98.27%
Validation set: Average loss: 1.098609, Accuracy: 711/1050 (68%)

Epoch: 27
Training set [0/6430 (0%)] Loss: 0.056137
Training set [5120/6430 (77%)] Loss: 0.052863
Training set: Average loss: 0.048142
Training set: Average accuracy: 98.41%
Validation set: Average loss: 1.184285, Accuracy: 730/1050 (70%)

Epoch: 28
Training set [0/6430 (0%)] Loss: 0.047365
Training set [5120/6430 (77%)] Loss: 0.066554
Training set: Average loss: 0.051031
Training set: Average accuracy: 98.57%
Validation set: Average loss: 1.085531, Accuracy: 738/1050 (70%)

Epoch: 29
Training set [0/6430 (0%)] Loss: 0.039769
Training set [5120/6430 (77%)] Loss: 0.035014
Training set: Average loss: 0.044616
Training set: Average accuracy: 98.69%
Validation set: Average loss: 1.370825, Accuracy: 733/1050 (70%)

Epoch: 30
Training set [0/6430 (0%)] Loss: 0.066709
Training set [5120/6430 (77%)] Loss: 0.038046
Training set: Average loss: 0.046433
Training set: Average accuracy: 98.68%
Validation set: Average loss: 1.087817, Accuracy: 730/1050 (70%)

Epoch: 31
Training set [0/6430 (0%)] Loss: 0.034761
Training set [5120/6430 (77%)] Loss: 0.031112
Training set: Average loss: 0.040235
Training set: Average accuracy: 98.85%
Validation set: Average loss: 1.105651, Accuracy: 730/1050 (70%)

Epoch: 32
Training set [0/6430 (0%)] Loss: 0.024780
Training set [5120/6430 (77%)] Loss: 0.034413
Training set: Average loss: 0.033357
Training set: Average accuracy: 99.10%
Validation set: Average loss: 1.302834, Accuracy: 723/1050 (69%)

Epoch: 33
Training set [0/6430 (0%)] Loss: 0.035331
Training set [5120/6430 (77%)] Loss: 0.036083
Training set: Average loss: 0.033651
Training set: Average accuracy: 98.99%
Validation set: Average loss: 1.201776, Accuracy: 742/1050 (71%)

Epoch: 34
Training set [0/6430 (0%)] Loss: 0.045059
Training set [5120/6430 (77%)] Loss: 0.039399
Training set: Average loss: 0.035146
Training set: Average accuracy: 98.86%
Validation set: Average loss: 1.173177, Accuracy: 733/1050 (70%)

Epoch: 35
Training set [0/6430 (0%)] Loss: 0.032899
Training set [5120/6430 (77%)] Loss: 0.031727
Training set: Average loss: 0.033497
Training set: Average accuracy: 98.96%
Validation set: Average loss: 1.135891, Accuracy: 739/1050 (70%)

Epoch: 36
Training set [0/6430 (0%)] Loss: 0.019245
Training set [5120/6430 (77%)] Loss: 0.035685
Training set: Average loss: 0.032301
Training set: Average accuracy: 99.10%
Validation set: Average loss: 1.249950, Accuracy: 742/1050 (71%)

Epoch: 37
Training set [0/6430 (0%)] Loss: 0.029685
Training set [5120/6430 (77%)] Loss: 0.030010
Training set: Average loss: 0.030955
Training set: Average accuracy: 99.13%
Validation set: Average loss: 1.224294, Accuracy: 734/1050 (70%)

Epoch: 38
Training set [0/6430 (0%)] Loss: 0.037123
Training set [5120/6430 (77%)] Loss: 0.023966
Training set: Average loss: 0.027205
Training set: Average accuracy: 99.28%
Validation set: Average loss: 1.220843, Accuracy: 722/1050 (69%)

Epoch: 39
Training set [0/6430 (0%)] Loss: 0.034519
Training set [5120/6430 (77%)] Loss: 0.032212
Training set: Average loss: 0.028199
Training set: Average accuracy: 99.19%
Validation set: Average loss: 1.395052, Accuracy: 726/1050 (69%)

Epoch: 40
Training set [0/6430 (0%)] Loss: 0.028886
Training set [5120/6430 (77%)] Loss: 0.035003
Training set: Average loss: 0.026832
Training set: Average accuracy: 99.10%
Validation set: Average loss: 1.413588, Accuracy: 730/1050 (70%)

Epoch: 41
Training set [0/6430 (0%)] Loss: 0.029048
Training set [5120/6430 (77%)] Loss: 0.032716
Training set: Average loss: 0.026546
Training set: Average accuracy: 99.22%
Validation set: Average loss: 1.229504, Accuracy: 733/1050 (70%)

Epoch: 42
Training set [0/6430 (0%)] Loss: 0.036066
Training set [5120/6430 (77%)] Loss: 0.027689
Training set: Average loss: 0.029650
Training set: Average accuracy: 99.13%
Validation set: Average loss: 1.180555, Accuracy: 742/1050 (71%)

Epoch: 43
Training set [0/6430 (0%)] Loss: 0.033210
Training set [5120/6430 (77%)] Loss: 0.020675
Training set: Average loss: 0.023212
Training set: Average accuracy: 99.33%
Validation set: Average loss: 1.319383, Accuracy: 717/1050 (68%)

Epoch: 44
Training set [0/6430 (0%)] Loss: 0.026820
Training set [5120/6430 (77%)] Loss: 0.024621
Training set: Average loss: 0.022995
Training set: Average accuracy: 99.32%
Validation set: Average loss: 1.352219, Accuracy: 718/1050 (68%)

Epoch: 45
Training set [0/6430 (0%)] Loss: 0.019063
Training set [5120/6430 (77%)] Loss: 0.019134
Training set: Average loss: 0.023382
Training set: Average accuracy: 99.35%
Validation set: Average loss: 1.250776, Accuracy: 736/1050 (70%)

Epoch: 46
Training set [0/6430 (0%)] Loss: 0.023476
Training set [5120/6430 (77%)] Loss: 0.017211
Training set: Average loss: 0.021097
Training set: Average accuracy: 99.39%
Validation set: Average loss: 1.350737, Accuracy: 726/1050 (69%)

Epoch: 47
Training set [0/6430 (0%)] Loss: 0.022925
Training set [5120/6430 (77%)] Loss: 0.022489
Training set: Average loss: 0.022389
Training set: Average accuracy: 99.38%
Validation set: Average loss: 1.318104, Accuracy: 733/1050 (70%)

Epoch: 48
Training set [0/6430 (0%)] Loss: 0.021035
Training set [5120/6430 (77%)] Loss: 0.016425
Training set: Average loss: 0.020525
Training set: Average accuracy: 99.30%
Validation set: Average loss: 1.504631, Accuracy: 736/1050 (70%)

Epoch: 49
Training set [0/6430 (0%)] Loss: 0.032715
Training set [5120/6430 (77%)] Loss: 0.024099
Training set: Average loss: 0.020898
Training set: Average accuracy: 99.35%
Validation set: Average loss: 1.376599, Accuracy: 730/1050 (70%)

Epoch: 50
Training set [0/6430 (0%)] Loss: 0.024938
Training set [5120/6430 (77%)] Loss: 0.015523
Training set: Average loss: 0.021112
Training set: Average accuracy: 99.42%
Validation set: Average loss: 1.302463, Accuracy: 743/1050 (71%)

Epoch: 51
Training set [0/6430 (0%)] Loss: 0.011139
Training set [5120/6430 (77%)] Loss: 0.013952
Training set: Average loss: 0.019511
Training set: Average accuracy: 99.33%
Validation set: Average loss: 1.254261, Accuracy: 753/1050 (72%)

Epoch: 52
Training set [0/6430 (0%)] Loss: 0.013559
Training set [5120/6430 (77%)] Loss: 0.023261
Training set: Average loss: 0.019961
Training set: Average accuracy: 99.36%
Validation set: Average loss: 1.542916, Accuracy: 732/1050 (70%)

Epoch: 53
Training set [0/6430 (0%)] Loss: 0.013270
Training set [5120/6430 (77%)] Loss: 0.028797
Training set: Average loss: 0.023545
Training set: Average accuracy: 99.35%
Validation set: Average loss: 1.416595, Accuracy: 716/1050 (68%)

Epoch: 54
Training set [0/6430 (0%)] Loss: 0.037520
Training set [5120/6430 (77%)] Loss: 0.016485
Training set: Average loss: 0.022694
Training set: Average accuracy: 99.32%
Validation set: Average loss: 1.296024, Accuracy: 728/1050 (69%)

Epoch: 55
Training set [0/6430 (0%)] Loss: 0.005827
Training set [5120/6430 (77%)] Loss: 0.015696
Training set: Average loss: 0.023801
Training set: Average accuracy: 99.27%
Validation set: Average loss: 1.345035, Accuracy: 724/1050 (69%)

Epoch: 56
Training set [0/6430 (0%)] Loss: 0.022041
Training set [5120/6430 (77%)] Loss: 0.016025
Training set: Average loss: 0.021959
Training set: Average accuracy: 99.35%
Validation set: Average loss: 1.221448, Accuracy: 746/1050 (71%)

Epoch: 57
Training set [0/6430 (0%)] Loss: 0.009873
Training set [5120/6430 (77%)] Loss: 0.028020
Training set: Average loss: 0.021009
Training set: Average accuracy: 99.25%
Validation set: Average loss: 1.411113, Accuracy: 729/1050 (69%)

Epoch: 58
Training set [0/6430 (0%)] Loss: 0.010197
Training set [5120/6430 (77%)] Loss: 0.034218
Training set: Average loss: 0.020224
Training set: Average accuracy: 99.36%
Validation set: Average loss: 1.303219, Accuracy: 725/1050 (69%)

Epoch: 59
Training set [0/6430 (0%)] Loss: 0.008542
Training set [5120/6430 (77%)] Loss: 0.018959
Training set: Average loss: 0.019133
Training set: Average accuracy: 99.41%
Validation set: Average loss: 1.499336, Accuracy: 737/1050 (70%)

Epoch: 60
Training set [0/6430 (0%)] Loss: 0.006115
Training set [5120/6430 (77%)] Loss: 0.014997
Training set: Average loss: 0.018763
Training set: Average accuracy: 99.36%
Validation set: Average loss: 1.370059, Accuracy: 730/1050 (70%)

Epoch: 61
Training set [0/6430 (0%)] Loss: 0.011946
Training set [5120/6430 (77%)] Loss: 0.013733
Training set: Average loss: 0.023378
Training set: Average accuracy: 99.36%
Validation set: Average loss: 1.471976, Accuracy: 724/1050 (69%)

Epoch: 62
Training set [0/6430 (0%)] Loss: 0.018528
Training set [5120/6430 (77%)] Loss: 0.017318
Training set: Average loss: 0.018294
Training set: Average accuracy: 99.35%
Validation set: Average loss: 1.396377, Accuracy: 727/1050 (69%)

Epoch: 63
Training set [0/6430 (0%)] Loss: 0.016292
Training set [5120/6430 (77%)] Loss: 0.018041
Training set: Average loss: 0.021010
Training set: Average accuracy: 99.28%
Validation set: Average loss: 1.404720, Accuracy: 726/1050 (69%)

Epoch: 64
Training set [0/6430 (0%)] Loss: 0.022274
Training set [5120/6430 (77%)] Loss: 0.030304
Training set: Average loss: 0.020869
Training set: Average accuracy: 99.32%
Validation set: Average loss: 1.558329, Accuracy: 735/1050 (70%)

Epoch: 65
Training set [0/6430 (0%)] Loss: 0.014357
Training set [5120/6430 (77%)] Loss: 0.023751
Training set: Average loss: 0.018277
Training set: Average accuracy: 99.46%
Validation set: Average loss: 1.446608, Accuracy: 725/1050 (69%)

Epoch: 66
Training set [0/6430 (0%)] Loss: 0.017393
Training set [5120/6430 (77%)] Loss: 0.030174
Training set: Average loss: 0.019796
Training set: Average accuracy: 99.35%
Validation set: Average loss: 1.308251, Accuracy: 743/1050 (71%)

Epoch: 67
Training set [0/6430 (0%)] Loss: 0.018510
Training set [5120/6430 (77%)] Loss: 0.011142
Training set: Average loss: 0.016971
Training set: Average accuracy: 99.53%
Validation set: Average loss: 1.327875, Accuracy: 736/1050 (70%)

Epoch: 68
Training set [0/6430 (0%)] Loss: 0.008626
Training set [5120/6430 (77%)] Loss: 0.009686
Training set: Average loss: 0.021083
Training set: Average accuracy: 99.39%
Validation set: Average loss: 1.307068, Accuracy: 721/1050 (69%)

Epoch: 69
Training set [0/6430 (0%)] Loss: 0.014546
Training set [5120/6430 (77%)] Loss: 0.020813
Training set: Average loss: 0.016997
Training set: Average accuracy: 99.46%
Validation set: Average loss: 1.399840, Accuracy: 726/1050 (69%)

Epoch: 70
Training set [0/6430 (0%)] Loss: 0.018546
Training set [5120/6430 (77%)] Loss: 0.027140
Training set: Average loss: 0.018212
Training set: Average accuracy: 99.46%
Validation set: Average loss: 1.481099, Accuracy: 731/1050 (70%)

Epoch: 71
Training set [0/6430 (0%)] Loss: 0.007972
Training set [5120/6430 (77%)] Loss: 0.017833
Training set: Average loss: 0.019459
Training set: Average accuracy: 99.28%
Validation set: Average loss: 1.354828, Accuracy: 730/1050 (70%)

Epoch: 72
Training set [0/6430 (0%)] Loss: 0.012758
Training set [5120/6430 (77%)] Loss: 0.023999
Training set: Average loss: 0.021568
Training set: Average accuracy: 99.39%
Validation set: Average loss: 1.380666, Accuracy: 730/1050 (70%)

Epoch: 73
Training set [0/6430 (0%)] Loss: 0.013361
Training set [5120/6430 (77%)] Loss: 0.014694
Training set: Average loss: 0.021958
Training set: Average accuracy: 99.16%
Validation set: Average loss: 1.475514, Accuracy: 738/1050 (70%)

Epoch: 74
Training set [0/6430 (0%)] Loss: 0.017393
Training set [5120/6430 (77%)] Loss: 0.013354
Training set: Average loss: 0.015837
Training set: Average accuracy: 99.52%
Validation set: Average loss: 1.357515, Accuracy: 733/1050 (70%)

Epoch: 75
Training set [0/6430 (0%)] Loss: 0.009061
Training set [5120/6430 (77%)] Loss: 0.019421
Training set: Average loss: 0.015618
Training set: Average accuracy: 99.58%
Validation set: Average loss: 1.402260, Accuracy: 735/1050 (70%)

Epoch: 76
Training set [0/6430 (0%)] Loss: 0.008074
Training set [5120/6430 (77%)] Loss: 0.015118
Training set: Average loss: 0.015052
Training set: Average accuracy: 99.52%
Validation set: Average loss: 1.331400, Accuracy: 737/1050 (70%)

Epoch: 77
Training set [0/6430 (0%)] Loss: 0.019788
Training set [5120/6430 (77%)] Loss: 0.021911
Training set: Average loss: 0.017660
Training set: Average accuracy: 99.55%
Validation set: Average loss: 1.270982, Accuracy: 734/1050 (70%)

Epoch: 78
Training set [0/6430 (0%)] Loss: 0.011078
Training set [5120/6430 (77%)] Loss: 0.004305
Training set: Average loss: 0.011048
Training set: Average accuracy: 99.64%
Validation set: Average loss: 1.502522, Accuracy: 740/1050 (70%)

Epoch: 79
Training set [0/6430 (0%)] Loss: 0.033337
Training set [5120/6430 (77%)] Loss: 0.006688
Training set: Average loss: 0.011208
Training set: Average accuracy: 99.70%
Validation set: Average loss: 1.429767, Accuracy: 742/1050 (71%)

Epoch: 80
Training set [0/6430 (0%)] Loss: 0.006669
Training set [5120/6430 (77%)] Loss: 0.006423
Training set: Average loss: 0.013571
Training set: Average accuracy: 99.60%
Validation set: Average loss: 1.428108, Accuracy: 724/1050 (69%)

Epoch: 81
Training set [0/6430 (0%)] Loss: 0.010937
Training set [5120/6430 (77%)] Loss: 0.009706
Training set: Average loss: 0.014152
Training set: Average accuracy: 99.55%
Validation set: Average loss: 1.362047, Accuracy: 724/1050 (69%)

Epoch: 82
Training set [0/6430 (0%)] Loss: 0.007751
Training set [5120/6430 (77%)] Loss: 0.004658
Training set: Average loss: 0.013488
Training set: Average accuracy: 99.56%
Validation set: Average loss: 1.428358, Accuracy: 722/1050 (69%)

Epoch: 83
Training set [0/6430 (0%)] Loss: 0.015305
Training set [5120/6430 (77%)] Loss: 0.017671
Training set: Average loss: 0.015706
Training set: Average accuracy: 99.53%
Validation set: Average loss: 1.477063, Accuracy: 718/1050 (68%)

Epoch: 84
Training set [0/6430 (0%)] Loss: 0.013128
Training set [5120/6430 (77%)] Loss: 0.011961
Training set: Average loss: 0.015437
Training set: Average accuracy: 99.55%
Validation set: Average loss: 1.406323, Accuracy: 741/1050 (71%)

Epoch: 85
Training set [0/6430 (0%)] Loss: 0.025626
Training set [5120/6430 (77%)] Loss: 0.012986
Training set: Average loss: 0.015431
Training set: Average accuracy: 99.64%
Validation set: Average loss: 1.451806, Accuracy: 723/1050 (69%)

Epoch: 86
Training set [0/6430 (0%)] Loss: 0.013176
Training set [5120/6430 (77%)] Loss: 0.010778
Training set: Average loss: 0.015817
Training set: Average accuracy: 99.49%
Validation set: Average loss: 1.577566, Accuracy: 732/1050 (70%)

Epoch: 87
Training set [0/6430 (0%)] Loss: 0.007160
Training set [5120/6430 (77%)] Loss: 0.008735
Training set: Average loss: 0.011297
Training set: Average accuracy: 99.70%
Validation set: Average loss: 1.554520, Accuracy: 735/1050 (70%)

Epoch: 88
Training set [0/6430 (0%)] Loss: 0.011461
Training set [5120/6430 (77%)] Loss: 0.005579
Training set: Average loss: 0.012429
Training set: Average accuracy: 99.63%
Validation set: Average loss: 1.467355, Accuracy: 733/1050 (70%)

Early stopping: no improvement for 10 epochs
ImprovedNet
training_loss -- validation_loss
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88]
[2.001964807510376, 1.8187974599691539, 1.6700514921775231, 1.5402278808447032, 1.4226136757777288, 1.2741065483826857, 1.1310652494430542, 0.9972530786807721, 0.839907352740948, 0.7021922423289373, 0.5707255395559164, 0.46742713222136867, 0.36726153126129735, 0.3061541754465837, 0.2604294488063225, 0.20041479628819686, 0.15994065541487473, 0.13038783233899337, 0.1162039190530777, 0.09905546559737279, 0.10661787081223267, 0.09671951199953373, 0.08178734349516723, 0.06405401831636062, 0.06942039011762692, 0.06925100661241092, 0.05661556382591908, 0.0481421140810618, 0.0510305160513291, 0.04461585959562889, 0.04643270545280897, 0.040234581782267645, 0.03335685856067217, 0.03365062893583225, 0.03514626371459319, 0.0334971327907764, 0.03230055206670211, 0.030955219498047463, 0.027204769520232312, 0.028198959305882454, 0.02683237259491132, 0.0265462938696146, 0.02965015574143483, 0.023212439022385158, 0.02299452659029227, 0.02338153052215393, 0.021097172481509354, 0.022388668086093206, 0.020524707766106494, 0.020897521780660518, 0.021112291572185662, 0.019510631807721578, 0.019960570005843274, 0.02354469135976755, 0.022693935638436906, 0.023800989612936974, 0.021958522176226743, 0.02100902502066814, 0.02022398320528177, 0.019132548656601172, 0.01876282312262517, 0.023378076676565867, 0.018293572446474664, 0.021010181078544028, 0.02086944247667606, 0.01827692835090252, 0.01979554150826656, 0.016971423827971403, 0.021082973680817164, 0.01699695163048231, 0.018212135164783552, 0.019459394379877128, 0.021567967147208177, 0.021957980755430002, 0.015837452231118314, 0.015618483858326307, 0.015052456229638595, 0.0176601093262434, 0.011048067182015914, 0.011207950659669362, 0.01357052056118846, 0.014151835670837989, 0.013487528221538434, 0.015705602171902474, 0.015436918223993136, 0.015430687890889553, 0.01581661467655347, 0.011296826199843334, 0.012429110240191221]
[1.9280900955200195, 1.7669341166814168, 1.6780850887298584, 1.4907903671264648, 1.4601500034332275, 1.3513567050298054, 1.1272323727607727, 1.1543340682983398, 1.2461830774943035, 0.9166731238365173, 0.9932231108347574, 0.9436104893684387, 1.0019929806391399, 1.0625040928522747, 0.9536904295285543, 0.9512823224067688, 0.9359637498855591, 1.0071027676264446, 0.9837218721707662, 1.015284279982249, 0.9842284023761749, 1.1103080709775288, 1.0485689441363018, 1.1512578924496968, 1.0218421121438344, 1.1306357185045879, 1.0986085732777913, 1.184285302956899, 1.0855305790901184, 1.3708254893620808, 1.087817261616389, 1.1056513984998066, 1.3028335173924763, 1.2017764846483867, 1.173176606496175, 1.1358912388483684, 1.2499498923619587, 1.2242936889330547, 1.2208428382873535, 1.395051638285319, 1.4135876099268596, 1.229503591855367, 1.1805546879768372, 1.3193829258282979, 1.3522186080614726, 1.2507755756378174, 1.3507367173830669, 1.3181042472521465, 1.5046312014261882, 1.3765992919603984, 1.302462875843048, 1.254260540008545, 1.5429162581761677, 1.4165947039922078, 1.2960241933663685, 1.345034658908844, 1.2214481631914775, 1.4111125270525615, 1.3032189806302388, 1.4993358651796977, 1.3700586557388306, 1.4719759225845337, 1.396377146244049, 1.4047201077143352, 1.5583288669586182, 1.4466081261634827, 1.3082506855328877, 1.3278751224279404, 1.3070679903030396, 1.3998404045899708, 1.4810987909634907, 1.354827841122945, 1.3806661367416382, 1.4755144317944844, 1.3575151165326436, 1.4022602538267772, 1.3314000467459361, 1.2709821661313374, 1.502522091070811, 1.4297666748364766, 1.428108145793279, 1.3620474835236867, 1.428357978661855, 1.4770634373029072, 1.40632297595342, 1.4518055468797684, 1.577565868695577, 1.5545197327931721, 1.4673550526301067]
ImprovedNet
training_accuracy -- validation_accuracy
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88]
[15.645412130637636, 27.38724727838258, 36.90513219284603, 43.09486780715397, 47.99377916018663, 53.98133748055987, 59.657853810264385, 64.88335925349922, 70.77760497667185, 76.43856920684293, 81.04199066874028, 84.5412130637636, 87.85381026438569, 89.7045101088647, 91.32192846034215, 93.49922239502332, 95.00777604976672, 96.049766718507, 96.37636080870918, 97.04510108864697, 96.56298600311042, 96.81181959564542, 97.55832037325038, 98.08709175738724, 97.74494556765163, 97.91601866251943, 98.27371695178849, 98.41368584758942, 98.56920684292379, 98.69362363919129, 98.67807153965785, 98.84914463452566, 99.09797822706065, 98.98911353032659, 98.8646967340591, 98.95800933125972, 99.09797822706065, 99.12908242612752, 99.2846034214619, 99.19129082426127, 99.09797822706065, 99.22239502332815, 99.12908242612752, 99.3312597200622, 99.31570762052877, 99.34681181959564, 99.39346811819595, 99.37791601866252, 99.30015552099533, 99.34681181959564, 99.42457231726283, 99.3312597200622, 99.36236391912908, 99.34681181959564, 99.31570762052877, 99.26905132192846, 99.34681181959564, 99.25349922239502, 99.36236391912908, 99.40902021772939, 99.36236391912908, 99.36236391912908, 99.34681181959564, 99.2846034214619, 99.31570762052877, 99.4556765163297, 99.34681181959564, 99.53343701399689, 99.39346811819595, 99.4556765163297, 99.4556765163297, 99.2846034214619, 99.39346811819595, 99.1601866251944, 99.51788491446345, 99.5800933125972, 99.51788491446345, 99.54898911353033, 99.64230171073095, 99.7045101088647, 99.59564541213064, 99.54898911353033, 99.56454121306376, 99.53343701399689, 99.54898911353033, 99.64230171073095, 99.48678071539658, 99.7045101088647, 99.62674961119751]
[22.38095238095238, 36.857142857142854, 40.57142857142857, 43.142857142857146, 49.42857142857143, 53.142857142857146, 57.04761904761905, 58.95238095238095, 63.23809523809524, 63.42857142857143, 65.52380952380952, 65.42857142857143, 66.38095238095238, 66.19047619047619, 67.80952380952381, 68.38095238095238, 69.52380952380952, 69.71428571428571, 68.66666666666667, 68.66666666666667, 69.80952380952381, 70.0952380952381, 68.95238095238095, 68.57142857142857, 69.42857142857143, 69.80952380952381, 67.71428571428571, 69.52380952380952, 70.28571428571429, 69.80952380952381, 69.52380952380952, 69.52380952380952, 68.85714285714286, 70.66666666666667, 69.80952380952381, 70.38095238095238, 70.66666666666667, 69.9047619047619, 68.76190476190476, 69.14285714285714, 69.52380952380952, 69.80952380952381, 70.66666666666667, 68.28571428571429, 68.38095238095238, 70.0952380952381, 69.14285714285714, 69.80952380952381, 70.0952380952381, 69.52380952380952, 70.76190476190476, 71.71428571428571, 69.71428571428571, 68.19047619047619, 69.33333333333333, 68.95238095238095, 71.04761904761905, 69.42857142857143, 69.04761904761905, 70.19047619047619, 69.52380952380952, 68.95238095238095, 69.23809523809524, 69.14285714285714, 70.0, 69.04761904761905, 70.76190476190476, 70.0952380952381, 68.66666666666667, 69.14285714285714, 69.61904761904762, 69.52380952380952, 69.52380952380952, 70.28571428571429, 69.80952380952381, 70.0, 70.19047619047619, 69.9047619047619, 70.47619047619048, 70.66666666666667, 68.95238095238095, 68.95238095238095, 68.76190476190476, 68.38095238095238, 70.57142857142857, 68.85714285714286, 69.71428571428571, 70.0, 69.80952380952381]
model saved as model_store_512/cnn_car_ImprovedNet.pt
Getting predictions from test set...
ImprovedNet
[[102   4   1  10  18   9   6]
 [  6  87   6   7  24   0  20]
 [ 15  11  95   4   8   2  15]
 [ 29   5   5  83   9   9  10]
 [  4   3   0   3 133   1   6]
 [ 11   1   6   9   4 116   3]
 [  4   7   9   3   8   2 117]]
=============================
ImprovedNetLite
=============================
Epoch: 0
Training set [0/6430 (0%)] Loss: 2.028199
Training set [5120/6430 (77%)] Loss: 1.905310
Training set: Average loss: 2.831052
Training set: Average accuracy: 18.32%
Validation set: Average loss: 1.952669, Accuracy: 153/1050 (15%)

Epoch: 1
Training set [0/6430 (0%)] Loss: 1.884307
Training set [5120/6430 (77%)] Loss: 1.853500
Training set: Average loss: 1.856439
Training set: Average accuracy: 23.98%
Validation set: Average loss: 2.154523, Accuracy: 179/1050 (17%)

Epoch: 2
Training set [0/6430 (0%)] Loss: 1.778696
Training set [5120/6430 (77%)] Loss: 1.790210
Training set: Average loss: 1.793394
Training set: Average accuracy: 27.12%
Validation set: Average loss: 2.027927, Accuracy: 230/1050 (22%)

Epoch: 3
Training set [0/6430 (0%)] Loss: 1.727528
Training set [5120/6430 (77%)] Loss: 1.688787
Training set: Average loss: 1.714570
Training set: Average accuracy: 30.84%
Validation set: Average loss: 2.051947, Accuracy: 273/1050 (26%)

Epoch: 4
Training set [0/6430 (0%)] Loss: 1.644048
Training set [5120/6430 (77%)] Loss: 1.641492
Training set: Average loss: 1.631285
Training set: Average accuracy: 34.91%
Validation set: Average loss: 1.790047, Accuracy: 386/1050 (37%)

Epoch: 5
Training set [0/6430 (0%)] Loss: 1.611621
Training set [5120/6430 (77%)] Loss: 1.517466
Training set: Average loss: 1.577873
Training set: Average accuracy: 37.48%
Validation set: Average loss: 1.666888, Accuracy: 446/1050 (42%)

Epoch: 6
Training set [0/6430 (0%)] Loss: 1.615160
Training set [5120/6430 (77%)] Loss: 1.512032
Training set: Average loss: 1.542148
Training set: Average accuracy: 39.77%
Validation set: Average loss: 1.626183, Accuracy: 461/1050 (44%)

Epoch: 7
Training set [0/6430 (0%)] Loss: 1.555520
Training set [5120/6430 (77%)] Loss: 1.437519
Training set: Average loss: 1.467077
Training set: Average accuracy: 42.46%
Validation set: Average loss: 1.558109, Accuracy: 479/1050 (46%)

Epoch: 8
Training set [0/6430 (0%)] Loss: 1.433779
Training set [5120/6430 (77%)] Loss: 1.397412
Training set: Average loss: 1.414987
Training set: Average accuracy: 44.76%
Validation set: Average loss: 1.688078, Accuracy: 464/1050 (44%)

Epoch: 9
Training set [0/6430 (0%)] Loss: 1.390733
Training set [5120/6430 (77%)] Loss: 1.359425
Training set: Average loss: 1.343236
Training set: Average accuracy: 47.47%
Validation set: Average loss: 1.768632, Accuracy: 479/1050 (46%)

Epoch: 10
Training set [0/6430 (0%)] Loss: 1.345350
Training set [5120/6430 (77%)] Loss: 1.216665
Training set: Average loss: 1.299657
Training set: Average accuracy: 48.99%
Validation set: Average loss: 1.457705, Accuracy: 532/1050 (51%)

Epoch: 11
Training set [0/6430 (0%)] Loss: 1.331474
Training set [5120/6430 (77%)] Loss: 1.210466
Training set: Average loss: 1.236691
Training set: Average accuracy: 51.85%
Validation set: Average loss: 1.256727, Accuracy: 577/1050 (55%)

Epoch: 12
Training set [0/6430 (0%)] Loss: 1.164082
Training set [5120/6430 (77%)] Loss: 1.234767
Training set: Average loss: 1.194967
Training set: Average accuracy: 53.55%
Validation set: Average loss: 1.463452, Accuracy: 519/1050 (49%)

Epoch: 13
Training set [0/6430 (0%)] Loss: 1.165756
Training set [5120/6430 (77%)] Loss: 1.128670
Training set: Average loss: 1.124448
Training set: Average accuracy: 56.24%
Validation set: Average loss: 1.098449, Accuracy: 647/1050 (62%)

Epoch: 14
Training set [0/6430 (0%)] Loss: 1.067443
Training set [5120/6430 (77%)] Loss: 1.069852
Training set: Average loss: 1.096105
Training set: Average accuracy: 56.70%
Validation set: Average loss: 1.620560, Accuracy: 534/1050 (51%)

Epoch: 15
Training set [0/6430 (0%)] Loss: 1.003262
Training set [5120/6430 (77%)] Loss: 1.106113
Training set: Average loss: 1.055057
Training set: Average accuracy: 58.55%
Validation set: Average loss: 1.183081, Accuracy: 627/1050 (60%)

Epoch: 16
Training set [0/6430 (0%)] Loss: 0.992874
Training set [5120/6430 (77%)] Loss: 1.016934
Training set: Average loss: 1.020150
Training set: Average accuracy: 60.11%
Validation set: Average loss: 0.888673, Accuracy: 651/1050 (62%)

Epoch: 17
Training set [0/6430 (0%)] Loss: 1.016416
Training set [5120/6430 (77%)] Loss: 0.946290
Training set: Average loss: 0.991160
Training set: Average accuracy: 60.11%
Validation set: Average loss: 1.226203, Accuracy: 587/1050 (56%)

Epoch: 18
Training set [0/6430 (0%)] Loss: 1.026503
Training set [5120/6430 (77%)] Loss: 0.906645
Training set: Average loss: 0.948475
Training set: Average accuracy: 62.35%
Validation set: Average loss: 1.039331, Accuracy: 662/1050 (63%)

Epoch: 19
Training set [0/6430 (0%)] Loss: 0.906942
Training set [5120/6430 (77%)] Loss: 0.908594
Training set: Average loss: 0.892388
Training set: Average accuracy: 64.14%
Validation set: Average loss: 0.987475, Accuracy: 674/1050 (64%)

Epoch: 20
Training set [0/6430 (0%)] Loss: 0.840473
Training set [5120/6430 (77%)] Loss: 0.931450
Training set: Average loss: 0.884549
Training set: Average accuracy: 64.49%
Validation set: Average loss: 0.825028, Accuracy: 702/1050 (67%)

Epoch: 21
Training set [0/6430 (0%)] Loss: 0.876985
Training set [5120/6430 (77%)] Loss: 0.814866
Training set: Average loss: 0.852888
Training set: Average accuracy: 64.93%
Validation set: Average loss: 0.904652, Accuracy: 665/1050 (63%)

Epoch: 22
Training set [0/6430 (0%)] Loss: 0.806846
Training set [5120/6430 (77%)] Loss: 0.832632
Training set: Average loss: 0.823967
Training set: Average accuracy: 66.52%
Validation set: Average loss: 0.847836, Accuracy: 720/1050 (69%)

Epoch: 23
Training set [0/6430 (0%)] Loss: 0.821357
Training set [5120/6430 (77%)] Loss: 0.762954
Training set: Average loss: 0.815522
Training set: Average accuracy: 66.73%
Validation set: Average loss: 0.835419, Accuracy: 745/1050 (71%)

Epoch: 24
Training set [0/6430 (0%)] Loss: 0.805787
Training set [5120/6430 (77%)] Loss: 0.780898
Training set: Average loss: 0.789486
Training set: Average accuracy: 67.23%
Validation set: Average loss: 0.769862, Accuracy: 752/1050 (72%)

Epoch: 25
Training set [0/6430 (0%)] Loss: 0.740651
Training set [5120/6430 (77%)] Loss: 0.704599
Training set: Average loss: 0.771656
Training set: Average accuracy: 68.68%
Validation set: Average loss: 0.806844, Accuracy: 706/1050 (67%)

Epoch: 26
Training set [0/6430 (0%)] Loss: 0.715909
Training set [5120/6430 (77%)] Loss: 0.780494
Training set: Average loss: 0.751851
Training set: Average accuracy: 69.44%
Validation set: Average loss: 0.807208, Accuracy: 715/1050 (68%)

Epoch: 27
Training set [0/6430 (0%)] Loss: 0.727052
Training set [5120/6430 (77%)] Loss: 0.775243
Training set: Average loss: 0.743102
Training set: Average accuracy: 70.19%
Validation set: Average loss: 0.760417, Accuracy: 741/1050 (71%)

Epoch: 28
Training set [0/6430 (0%)] Loss: 0.746058
Training set [5120/6430 (77%)] Loss: 0.743169
Training set: Average loss: 0.719664
Training set: Average accuracy: 70.56%
Validation set: Average loss: 0.664055, Accuracy: 781/1050 (74%)

Epoch: 29
Training set [0/6430 (0%)] Loss: 0.712073
Training set [5120/6430 (77%)] Loss: 0.640149
Training set: Average loss: 0.688820
Training set: Average accuracy: 71.87%
Validation set: Average loss: 0.907725, Accuracy: 678/1050 (65%)

Epoch: 30
Training set [0/6430 (0%)] Loss: 0.720910
Training set [5120/6430 (77%)] Loss: 0.612826
Training set: Average loss: 0.685783
Training set: Average accuracy: 71.09%
Validation set: Average loss: 0.908916, Accuracy: 707/1050 (67%)

Epoch: 31
Training set [0/6430 (0%)] Loss: 0.678764
Training set [5120/6430 (77%)] Loss: 0.698021
Training set: Average loss: 0.669802
Training set: Average accuracy: 72.02%
Validation set: Average loss: 0.790521, Accuracy: 744/1050 (71%)

Epoch: 32
Training set [0/6430 (0%)] Loss: 0.683122
Training set [5120/6430 (77%)] Loss: 0.719554
Training set: Average loss: 0.689636
Training set: Average accuracy: 71.48%
Validation set: Average loss: 1.717193, Accuracy: 560/1050 (53%)

Epoch: 33
Training set [0/6430 (0%)] Loss: 0.636574
Training set [5120/6430 (77%)] Loss: 0.649442
Training set: Average loss: 0.658385
Training set: Average accuracy: 72.63%
Validation set: Average loss: 0.702163, Accuracy: 773/1050 (74%)

Epoch: 34
Training set [0/6430 (0%)] Loss: 0.580293
Training set [5120/6430 (77%)] Loss: 0.642827
Training set: Average loss: 0.636107
Training set: Average accuracy: 74.12%
Validation set: Average loss: 0.654746, Accuracy: 780/1050 (74%)

Epoch: 35
Training set [0/6430 (0%)] Loss: 0.629046
Training set [5120/6430 (77%)] Loss: 0.614235
Training set: Average loss: 0.639886
Training set: Average accuracy: 73.67%
Validation set: Average loss: 0.742234, Accuracy: 734/1050 (70%)

Epoch: 36
Training set [0/6430 (0%)] Loss: 0.632025
Training set [5120/6430 (77%)] Loss: 0.586178
Training set: Average loss: 0.612812
Training set: Average accuracy: 74.56%
Validation set: Average loss: 0.969987, Accuracy: 692/1050 (66%)

Epoch: 37
Training set [0/6430 (0%)] Loss: 0.579468
Training set [5120/6430 (77%)] Loss: 0.567687
Training set: Average loss: 0.588017
Training set: Average accuracy: 75.26%
Validation set: Average loss: 0.780190, Accuracy: 764/1050 (73%)

Epoch: 38
Training set [0/6430 (0%)] Loss: 0.585619
Training set [5120/6430 (77%)] Loss: 0.583668
Training set: Average loss: 0.582162
Training set: Average accuracy: 75.44%
Validation set: Average loss: 0.713033, Accuracy: 765/1050 (73%)

Epoch: 39
Training set [0/6430 (0%)] Loss: 0.577412
Training set [5120/6430 (77%)] Loss: 0.601605
Training set: Average loss: 0.603185
Training set: Average accuracy: 74.71%
Validation set: Average loss: 0.645712, Accuracy: 784/1050 (75%)

Epoch: 40
Training set [0/6430 (0%)] Loss: 0.617417
Training set [5120/6430 (77%)] Loss: 0.576746
Training set: Average loss: 0.574621
Training set: Average accuracy: 75.74%
Validation set: Average loss: 0.710616, Accuracy: 761/1050 (72%)

Epoch: 41
Training set [0/6430 (0%)] Loss: 0.527284
Training set [5120/6430 (77%)] Loss: 0.590365
Training set: Average loss: 0.579110
Training set: Average accuracy: 75.83%
Validation set: Average loss: 0.721330, Accuracy: 750/1050 (71%)

Epoch: 42
Training set [0/6430 (0%)] Loss: 0.513598
Training set [5120/6430 (77%)] Loss: 0.541217
Training set: Average loss: 0.524475
Training set: Average accuracy: 77.84%
Validation set: Average loss: 0.618753, Accuracy: 796/1050 (76%)

Epoch: 43
Training set [0/6430 (0%)] Loss: 0.550398
Training set [5120/6430 (77%)] Loss: 0.560368
Training set: Average loss: 0.536760
Training set: Average accuracy: 77.62%
Validation set: Average loss: 0.720575, Accuracy: 766/1050 (73%)

Epoch: 44
Training set [0/6430 (0%)] Loss: 0.511268
Training set [5120/6430 (77%)] Loss: 0.529220
Training set: Average loss: 0.536538
Training set: Average accuracy: 77.48%
Validation set: Average loss: 0.672221, Accuracy: 773/1050 (74%)

Epoch: 45
Training set [0/6430 (0%)] Loss: 0.552989
Training set [5120/6430 (77%)] Loss: 0.559475
Training set: Average loss: 0.545948
Training set: Average accuracy: 77.31%
Validation set: Average loss: 0.861342, Accuracy: 751/1050 (72%)

Epoch: 46
Training set [0/6430 (0%)] Loss: 0.474291
Training set [5120/6430 (77%)] Loss: 0.531324
Training set: Average loss: 0.542441
Training set: Average accuracy: 77.37%
Validation set: Average loss: 0.872656, Accuracy: 735/1050 (70%)

Epoch: 47
Training set [0/6430 (0%)] Loss: 0.520757
Training set [5120/6430 (77%)] Loss: 0.499204
Training set: Average loss: 0.526825
Training set: Average accuracy: 78.21%
Validation set: Average loss: 0.859321, Accuracy: 772/1050 (74%)

Epoch: 48
Training set [0/6430 (0%)] Loss: 0.591286
Training set [5120/6430 (77%)] Loss: 0.501189
Training set: Average loss: 0.515793
Training set: Average accuracy: 78.26%
Validation set: Average loss: 0.652914, Accuracy: 793/1050 (76%)

Epoch: 49
Training set [0/6430 (0%)] Loss: 0.506935
Training set [5120/6430 (77%)] Loss: 0.526826
Training set: Average loss: 0.501753
Training set: Average accuracy: 79.04%
Validation set: Average loss: 0.741817, Accuracy: 790/1050 (75%)

Epoch: 50
Training set [0/6430 (0%)] Loss: 0.430523
Training set [5120/6430 (77%)] Loss: 0.491801
Training set: Average loss: 0.498723
Training set: Average accuracy: 78.76%
Validation set: Average loss: 0.668586, Accuracy: 775/1050 (74%)

Epoch: 51
Training set [0/6430 (0%)] Loss: 0.503757
Training set [5120/6430 (77%)] Loss: 0.481300
Training set: Average loss: 0.480807
Training set: Average accuracy: 79.08%
Validation set: Average loss: 0.605246, Accuracy: 797/1050 (76%)

Epoch: 52
Training set [0/6430 (0%)] Loss: 0.485044
Training set [5120/6430 (77%)] Loss: 0.453201
Training set: Average loss: 0.465858
Training set: Average accuracy: 80.31%
Validation set: Average loss: 0.635759, Accuracy: 815/1050 (78%)

Epoch: 53
Training set [0/6430 (0%)] Loss: 0.509581
Training set [5120/6430 (77%)] Loss: 0.435284
Training set: Average loss: 0.466133
Training set: Average accuracy: 80.37%
Validation set: Average loss: 0.609681, Accuracy: 816/1050 (78%)

Epoch: 54
Training set [0/6430 (0%)] Loss: 0.451593
Training set [5120/6430 (77%)] Loss: 0.486579
Training set: Average loss: 0.453006
Training set: Average accuracy: 80.86%
Validation set: Average loss: 0.818597, Accuracy: 773/1050 (74%)

Epoch: 55
Training set [0/6430 (0%)] Loss: 0.449864
Training set [5120/6430 (77%)] Loss: 0.472625
Training set: Average loss: 0.458367
Training set: Average accuracy: 81.15%
Validation set: Average loss: 0.789579, Accuracy: 770/1050 (73%)

Epoch: 56
Training set [0/6430 (0%)] Loss: 0.445907
Training set [5120/6430 (77%)] Loss: 0.513732
Training set: Average loss: 0.455040
Training set: Average accuracy: 80.86%
Validation set: Average loss: 0.560246, Accuracy: 814/1050 (78%)

Epoch: 57
Training set [0/6430 (0%)] Loss: 0.443904
Training set [5120/6430 (77%)] Loss: 0.473150
Training set: Average loss: 0.451107
Training set: Average accuracy: 80.03%
Validation set: Average loss: 0.941617, Accuracy: 759/1050 (72%)

Epoch: 58
Training set [0/6430 (0%)] Loss: 0.427546
Training set [5120/6430 (77%)] Loss: 0.519833
Training set: Average loss: 0.481772
Training set: Average accuracy: 79.52%
Validation set: Average loss: 0.599009, Accuracy: 815/1050 (78%)

Epoch: 59
Training set [0/6430 (0%)] Loss: 0.456959
Training set [5120/6430 (77%)] Loss: 0.508296
Training set: Average loss: 0.465909
Training set: Average accuracy: 79.88%
Validation set: Average loss: 0.602336, Accuracy: 803/1050 (76%)

Epoch: 60
Training set [0/6430 (0%)] Loss: 0.560965
Training set [5120/6430 (77%)] Loss: 0.463412
Training set: Average loss: 0.452866
Training set: Average accuracy: 80.54%
Validation set: Average loss: 0.639212, Accuracy: 817/1050 (78%)

Epoch: 61
Training set [0/6430 (0%)] Loss: 0.445252
Training set [5120/6430 (77%)] Loss: 0.458178
Training set: Average loss: 0.425296
Training set: Average accuracy: 81.57%
Validation set: Average loss: 0.566638, Accuracy: 830/1050 (79%)

Epoch: 62
Training set [0/6430 (0%)] Loss: 0.403010
Training set [5120/6430 (77%)] Loss: 0.418274
Training set: Average loss: 0.427019
Training set: Average accuracy: 81.94%
Validation set: Average loss: 0.629762, Accuracy: 806/1050 (77%)

Epoch: 63
Training set [0/6430 (0%)] Loss: 0.417350
Training set [5120/6430 (77%)] Loss: 0.426722
Training set: Average loss: 0.427681
Training set: Average accuracy: 82.16%
Validation set: Average loss: 0.562804, Accuracy: 821/1050 (78%)

Epoch: 64
Training set [0/6430 (0%)] Loss: 0.466054
Training set [5120/6430 (77%)] Loss: 0.390685
Training set: Average loss: 0.409150
Training set: Average accuracy: 82.67%
Validation set: Average loss: 0.739379, Accuracy: 785/1050 (75%)

Epoch: 65
Training set [0/6430 (0%)] Loss: 0.450027
Training set [5120/6430 (77%)] Loss: 0.497432
Training set: Average loss: 0.449252
Training set: Average accuracy: 81.23%
Validation set: Average loss: 0.641421, Accuracy: 796/1050 (76%)

Epoch: 66
Training set [0/6430 (0%)] Loss: 0.333036
Training set [5120/6430 (77%)] Loss: 0.378718
Training set: Average loss: 0.407573
Training set: Average accuracy: 82.64%
Validation set: Average loss: 0.622691, Accuracy: 825/1050 (79%)

Epoch: 67
Training set [0/6430 (0%)] Loss: 0.446812
Training set [5120/6430 (77%)] Loss: 0.425850
Training set: Average loss: 0.424127
Training set: Average accuracy: 82.66%
Validation set: Average loss: 0.649725, Accuracy: 809/1050 (77%)

Epoch: 68
Training set [0/6430 (0%)] Loss: 0.395477
Training set [5120/6430 (77%)] Loss: 0.435018
Training set: Average loss: 0.409932
Training set: Average accuracy: 82.55%
Validation set: Average loss: 0.610077, Accuracy: 814/1050 (78%)

Epoch: 69
Training set [0/6430 (0%)] Loss: 0.451465
Training set [5120/6430 (77%)] Loss: 0.387087
Training set: Average loss: 0.408335
Training set: Average accuracy: 82.49%
Validation set: Average loss: 0.731221, Accuracy: 789/1050 (75%)

Epoch: 70
Training set [0/6430 (0%)] Loss: 0.386265
Training set [5120/6430 (77%)] Loss: 0.421002
Training set: Average loss: 0.407524
Training set: Average accuracy: 81.82%
Validation set: Average loss: 0.711361, Accuracy: 787/1050 (75%)

Epoch: 71
Training set [0/6430 (0%)] Loss: 0.395405
Training set [5120/6430 (77%)] Loss: 0.375483
Training set: Average loss: 0.388312
Training set: Average accuracy: 83.33%
Validation set: Average loss: 0.645511, Accuracy: 822/1050 (78%)

Epoch: 72
Training set [0/6430 (0%)] Loss: 0.443656
Training set [5120/6430 (77%)] Loss: 0.397313
Training set: Average loss: 0.406748
Training set: Average accuracy: 82.15%
Validation set: Average loss: 0.901165, Accuracy: 769/1050 (73%)

Epoch: 73
Training set [0/6430 (0%)] Loss: 0.393761
Training set [5120/6430 (77%)] Loss: 0.399456
Training set: Average loss: 0.382095
Training set: Average accuracy: 83.56%
Validation set: Average loss: 1.537082, Accuracy: 660/1050 (63%)

Epoch: 74
Training set [0/6430 (0%)] Loss: 0.388532
Training set [5120/6430 (77%)] Loss: 0.399577
Training set: Average loss: 0.376082
Training set: Average accuracy: 83.51%
Validation set: Average loss: 0.615491, Accuracy: 804/1050 (77%)

Epoch: 75
Training set [0/6430 (0%)] Loss: 0.396751
Training set [5120/6430 (77%)] Loss: 0.425376
Training set: Average loss: 0.394591
Training set: Average accuracy: 83.48%
Validation set: Average loss: 0.658686, Accuracy: 832/1050 (79%)

Epoch: 76
Training set [0/6430 (0%)] Loss: 0.374692
Training set [5120/6430 (77%)] Loss: 0.391278
Training set: Average loss: 0.388315
Training set: Average accuracy: 83.45%
Validation set: Average loss: 0.693829, Accuracy: 814/1050 (78%)

Epoch: 77
Training set [0/6430 (0%)] Loss: 0.376408
Training set [5120/6430 (77%)] Loss: 0.516403
Training set: Average loss: 0.408485
Training set: Average accuracy: 82.86%
Validation set: Average loss: 0.800403, Accuracy: 809/1050 (77%)

Epoch: 78
Training set [0/6430 (0%)] Loss: 0.368891
Training set [5120/6430 (77%)] Loss: 0.397691
Training set: Average loss: 0.383049
Training set: Average accuracy: 83.44%
Validation set: Average loss: 1.572876, Accuracy: 644/1050 (61%)

Epoch: 79
Training set [0/6430 (0%)] Loss: 0.465496
Training set [5120/6430 (77%)] Loss: 0.393414
Training set: Average loss: 0.387755
Training set: Average accuracy: 83.50%
Validation set: Average loss: 0.853384, Accuracy: 782/1050 (74%)

Epoch: 80
Training set [0/6430 (0%)] Loss: 0.377683
Training set [5120/6430 (77%)] Loss: 0.397660
Training set: Average loss: 0.378962
Training set: Average accuracy: 83.81%
Validation set: Average loss: 0.691795, Accuracy: 811/1050 (77%)

Epoch: 81
Training set [0/6430 (0%)] Loss: 0.312504
Training set [5120/6430 (77%)] Loss: 0.329852
Training set: Average loss: 0.366795
Training set: Average accuracy: 84.18%
Validation set: Average loss: 0.710286, Accuracy: 806/1050 (77%)

Epoch: 82
Training set [0/6430 (0%)] Loss: 0.334718
Training set [5120/6430 (77%)] Loss: 0.391046
Training set: Average loss: 0.378957
Training set: Average accuracy: 84.31%
Validation set: Average loss: 0.785183, Accuracy: 808/1050 (77%)

Epoch: 83
Training set [0/6430 (0%)] Loss: 0.398398
Training set [5120/6430 (77%)] Loss: 0.364799
Training set: Average loss: 0.367342
Training set: Average accuracy: 84.48%
Validation set: Average loss: 0.728491, Accuracy: 797/1050 (76%)

Epoch: 84
Training set [0/6430 (0%)] Loss: 0.342906
Training set [5120/6430 (77%)] Loss: 0.381244
Training set: Average loss: 0.357414
Training set: Average accuracy: 84.85%
Validation set: Average loss: 0.660608, Accuracy: 812/1050 (77%)

Epoch: 85
Training set [0/6430 (0%)] Loss: 0.347945
Training set [5120/6430 (77%)] Loss: 0.353628
Training set: Average loss: 0.358098
Training set: Average accuracy: 84.95%
Validation set: Average loss: 1.552842, Accuracy: 759/1050 (72%)

Epoch: 86
Training set [0/6430 (0%)] Loss: 0.353012
Training set [5120/6430 (77%)] Loss: 0.320377
Training set: Average loss: 0.359703
Training set: Average accuracy: 84.31%
Validation set: Average loss: 1.350705, Accuracy: 725/1050 (69%)

Epoch: 87
Training set [0/6430 (0%)] Loss: 0.355962
Training set [5120/6430 (77%)] Loss: 0.368695
Training set: Average loss: 0.362978
Training set: Average accuracy: 84.40%
Validation set: Average loss: 0.580618, Accuracy: 830/1050 (79%)

Epoch: 88
Training set [0/6430 (0%)] Loss: 0.320412
Training set [5120/6430 (77%)] Loss: 0.369671
Training set: Average loss: 0.347058
Training set: Average accuracy: 84.96%
Validation set: Average loss: 0.800236, Accuracy: 808/1050 (77%)

Epoch: 89
Training set [0/6430 (0%)] Loss: 0.366597
Training set [5120/6430 (77%)] Loss: 0.329536
Training set: Average loss: 0.340964
Training set: Average accuracy: 85.47%
Validation set: Average loss: 1.016442, Accuracy: 781/1050 (74%)

Epoch: 90
Training set [0/6430 (0%)] Loss: 0.319686
Training set [5120/6430 (77%)] Loss: 0.368552
Training set: Average loss: 0.338789
Training set: Average accuracy: 85.58%
Validation set: Average loss: 0.789159, Accuracy: 827/1050 (79%)

Epoch: 91
Training set [0/6430 (0%)] Loss: 0.404748
Training set [5120/6430 (77%)] Loss: 0.375560
Training set: Average loss: 0.351549
Training set: Average accuracy: 84.82%
Validation set: Average loss: 0.758266, Accuracy: 820/1050 (78%)

Epoch: 92
Training set [0/6430 (0%)] Loss: 0.339849
Training set [5120/6430 (77%)] Loss: 0.403577
Training set: Average loss: 0.370274
Training set: Average accuracy: 84.84%
Validation set: Average loss: 0.582703, Accuracy: 830/1050 (79%)

Epoch: 93
Training set [0/6430 (0%)] Loss: 0.342813
Training set [5120/6430 (77%)] Loss: 0.376167
Training set: Average loss: 0.330638
Training set: Average accuracy: 86.21%
Validation set: Average loss: 0.610717, Accuracy: 851/1050 (81%)

Epoch: 94
Training set [0/6430 (0%)] Loss: 0.273078
Training set [5120/6430 (77%)] Loss: 0.272012
Training set: Average loss: 0.322933
Training set: Average accuracy: 85.85%
Validation set: Average loss: 0.729423, Accuracy: 829/1050 (79%)

Epoch: 95
Training set [0/6430 (0%)] Loss: 0.333421
Training set [5120/6430 (77%)] Loss: 0.312311
Training set: Average loss: 0.320039
Training set: Average accuracy: 86.67%
Validation set: Average loss: 0.703463, Accuracy: 848/1050 (81%)

Epoch: 96
Training set [0/6430 (0%)] Loss: 0.355325
Training set [5120/6430 (77%)] Loss: 0.345262
Training set: Average loss: 0.324943
Training set: Average accuracy: 85.68%
Validation set: Average loss: 0.664607, Accuracy: 805/1050 (77%)

Epoch: 97
Training set [0/6430 (0%)] Loss: 0.379874
Training set [5120/6430 (77%)] Loss: 0.334560
Training set: Average loss: 0.331201
Training set: Average accuracy: 86.10%
Validation set: Average loss: 0.851691, Accuracy: 800/1050 (76%)

Epoch: 98
Training set [0/6430 (0%)] Loss: 0.326032
Training set [5120/6430 (77%)] Loss: 0.286437
Training set: Average loss: 0.321785
Training set: Average accuracy: 86.36%
Validation set: Average loss: 0.694044, Accuracy: 822/1050 (78%)

Epoch: 99
Training set [0/6430 (0%)] Loss: 0.337012
Training set [5120/6430 (77%)] Loss: 0.344883
Training set: Average loss: 0.327804
Training set: Average accuracy: 85.61%
Validation set: Average loss: 1.927549, Accuracy: 653/1050 (62%)

Epoch: 100
Training set [0/6430 (0%)] Loss: 0.326834
Training set [5120/6430 (77%)] Loss: 0.310351
Training set: Average loss: 0.322457
Training set: Average accuracy: 86.02%
Validation set: Average loss: 0.670664, Accuracy: 835/1050 (80%)

Epoch: 101
Training set [0/6430 (0%)] Loss: 0.379562
Training set [5120/6430 (77%)] Loss: 0.291574
Training set: Average loss: 0.316798
Training set: Average accuracy: 86.53%
Validation set: Average loss: 0.642645, Accuracy: 831/1050 (79%)

Epoch: 102
Training set [0/6430 (0%)] Loss: 0.394502
Training set [5120/6430 (77%)] Loss: 0.333883
Training set: Average loss: 0.322914
Training set: Average accuracy: 86.22%
Validation set: Average loss: 0.640605, Accuracy: 826/1050 (79%)

Epoch: 103
Training set [0/6430 (0%)] Loss: 0.346426
Training set [5120/6430 (77%)] Loss: 0.332331
Training set: Average loss: 0.344179
Training set: Average accuracy: 84.90%
Validation set: Average loss: 0.652313, Accuracy: 814/1050 (78%)

Epoch: 104
Training set [0/6430 (0%)] Loss: 0.325225
Training set [5120/6430 (77%)] Loss: 0.262644
Training set: Average loss: 0.321338
Training set: Average accuracy: 86.31%
Validation set: Average loss: 0.603760, Accuracy: 855/1050 (81%)

Epoch: 105
Training set [0/6430 (0%)] Loss: 0.296435
Training set [5120/6430 (77%)] Loss: 0.306089
Training set: Average loss: 0.318096
Training set: Average accuracy: 86.63%
Validation set: Average loss: 0.680587, Accuracy: 831/1050 (79%)

Epoch: 106
Training set [0/6430 (0%)] Loss: 0.279420
Training set [5120/6430 (77%)] Loss: 0.314748
Training set: Average loss: 0.316251
Training set: Average accuracy: 86.10%
Validation set: Average loss: 0.590003, Accuracy: 839/1050 (80%)

Epoch: 107
Training set [0/6430 (0%)] Loss: 0.368218
Training set [5120/6430 (77%)] Loss: 0.343066
Training set: Average loss: 0.312654
Training set: Average accuracy: 86.35%
Validation set: Average loss: 0.659392, Accuracy: 831/1050 (79%)

Epoch: 108
Training set [0/6430 (0%)] Loss: 0.317218
Training set [5120/6430 (77%)] Loss: 0.320436
Training set: Average loss: 0.309991
Training set: Average accuracy: 87.05%
Validation set: Average loss: 1.353407, Accuracy: 750/1050 (71%)

Epoch: 109
Training set [0/6430 (0%)] Loss: 0.316297
Training set [5120/6430 (77%)] Loss: 0.299871
Training set: Average loss: 0.291831
Training set: Average accuracy: 87.43%
Validation set: Average loss: 0.671033, Accuracy: 836/1050 (80%)

Epoch: 110
Training set [0/6430 (0%)] Loss: 0.245914
Training set [5120/6430 (77%)] Loss: 0.281000
Training set: Average loss: 0.291145
Training set: Average accuracy: 87.50%
Validation set: Average loss: 0.969860, Accuracy: 798/1050 (76%)

Epoch: 111
Training set [0/6430 (0%)] Loss: 0.319155
Training set [5120/6430 (77%)] Loss: 0.305226
Training set: Average loss: 0.313310
Training set: Average accuracy: 86.64%
Validation set: Average loss: 0.761924, Accuracy: 815/1050 (78%)

Epoch: 112
Training set [0/6430 (0%)] Loss: 0.335253
Training set [5120/6430 (77%)] Loss: 0.312559
Training set: Average loss: 0.305502
Training set: Average accuracy: 87.01%
Validation set: Average loss: 0.847390, Accuracy: 805/1050 (77%)

Epoch: 113
Training set [0/6430 (0%)] Loss: 0.335034
Training set [5120/6430 (77%)] Loss: 0.323313
Training set: Average loss: 0.322300
Training set: Average accuracy: 86.49%
Validation set: Average loss: 1.170661, Accuracy: 731/1050 (70%)

Epoch: 114
Training set [0/6430 (0%)] Loss: 0.249831
Training set [5120/6430 (77%)] Loss: 0.271405
Training set: Average loss: 0.297634
Training set: Average accuracy: 87.22%
Validation set: Average loss: 0.683766, Accuracy: 815/1050 (78%)

Epoch: 115
Training set [0/6430 (0%)] Loss: 0.312935
Training set [5120/6430 (77%)] Loss: 0.266702
Training set: Average loss: 0.278656
Training set: Average accuracy: 87.78%
Validation set: Average loss: 0.756936, Accuracy: 814/1050 (78%)

Epoch: 116
Training set [0/6430 (0%)] Loss: 0.233891
Training set [5120/6430 (77%)] Loss: 0.294987
Training set: Average loss: 0.299518
Training set: Average accuracy: 87.00%
Validation set: Average loss: 0.653789, Accuracy: 838/1050 (80%)

Epoch: 117
Training set [0/6430 (0%)] Loss: 0.274013
Training set [5120/6430 (77%)] Loss: 0.263217
Training set: Average loss: 0.287370
Training set: Average accuracy: 88.26%
Validation set: Average loss: 0.756814, Accuracy: 813/1050 (77%)

Epoch: 118
Training set [0/6430 (0%)] Loss: 0.246477
Training set [5120/6430 (77%)] Loss: 0.292494
Training set: Average loss: 0.275937
Training set: Average accuracy: 88.54%
Validation set: Average loss: 0.731105, Accuracy: 853/1050 (81%)

Epoch: 119
Training set [0/6430 (0%)] Loss: 0.285587
Training set [5120/6430 (77%)] Loss: 0.289767
Training set: Average loss: 0.285625
Training set: Average accuracy: 87.84%
Validation set: Average loss: 0.758967, Accuracy: 823/1050 (78%)

Epoch: 120
Training set [0/6430 (0%)] Loss: 0.263597
Training set [5120/6430 (77%)] Loss: 0.288444
Training set: Average loss: 0.271073
Training set: Average accuracy: 88.72%
Validation set: Average loss: 1.059258, Accuracy: 777/1050 (74%)

Epoch: 121
Training set [0/6430 (0%)] Loss: 0.281754
Training set [5120/6430 (77%)] Loss: 0.267320
Training set: Average loss: 0.281774
Training set: Average accuracy: 87.87%
Validation set: Average loss: 0.597379, Accuracy: 838/1050 (80%)

Epoch: 122
Training set [0/6430 (0%)] Loss: 0.249642
Training set [5120/6430 (77%)] Loss: 0.266250
Training set: Average loss: 0.268740
Training set: Average accuracy: 88.62%
Validation set: Average loss: 0.768447, Accuracy: 819/1050 (78%)

Epoch: 123
Training set [0/6430 (0%)] Loss: 0.240177
Training set [5120/6430 (77%)] Loss: 0.258827
Training set: Average loss: 0.268529
Training set: Average accuracy: 88.62%
Validation set: Average loss: 0.739402, Accuracy: 836/1050 (80%)

Epoch: 124
Training set [0/6430 (0%)] Loss: 0.329074
Training set [5120/6430 (77%)] Loss: 0.236728
Training set: Average loss: 0.274512
Training set: Average accuracy: 88.32%
Validation set: Average loss: 0.691252, Accuracy: 854/1050 (81%)

Epoch: 125
Training set [0/6430 (0%)] Loss: 0.263117
Training set [5120/6430 (77%)] Loss: 0.241583
Training set: Average loss: 0.252257
Training set: Average accuracy: 89.21%
Validation set: Average loss: 0.656410, Accuracy: 830/1050 (79%)

Epoch: 126
Training set [0/6430 (0%)] Loss: 0.284193
Training set [5120/6430 (77%)] Loss: 0.243195
Training set: Average loss: 0.265857
Training set: Average accuracy: 88.29%
Validation set: Average loss: 0.754114, Accuracy: 832/1050 (79%)

Epoch: 127
Training set [0/6430 (0%)] Loss: 0.266226
Training set [5120/6430 (77%)] Loss: 0.304527
Training set: Average loss: 0.282089
Training set: Average accuracy: 87.84%
Validation set: Average loss: 0.823819, Accuracy: 840/1050 (80%)

Epoch: 128
Training set [0/6430 (0%)] Loss: 0.259668
Training set [5120/6430 (77%)] Loss: 0.278632
Training set: Average loss: 0.266925
Training set: Average accuracy: 88.62%
Validation set: Average loss: 1.741522, Accuracy: 704/1050 (67%)

Epoch: 129
Training set [0/6430 (0%)] Loss: 0.233954
Training set [5120/6430 (77%)] Loss: 0.261688
Training set: Average loss: 0.270260
Training set: Average accuracy: 88.57%
Validation set: Average loss: 0.718731, Accuracy: 820/1050 (78%)

Epoch: 130
Training set [0/6430 (0%)] Loss: 0.239955
Training set [5120/6430 (77%)] Loss: 0.287695
Training set: Average loss: 0.274280
Training set: Average accuracy: 88.49%
Validation set: Average loss: 0.655037, Accuracy: 843/1050 (80%)

Epoch: 131
Training set [0/6430 (0%)] Loss: 0.236949
Training set [5120/6430 (77%)] Loss: 0.273851
Training set: Average loss: 0.262293
Training set: Average accuracy: 88.54%
Validation set: Average loss: 0.643185, Accuracy: 833/1050 (79%)

Epoch: 132
Training set [0/6430 (0%)] Loss: 0.326844
Training set [5120/6430 (77%)] Loss: 0.301667
Training set: Average loss: 0.275500
Training set: Average accuracy: 88.41%
Validation set: Average loss: 0.655257, Accuracy: 844/1050 (80%)

Epoch: 133
Training set [0/6430 (0%)] Loss: 0.291851
Training set [5120/6430 (77%)] Loss: 0.235916
Training set: Average loss: 0.258312
Training set: Average accuracy: 89.16%
Validation set: Average loss: 0.802074, Accuracy: 830/1050 (79%)

Epoch: 134
Training set [0/6430 (0%)] Loss: 0.304101
Training set [5120/6430 (77%)] Loss: 0.238160
Training set: Average loss: 0.281820
Training set: Average accuracy: 88.10%
Validation set: Average loss: 0.642074, Accuracy: 846/1050 (81%)

Epoch: 135
Training set [0/6430 (0%)] Loss: 0.236908
Training set [5120/6430 (77%)] Loss: 0.310182
Training set: Average loss: 0.273259
Training set: Average accuracy: 88.15%
Validation set: Average loss: 0.986295, Accuracy: 806/1050 (77%)

Early stopping: no improvement for 10 epochs
ImprovedNetLite
training_loss -- validation_loss
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135]
[2.831051909006559, 1.856439003577599, 1.793393951195937, 1.7145697703728309, 1.6312854473407452, 1.577872789823092, 1.5421478289824266, 1.4670772827588594, 1.414986903850849, 1.3432356761052058, 1.2996566754121046, 1.2366911264566274, 1.1949665179619422, 1.1244476300019484, 1.0961053371429443, 1.0550565719604492, 1.0201504138799815, 0.9911600397183344, 0.9484754021351154, 0.8923882291867182, 0.884548558638646, 0.8528882127541763, 0.8239669708105234, 0.8155216666368338, 0.78948575258255, 0.7716559996971717, 0.7518507150503305, 0.7431023441828214, 0.7196637437893794, 0.6888200961626493, 0.6857834412501409, 0.669802399782034, 0.68963623046875, 0.658385496873122, 0.6361070779653696, 0.6398860399539654, 0.6128120789161096, 0.5880172069256122, 0.5821619904958285, 0.6031849063359774, 0.5746206045150757, 0.5791101272289569, 0.5244754965488727, 0.536760016129567, 0.5365376793421232, 0.5459482669830322, 0.5424406941120441, 0.5268248182076675, 0.5157933831214905, 0.5017530367924616, 0.49872265870754534, 0.48080735710951, 0.465858152279487, 0.4661332689798795, 0.4530057150584001, 0.45836689609747666, 0.4550395378699669, 0.45110666981110203, 0.4817715401832874, 0.4659089629466717, 0.4528656051709102, 0.4252962745152987, 0.42701931870900667, 0.42768145295289844, 0.4091495688144977, 0.4492517297084515, 0.4075727898340959, 0.4241271110681387, 0.4099323566143329, 0.4083354404339424, 0.40752397592251116, 0.388311716226431, 0.4067484392569615, 0.38209473399015575, 0.3760817348957062, 0.3945909348817972, 0.38831467582629275, 0.4084849265905527, 0.3830488920211792, 0.38775532979231614, 0.37896175338671756, 0.3667953106073233, 0.37895657466008115, 0.3673420181641212, 0.35741448402404785, 0.3580977526994852, 0.3597028828584231, 0.36297751848514265, 0.34705788126358617, 0.34096436087901777, 0.3387889862060547, 0.35154881844153774, 0.370273626767672, 0.3306378905589764, 0.32293269955194914, 0.32003931357310367, 0.3249431619277367, 0.33120072804964507, 0.321784923856075, 0.327803740134606, 0.3224568756727072, 0.3167984691949991, 0.32291393555127657, 0.34417853217858535, 0.3213376998901367, 0.3180956748815683, 0.3162512481212616, 0.31265372267136204, 0.3099914055604201, 0.29183053970336914, 0.2911451860116078, 0.3133097749490004, 0.30550150458629316, 0.3222995446278499, 0.29763382558639234, 0.2786559061362193, 0.2995178561944228, 0.2873696478513571, 0.2759365611351453, 0.2856249580016503, 0.27107266852488887, 0.28177410478775317, 0.2687403869170409, 0.2685294598340988, 0.2745116834457104, 0.25225683473623717, 0.26585714977521163, 0.2820886213045854, 0.26692461852843946, 0.2702600635015048, 0.27427979845267075, 0.26229326541607195, 0.27550020470069003, 0.25831204423537624, 0.2818202250278913, 0.2732592477248265]
[1.9526694615681965, 2.1545232137044272, 2.027926961580912, 2.0519466400146484, 1.7900465726852417, 1.666887879371643, 1.6261831919352214, 1.5581088066101074, 1.6880776087443035, 1.7686315774917603, 1.4577054182688396, 1.2567272981007893, 1.4634519418080647, 1.0984488725662231, 1.6205602486928303, 1.1830814679463704, 0.8886729876200358, 1.2262027263641357, 1.0393311977386475, 0.9874751369158427, 0.8250281612078348, 0.9046522974967957, 0.8478364944458008, 0.8354188998540243, 0.7698619564374288, 0.8068437973658243, 0.8072081406911215, 0.7604169448216757, 0.6640551686286926, 0.9077246288458506, 0.9089158972104391, 0.7905210653940836, 1.7171932856241863, 0.7021634578704834, 0.6547464231650034, 0.7422340909639994, 0.9699865778287252, 0.7801903684933981, 0.7130333085854849, 0.6457120875517527, 0.7106156647205353, 0.7213298181692759, 0.6187529265880585, 0.7205749352773031, 0.67222099006176, 0.8613417943318685, 0.8726561466852824, 0.8593210975329081, 0.6529144843419393, 0.7418168485164642, 0.6685859759648641, 0.6052457988262177, 0.6357593238353729, 0.6096808165311813, 0.8185970187187195, 0.7895790139834086, 0.5602461273471514, 0.9416166345278422, 0.5990086731811365, 0.6023362030585607, 0.6392122209072113, 0.5666383653879166, 0.6297617057959238, 0.5628044257561365, 0.7393792519966761, 0.6414205009738604, 0.6226911793152491, 0.6497253278891245, 0.6100769340991974, 0.7312208910783132, 0.711361057125032, 0.6455112000306448, 0.9011649390061697, 1.5370817979176838, 0.6154912437001864, 0.6586856643358866, 0.693828746676445, 0.8004027406374613, 1.572876473267873, 0.8533838192621866, 0.6917948226133982, 0.7102856983741125, 0.7851833601792654, 0.7284908493359884, 0.6606082568566004, 1.5528415441513062, 1.3507046302159627, 0.5806184907754263, 0.800236165523529, 1.01644233862559, 0.7891587813695272, 0.7582660913467407, 0.5827034836014112, 0.6107165813446045, 0.7294230759143829, 0.703462541103363, 0.6646067922314008, 0.8516910771528879, 0.6940441032250723, 1.9275490045547485, 0.6706635598093271, 0.64264548321565, 0.6406054049730301, 0.6523127754529318, 0.6037600686152776, 0.6805872085193793, 0.5900030185778936, 0.6593920687834421, 1.3534066677093506, 0.671033134063085, 0.9698603749275208, 0.761924127737681, 0.847389817237854, 1.1706605851650238, 0.6837664917111397, 0.7569360683361689, 0.6537890533606211, 0.7568143705526987, 0.7311046322186788, 0.7589670419692993, 1.0592575073242188, 0.5973786016305288, 0.7684468477964401, 0.7394015391667684, 0.691251656661431, 0.656410406033198, 0.7541136940320333, 0.8238194386164347, 1.7415220737457275, 0.718730648358663, 0.6550368169943491, 0.6431852877140045, 0.65525700400273, 0.8020739356676737, 0.6420738299687704, 0.9862946371237437]
ImprovedNetLite
training_accuracy -- validation_accuracy
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135]
[18.3203732503888, 23.981337480559876, 27.12286158631415, 30.839813374805598, 34.914463452566096, 37.480559875583204, 39.766718506998444, 42.45723172628305, 44.758942457231726, 47.46500777604977, 48.98911353032659, 51.850699844479, 53.54587869362364, 56.236391912908246, 56.70295489891135, 58.55365474339036, 60.10886469673406, 60.10886469673406, 62.34836702954899, 64.13685847589424, 64.4945567651633, 64.93001555209953, 66.51632970451011, 66.73405909797823, 67.23172628304822, 68.67807153965785, 69.44012441679627, 70.18662519440124, 70.55987558320373, 71.86625194401245, 71.0886469673406, 72.02177293934682, 71.47744945567652, 72.62830482115085, 74.1213063763608, 73.67029548989113, 74.55676516329704, 75.25660964230171, 75.44323483670296, 74.71228615863141, 75.73872472783826, 75.83203732503888, 77.83825816485225, 77.62052877138413, 77.48055987558321, 77.3094867807154, 77.37169517884915, 78.21150855365474, 78.25816485225505, 79.0357698289269, 78.75583203732504, 79.08242612752721, 80.31104199066874, 80.37325038880249, 80.85536547433904, 81.15085536547434, 80.85536547433904, 80.03110419906687, 79.51788491446345, 79.8755832037325, 80.5443234836703, 81.57076205287714, 81.94401244167963, 82.16174183514775, 82.67496111975116, 81.22861586314153, 82.64385692068429, 82.65940902021772, 82.55054432348366, 82.48833592534993, 81.81959564541214, 83.32814930015552, 82.14618973561431, 83.56143079315707, 83.51477449455676, 83.48367029548989, 83.45256609642301, 82.8615863141524, 83.43701399688958, 83.49922239502332, 83.81026438569207, 84.18351477449455, 84.30793157076205, 84.47900466562986, 84.85225505443235, 84.94556765163297, 84.30793157076205, 84.40124416796267, 84.96111975116641, 85.47433903576983, 85.58320373250389, 84.82115085536547, 84.83670295489891, 86.20528771384137, 85.84758942457232, 86.67185069984448, 85.67651632970451, 86.09642301710731, 86.36080870917574, 85.61430793157076, 86.01866251944013, 86.53188180404355, 86.22083981337481, 84.89891135303266, 86.31415241057543, 86.62519440124417, 86.09642301710731, 86.3452566096423, 87.04510108864697, 87.4339035769829, 87.49611197511665, 86.64074650077761, 87.0139968895801, 86.48522550544324, 87.21617418351478, 87.7760497667185, 86.99844479004666, 88.25816485225505, 88.53810264385692, 87.83825816485225, 88.72472783825816, 87.86936236391912, 88.6158631415241, 88.6158631415241, 88.3203732503888, 89.20684292379471, 88.28926905132192, 87.83825816485225, 88.6158631415241, 88.56920684292379, 88.4914463452566, 88.53810264385692, 88.41368584758942, 89.1601866251944, 88.10264385692068, 88.14930015552099]
[14.571428571428571, 17.047619047619047, 21.904761904761905, 26.0, 36.76190476190476, 42.476190476190474, 43.904761904761905, 45.61904761904762, 44.19047619047619, 45.61904761904762, 50.666666666666664, 54.95238095238095, 49.42857142857143, 61.61904761904762, 50.857142857142854, 59.714285714285715, 62.0, 55.904761904761905, 63.04761904761905, 64.19047619047619, 66.85714285714286, 63.333333333333336, 68.57142857142857, 70.95238095238095, 71.61904761904762, 67.23809523809524, 68.0952380952381, 70.57142857142857, 74.38095238095238, 64.57142857142857, 67.33333333333333, 70.85714285714286, 53.333333333333336, 73.61904761904762, 74.28571428571429, 69.9047619047619, 65.9047619047619, 72.76190476190476, 72.85714285714286, 74.66666666666667, 72.47619047619048, 71.42857142857143, 75.80952380952381, 72.95238095238095, 73.61904761904762, 71.52380952380952, 70.0, 73.52380952380952, 75.52380952380952, 75.23809523809524, 73.80952380952381, 75.9047619047619, 77.61904761904762, 77.71428571428571, 73.61904761904762, 73.33333333333333, 77.52380952380952, 72.28571428571429, 77.61904761904762, 76.47619047619048, 77.80952380952381, 79.04761904761905, 76.76190476190476, 78.19047619047619, 74.76190476190476, 75.80952380952381, 78.57142857142857, 77.04761904761905, 77.52380952380952, 75.14285714285714, 74.95238095238095, 78.28571428571429, 73.23809523809524, 62.857142857142854, 76.57142857142857, 79.23809523809524, 77.52380952380952, 77.04761904761905, 61.333333333333336, 74.47619047619048, 77.23809523809524, 76.76190476190476, 76.95238095238095, 75.9047619047619, 77.33333333333333, 72.28571428571429, 69.04761904761905, 79.04761904761905, 76.95238095238095, 74.38095238095238, 78.76190476190476, 78.0952380952381, 79.04761904761905, 81.04761904761905, 78.95238095238095, 80.76190476190476, 76.66666666666667, 76.19047619047619, 78.28571428571429, 62.19047619047619, 79.52380952380952, 79.14285714285714, 78.66666666666667, 77.52380952380952, 81.42857142857143, 79.14285714285714, 79.9047619047619, 79.14285714285714, 71.42857142857143, 79.61904761904762, 76.0, 77.61904761904762, 76.66666666666667, 69.61904761904762, 77.61904761904762, 77.52380952380952, 79.80952380952381, 77.42857142857143, 81.23809523809524, 78.38095238095238, 74.0, 79.80952380952381, 78.0, 79.61904761904762, 81.33333333333333, 79.04761904761905, 79.23809523809524, 80.0, 67.04761904761905, 78.0952380952381, 80.28571428571429, 79.33333333333333, 80.38095238095238, 79.04761904761905, 80.57142857142857, 76.76190476190476]
model saved as model_store_512/cnn_car_ImprovedNetLite.pt
Getting predictions from test set...
ImprovedNetLite
[[133   0   0   0  15   2   0]
 [  3 115   0   0  12   9  11]
 [  6   9 101   1  12  11  10]
 [ 57   2   3  66   6  14   2]
 [  0   0   0   0 149   0   1]
 [ 10   5   0   3   8 118   6]
 [  0   8   1   0  15   2 124]]
Data loaders ready
=============================
BasicNet
=============================
Epoch: 0
Training set [0/6430 (0%)] Loss: 2.046719
Training set [4480/6430 (67%)] Loss: 1.889657
Training set: Average loss: 2.781096
Training set: Average accuracy: 18.43%
Validation set: Average loss: 1.924951, Accuracy: 165/1050 (16%)

Epoch: 1
Training set [0/6430 (0%)] Loss: 1.818494
Training set [4480/6430 (67%)] Loss: 1.791952
Training set: Average loss: 1.804163
Training set: Average accuracy: 28.09%
Validation set: Average loss: 1.777752, Accuracy: 191/1050 (18%)

Epoch: 2
Training set [0/6430 (0%)] Loss: 1.771533
Training set [4480/6430 (67%)] Loss: 1.733396
Training set: Average loss: 1.730088
Training set: Average accuracy: 31.87%
Validation set: Average loss: 1.682851, Accuracy: 366/1050 (35%)

Epoch: 3
Training set [0/6430 (0%)] Loss: 1.692627
Training set [4480/6430 (67%)] Loss: 1.614760
Training set: Average loss: 1.655616
Training set: Average accuracy: 34.18%
Validation set: Average loss: 1.630054, Accuracy: 421/1050 (40%)

Epoch: 4
Training set [0/6430 (0%)] Loss: 1.632595
Training set [4480/6430 (67%)] Loss: 1.568976
Training set: Average loss: 1.593906
Training set: Average accuracy: 36.64%
Validation set: Average loss: 1.615218, Accuracy: 432/1050 (41%)

Epoch: 5
Training set [0/6430 (0%)] Loss: 1.527494
Training set [4480/6430 (67%)] Loss: 1.550793
Training set: Average loss: 1.546738
Training set: Average accuracy: 38.43%
Validation set: Average loss: 1.551811, Accuracy: 466/1050 (44%)

Epoch: 6
Training set [0/6430 (0%)] Loss: 1.516447
Training set [4480/6430 (67%)] Loss: 1.483251
Training set: Average loss: 1.480840
Training set: Average accuracy: 41.31%
Validation set: Average loss: 1.439948, Accuracy: 506/1050 (48%)

Epoch: 7
Training set [0/6430 (0%)] Loss: 1.405306
Training set [4480/6430 (67%)] Loss: 1.348179
Training set: Average loss: 1.391052
Training set: Average accuracy: 44.96%
Validation set: Average loss: 1.405931, Accuracy: 502/1050 (48%)

Epoch: 8
Training set [0/6430 (0%)] Loss: 1.365637
Training set [4480/6430 (67%)] Loss: 1.367910
Training set: Average loss: 1.344655
Training set: Average accuracy: 47.01%
Validation set: Average loss: 1.477132, Accuracy: 464/1050 (44%)

Epoch: 9
Training set [0/6430 (0%)] Loss: 1.305655
Training set [4480/6430 (67%)] Loss: 1.309000
Training set: Average loss: 1.300746
Training set: Average accuracy: 48.88%
Validation set: Average loss: 1.254943, Accuracy: 555/1050 (53%)

Epoch: 10
Training set [0/6430 (0%)] Loss: 1.264930
Training set [4480/6430 (67%)] Loss: 1.231037
Training set: Average loss: 1.230192
Training set: Average accuracy: 51.82%
Validation set: Average loss: 1.241037, Accuracy: 579/1050 (55%)

Epoch: 11
Training set [0/6430 (0%)] Loss: 1.203593
Training set [4480/6430 (67%)] Loss: 1.173066
Training set: Average loss: 1.200002
Training set: Average accuracy: 52.36%
Validation set: Average loss: 1.139720, Accuracy: 628/1050 (60%)

Epoch: 12
Training set [0/6430 (0%)] Loss: 1.112357
Training set [4480/6430 (67%)] Loss: 1.125404
Training set: Average loss: 1.158804
Training set: Average accuracy: 55.47%
Validation set: Average loss: 4.192943, Accuracy: 230/1050 (22%)

Epoch: 13
Training set [0/6430 (0%)] Loss: 1.051673
Training set [4480/6430 (67%)] Loss: 1.065650
Training set: Average loss: 1.101734
Training set: Average accuracy: 57.45%
Validation set: Average loss: 1.102208, Accuracy: 636/1050 (61%)

Epoch: 14
Training set [0/6430 (0%)] Loss: 1.020915
Training set [4480/6430 (67%)] Loss: 1.124600
Training set: Average loss: 1.045354
Training set: Average accuracy: 58.77%
Validation set: Average loss: 1.054777, Accuracy: 654/1050 (62%)

Epoch: 15
Training set [0/6430 (0%)] Loss: 0.981917
Training set [4480/6430 (67%)] Loss: 0.956958
Training set: Average loss: 1.010334
Training set: Average accuracy: 60.14%
Validation set: Average loss: 1.053660, Accuracy: 637/1050 (61%)

Epoch: 16
Training set [0/6430 (0%)] Loss: 0.953332
Training set [4480/6430 (67%)] Loss: 0.916202
Training set: Average loss: 0.985851
Training set: Average accuracy: 60.79%
Validation set: Average loss: 2.564600, Accuracy: 364/1050 (35%)

Epoch: 17
Training set [0/6430 (0%)] Loss: 0.984886
Training set [4480/6430 (67%)] Loss: 0.962082
Training set: Average loss: 0.953847
Training set: Average accuracy: 62.89%
Validation set: Average loss: 0.951823, Accuracy: 697/1050 (66%)

Epoch: 18
Training set [0/6430 (0%)] Loss: 0.905405
Training set [4480/6430 (67%)] Loss: 0.865408
Training set: Average loss: 0.924691
Training set: Average accuracy: 63.31%
Validation set: Average loss: 1.147995, Accuracy: 604/1050 (58%)

Epoch: 19
Training set [0/6430 (0%)] Loss: 1.005202
Training set [4480/6430 (67%)] Loss: 0.889824
Training set: Average loss: 0.910801
Training set: Average accuracy: 64.59%
Validation set: Average loss: 1.031019, Accuracy: 648/1050 (62%)

Epoch: 20
Training set [0/6430 (0%)] Loss: 0.817140
Training set [4480/6430 (67%)] Loss: 0.840088
Training set: Average loss: 0.873385
Training set: Average accuracy: 66.07%
Validation set: Average loss: 1.126323, Accuracy: 643/1050 (61%)

Epoch: 21
Training set [0/6430 (0%)] Loss: 0.810967
Training set [4480/6430 (67%)] Loss: 0.810088
Training set: Average loss: 0.867597
Training set: Average accuracy: 66.10%
Validation set: Average loss: 1.701967, Accuracy: 480/1050 (46%)

Epoch: 22
Training set [0/6430 (0%)] Loss: 0.875510
Training set [4480/6430 (67%)] Loss: 0.852166
Training set: Average loss: 0.820749
Training set: Average accuracy: 68.46%
Validation set: Average loss: 0.987748, Accuracy: 690/1050 (66%)

Epoch: 23
Training set [0/6430 (0%)] Loss: 0.743169
Training set [4480/6430 (67%)] Loss: 0.834220
Training set: Average loss: 0.790184
Training set: Average accuracy: 69.41%
Validation set: Average loss: 0.981288, Accuracy: 721/1050 (69%)

Epoch: 24
Training set [0/6430 (0%)] Loss: 0.774206
Training set [4480/6430 (67%)] Loss: 0.793569
Training set: Average loss: 0.782571
Training set: Average accuracy: 70.00%
Validation set: Average loss: 0.910697, Accuracy: 734/1050 (70%)

Epoch: 25
Training set [0/6430 (0%)] Loss: 0.764989
Training set [4480/6430 (67%)] Loss: 0.758474
Training set: Average loss: 0.759215
Training set: Average accuracy: 69.94%
Validation set: Average loss: 1.705745, Accuracy: 542/1050 (52%)

Epoch: 26
Training set [0/6430 (0%)] Loss: 0.911591
Training set [4480/6430 (67%)] Loss: 0.788494
Training set: Average loss: 0.785330
Training set: Average accuracy: 69.28%
Validation set: Average loss: 0.915791, Accuracy: 764/1050 (73%)

Epoch: 27
Training set [0/6430 (0%)] Loss: 0.750415
Training set [4480/6430 (67%)] Loss: 0.715022
Training set: Average loss: 0.729239
Training set: Average accuracy: 71.48%
Validation set: Average loss: 0.820406, Accuracy: 750/1050 (71%)

Epoch: 28
Training set [0/6430 (0%)] Loss: 0.727212
Training set [4480/6430 (67%)] Loss: 0.714521
Training set: Average loss: 0.716847
Training set: Average accuracy: 71.68%
Validation set: Average loss: 0.961826, Accuracy: 698/1050 (66%)

Epoch: 29
Training set [0/6430 (0%)] Loss: 0.727371
Training set [4480/6430 (67%)] Loss: 0.757571
Training set: Average loss: 0.711609
Training set: Average accuracy: 71.91%
Validation set: Average loss: 0.842590, Accuracy: 769/1050 (73%)

Epoch: 30
Training set [0/6430 (0%)] Loss: 0.696282
Training set [4480/6430 (67%)] Loss: 0.614786
Training set: Average loss: 0.694549
Training set: Average accuracy: 72.63%
Validation set: Average loss: 0.936201, Accuracy: 730/1050 (70%)

Epoch: 31
Training set [0/6430 (0%)] Loss: 0.651114
Training set [4480/6430 (67%)] Loss: 0.710412
Training set: Average loss: 0.661681
Training set: Average accuracy: 73.84%
Validation set: Average loss: 1.071128, Accuracy: 679/1050 (65%)

Epoch: 32
Training set [0/6430 (0%)] Loss: 0.630402
Training set [4480/6430 (67%)] Loss: 0.701299
Training set: Average loss: 0.684443
Training set: Average accuracy: 73.03%
Validation set: Average loss: 0.949802, Accuracy: 744/1050 (71%)

Epoch: 33
Training set [0/6430 (0%)] Loss: 0.673503
Training set [4480/6430 (67%)] Loss: 0.667160
Training set: Average loss: 0.661808
Training set: Average accuracy: 74.04%
Validation set: Average loss: 2.207302, Accuracy: 510/1050 (49%)

Epoch: 34
Training set [0/6430 (0%)] Loss: 0.635228
Training set [4480/6430 (67%)] Loss: 0.664288
Training set: Average loss: 0.661145
Training set: Average accuracy: 74.14%
Validation set: Average loss: 1.165567, Accuracy: 652/1050 (62%)

Epoch: 35
Training set [0/6430 (0%)] Loss: 0.684460
Training set [4480/6430 (67%)] Loss: 0.657722
Training set: Average loss: 0.621442
Training set: Average accuracy: 75.21%
Validation set: Average loss: 0.765782, Accuracy: 790/1050 (75%)

Epoch: 36
Training set [0/6430 (0%)] Loss: 0.651935
Training set [4480/6430 (67%)] Loss: 0.559472
Training set: Average loss: 0.619411
Training set: Average accuracy: 75.26%
Validation set: Average loss: 0.751665, Accuracy: 782/1050 (74%)

Epoch: 37
Training set [0/6430 (0%)] Loss: 0.625494
Training set [4480/6430 (67%)] Loss: 0.629632
Training set: Average loss: 0.608878
Training set: Average accuracy: 76.55%
Validation set: Average loss: 0.934064, Accuracy: 731/1050 (70%)

Epoch: 38
Training set [0/6430 (0%)] Loss: 0.609273
Training set [4480/6430 (67%)] Loss: 0.563285
Training set: Average loss: 0.601165
Training set: Average accuracy: 75.99%
Validation set: Average loss: 0.795281, Accuracy: 784/1050 (75%)

Epoch: 39
Training set [0/6430 (0%)] Loss: 0.637336
Training set [4480/6430 (67%)] Loss: 0.612845
Training set: Average loss: 0.627569
Training set: Average accuracy: 75.41%
Validation set: Average loss: 1.103621, Accuracy: 718/1050 (68%)

Epoch: 40
Training set [0/6430 (0%)] Loss: 0.559259
Training set [4480/6430 (67%)] Loss: 0.605961
Training set: Average loss: 0.632437
Training set: Average accuracy: 74.90%
Validation set: Average loss: 0.787211, Accuracy: 786/1050 (75%)

Epoch: 41
Training set [0/6430 (0%)] Loss: 0.599031
Training set [4480/6430 (67%)] Loss: 0.631147
Training set: Average loss: 0.598519
Training set: Average accuracy: 76.07%
Validation set: Average loss: 0.815695, Accuracy: 756/1050 (72%)

Epoch: 42
Training set [0/6430 (0%)] Loss: 0.618972
Training set [4480/6430 (67%)] Loss: 0.647118
Training set: Average loss: 0.599112
Training set: Average accuracy: 76.28%
Validation set: Average loss: 0.775036, Accuracy: 792/1050 (75%)

Epoch: 43
Training set [0/6430 (0%)] Loss: 0.552835
Training set [4480/6430 (67%)] Loss: 0.530237
Training set: Average loss: 0.563051
Training set: Average accuracy: 76.56%
Validation set: Average loss: 1.619869, Accuracy: 641/1050 (61%)

Epoch: 44
Training set [0/6430 (0%)] Loss: 0.562208
Training set [4480/6430 (67%)] Loss: 0.521274
Training set: Average loss: 0.560382
Training set: Average accuracy: 77.73%
Validation set: Average loss: 0.717716, Accuracy: 822/1050 (78%)

Epoch: 45
Training set [0/6430 (0%)] Loss: 0.476086
Training set [4480/6430 (67%)] Loss: 0.504417
Training set: Average loss: 0.548417
Training set: Average accuracy: 78.04%
Validation set: Average loss: 1.325414, Accuracy: 693/1050 (66%)

Epoch: 46
Training set [0/6430 (0%)] Loss: 0.545373
Training set [4480/6430 (67%)] Loss: 0.537861
Training set: Average loss: 0.537781
Training set: Average accuracy: 78.96%
Validation set: Average loss: 1.135965, Accuracy: 715/1050 (68%)

Epoch: 47
Training set [0/6430 (0%)] Loss: 0.505691
Training set [4480/6430 (67%)] Loss: 0.630275
Training set: Average loss: 0.550176
Training set: Average accuracy: 78.44%
Validation set: Average loss: 1.022804, Accuracy: 761/1050 (72%)

Epoch: 48
Training set [0/6430 (0%)] Loss: 0.559098
Training set [4480/6430 (67%)] Loss: 0.541884
Training set: Average loss: 0.531626
Training set: Average accuracy: 78.71%
Validation set: Average loss: 1.008767, Accuracy: 745/1050 (71%)

Epoch: 49
Training set [0/6430 (0%)] Loss: 0.573324
Training set [4480/6430 (67%)] Loss: 0.478953
Training set: Average loss: 0.538455
Training set: Average accuracy: 78.37%
Validation set: Average loss: 0.833291, Accuracy: 794/1050 (76%)

Epoch: 50
Training set [0/6430 (0%)] Loss: 0.501517
Training set [4480/6430 (67%)] Loss: 0.470527
Training set: Average loss: 0.513409
Training set: Average accuracy: 79.72%
Validation set: Average loss: 0.848351, Accuracy: 763/1050 (73%)

Epoch: 51
Training set [0/6430 (0%)] Loss: 0.553783
Training set [4480/6430 (67%)] Loss: 0.508738
Training set: Average loss: 0.508564
Training set: Average accuracy: 79.47%
Validation set: Average loss: 0.797951, Accuracy: 773/1050 (74%)

Epoch: 52
Training set [0/6430 (0%)] Loss: 0.475528
Training set [4480/6430 (67%)] Loss: 0.496543
Training set: Average loss: 0.514402
Training set: Average accuracy: 79.22%
Validation set: Average loss: 0.836789, Accuracy: 788/1050 (75%)

Epoch: 53
Training set [0/6430 (0%)] Loss: 0.559178
Training set [4480/6430 (67%)] Loss: 0.510159
Training set: Average loss: 0.498781
Training set: Average accuracy: 79.66%
Validation set: Average loss: 1.019820, Accuracy: 758/1050 (72%)

Epoch: 54
Training set [0/6430 (0%)] Loss: 0.604714
Training set [4480/6430 (67%)] Loss: 0.455258
Training set: Average loss: 0.504845
Training set: Average accuracy: 79.94%
Validation set: Average loss: 0.987209, Accuracy: 750/1050 (71%)

Epoch: 55
Training set [0/6430 (0%)] Loss: 0.469914
Training set [4480/6430 (67%)] Loss: 0.534990
Training set: Average loss: 0.518718
Training set: Average accuracy: 79.14%
Validation set: Average loss: 0.770851, Accuracy: 790/1050 (75%)

Epoch: 56
Training set [0/6430 (0%)] Loss: 0.498607
Training set [4480/6430 (67%)] Loss: 0.527533
Training set: Average loss: 0.486612
Training set: Average accuracy: 80.47%
Validation set: Average loss: 1.515277, Accuracy: 671/1050 (64%)

Epoch: 57
Training set [0/6430 (0%)] Loss: 0.447438
Training set [4480/6430 (67%)] Loss: 0.474142
Training set: Average loss: 0.501923
Training set: Average accuracy: 80.23%
Validation set: Average loss: 0.952903, Accuracy: 776/1050 (74%)

Epoch: 58
Training set [0/6430 (0%)] Loss: 0.521852
Training set [4480/6430 (67%)] Loss: 0.482220
Training set: Average loss: 0.491084
Training set: Average accuracy: 80.47%
Validation set: Average loss: 0.862587, Accuracy: 757/1050 (72%)

Epoch: 59
Training set [0/6430 (0%)] Loss: 0.494997
Training set [4480/6430 (67%)] Loss: 0.481328
Training set: Average loss: 0.491302
Training set: Average accuracy: 80.31%
Validation set: Average loss: 1.040042, Accuracy: 761/1050 (72%)

Epoch: 60
Training set [0/6430 (0%)] Loss: 0.466518
Training set [4480/6430 (67%)] Loss: 0.455564
Training set: Average loss: 0.462929
Training set: Average accuracy: 81.60%
Validation set: Average loss: 1.286028, Accuracy: 709/1050 (68%)

Epoch: 61
Training set [0/6430 (0%)] Loss: 0.494909
Training set [4480/6430 (67%)] Loss: 0.473296
Training set: Average loss: 0.458589
Training set: Average accuracy: 81.66%
Validation set: Average loss: 0.865556, Accuracy: 777/1050 (74%)

Epoch: 62
Training set [0/6430 (0%)] Loss: 0.454983
Training set [4480/6430 (67%)] Loss: 0.496647
Training set: Average loss: 0.471439
Training set: Average accuracy: 81.15%
Validation set: Average loss: 1.397843, Accuracy: 686/1050 (65%)

Epoch: 63
Training set [0/6430 (0%)] Loss: 0.446471
Training set [4480/6430 (67%)] Loss: 0.439534
Training set: Average loss: 0.449019
Training set: Average accuracy: 81.88%
Validation set: Average loss: 1.087564, Accuracy: 779/1050 (74%)

Epoch: 64
Training set [0/6430 (0%)] Loss: 0.439808
Training set [4480/6430 (67%)] Loss: 0.389584
Training set: Average loss: 0.455942
Training set: Average accuracy: 82.32%
Validation set: Average loss: 0.868251, Accuracy: 788/1050 (75%)

Epoch: 65
Training set [0/6430 (0%)] Loss: 0.445157
Training set [4480/6430 (67%)] Loss: 0.456711
Training set: Average loss: 0.438227
Training set: Average accuracy: 82.22%
Validation set: Average loss: 1.281661, Accuracy: 723/1050 (69%)

Epoch: 66
Training set [0/6430 (0%)] Loss: 0.432802
Training set [4480/6430 (67%)] Loss: 0.413175
Training set: Average loss: 0.429447
Training set: Average accuracy: 82.92%
Validation set: Average loss: 0.952230, Accuracy: 792/1050 (75%)

Epoch: 67
Training set [0/6430 (0%)] Loss: 0.389101
Training set [4480/6430 (67%)] Loss: 0.412602
Training set: Average loss: 0.431533
Training set: Average accuracy: 82.27%
Validation set: Average loss: 0.830182, Accuracy: 804/1050 (77%)

Epoch: 68
Training set [0/6430 (0%)] Loss: 0.427300
Training set [4480/6430 (67%)] Loss: 0.432610
Training set: Average loss: 0.426026
Training set: Average accuracy: 82.69%
Validation set: Average loss: 0.760021, Accuracy: 825/1050 (79%)

Epoch: 69
Training set [0/6430 (0%)] Loss: 0.383617
Training set [4480/6430 (67%)] Loss: 0.486932
Training set: Average loss: 0.431284
Training set: Average accuracy: 83.16%
Validation set: Average loss: 0.886845, Accuracy: 794/1050 (76%)

Epoch: 70
Training set [0/6430 (0%)] Loss: 0.472799
Training set [4480/6430 (67%)] Loss: 0.415148
Training set: Average loss: 0.423529
Training set: Average accuracy: 83.08%
Validation set: Average loss: 0.915289, Accuracy: 794/1050 (76%)

Epoch: 71
Training set [0/6430 (0%)] Loss: 0.488433
Training set [4480/6430 (67%)] Loss: 0.436028
Training set: Average loss: 0.439143
Training set: Average accuracy: 82.64%
Validation set: Average loss: 0.986929, Accuracy: 786/1050 (75%)

Epoch: 72
Training set [0/6430 (0%)] Loss: 0.385264
Training set [4480/6430 (67%)] Loss: 0.417691
Training set: Average loss: 0.424371
Training set: Average accuracy: 83.42%
Validation set: Average loss: 1.014748, Accuracy: 785/1050 (75%)

Epoch: 73
Training set [0/6430 (0%)] Loss: 0.400923
Training set [4480/6430 (67%)] Loss: 0.447917
Training set: Average loss: 0.422369
Training set: Average accuracy: 83.31%
Validation set: Average loss: 0.834317, Accuracy: 820/1050 (78%)

Epoch: 74
Training set [0/6430 (0%)] Loss: 0.403688
Training set [4480/6430 (67%)] Loss: 0.473220
Training set: Average loss: 0.392642
Training set: Average accuracy: 83.98%
Validation set: Average loss: 0.853463, Accuracy: 787/1050 (75%)

Epoch: 75
Training set [0/6430 (0%)] Loss: 0.419045
Training set [4480/6430 (67%)] Loss: 0.360439
Training set: Average loss: 0.419945
Training set: Average accuracy: 83.17%
Validation set: Average loss: 1.081548, Accuracy: 772/1050 (74%)

Epoch: 76
Training set [0/6430 (0%)] Loss: 0.468636
Training set [4480/6430 (67%)] Loss: 0.405747
Training set: Average loss: 0.403706
Training set: Average accuracy: 83.86%
Validation set: Average loss: 0.967067, Accuracy: 807/1050 (77%)

Epoch: 77
Training set [0/6430 (0%)] Loss: 0.418212
Training set [4480/6430 (67%)] Loss: 0.419651
Training set: Average loss: 0.418927
Training set: Average accuracy: 82.67%
Validation set: Average loss: 1.040136, Accuracy: 762/1050 (73%)

Epoch: 78
Training set [0/6430 (0%)] Loss: 0.433346
Training set [4480/6430 (67%)] Loss: 0.432863
Training set: Average loss: 0.434427
Training set: Average accuracy: 83.00%
Validation set: Average loss: 0.780812, Accuracy: 810/1050 (77%)

Epoch: 79
Training set [0/6430 (0%)] Loss: 0.454283
Training set [4480/6430 (67%)] Loss: 0.449344
Training set: Average loss: 0.411724
Training set: Average accuracy: 83.44%
Validation set: Average loss: 0.888768, Accuracy: 789/1050 (75%)

Epoch: 80
Training set [0/6430 (0%)] Loss: 0.438888
Training set [4480/6430 (67%)] Loss: 0.349299
Training set: Average loss: 0.401848
Training set: Average accuracy: 83.62%
Validation set: Average loss: 1.182428, Accuracy: 753/1050 (72%)

Epoch: 81
Training set [0/6430 (0%)] Loss: 0.494606
Training set [4480/6430 (67%)] Loss: 0.378798
Training set: Average loss: 0.420634
Training set: Average accuracy: 83.27%
Validation set: Average loss: 0.836014, Accuracy: 796/1050 (76%)

Epoch: 82
Training set [0/6430 (0%)] Loss: 0.428624
Training set [4480/6430 (67%)] Loss: 0.408134
Training set: Average loss: 0.391521
Training set: Average accuracy: 84.84%
Validation set: Average loss: 1.399310, Accuracy: 709/1050 (68%)

Epoch: 83
Training set [0/6430 (0%)] Loss: 0.391285
Training set [4480/6430 (67%)] Loss: 0.410443
Training set: Average loss: 0.390327
Training set: Average accuracy: 84.06%
Validation set: Average loss: 0.998734, Accuracy: 804/1050 (77%)

Epoch: 84
Training set [0/6430 (0%)] Loss: 0.352332
Training set [4480/6430 (67%)] Loss: 0.399374
Training set: Average loss: 0.367620
Training set: Average accuracy: 85.58%
Validation set: Average loss: 0.896750, Accuracy: 820/1050 (78%)

Epoch: 85
Training set [0/6430 (0%)] Loss: 0.367844
Training set [4480/6430 (67%)] Loss: 0.372393
Training set: Average loss: 0.372479
Training set: Average accuracy: 84.51%
Validation set: Average loss: 1.080828, Accuracy: 792/1050 (75%)

Epoch: 86
Training set [0/6430 (0%)] Loss: 0.329154
Training set [4480/6430 (67%)] Loss: 0.389195
Training set: Average loss: 0.356228
Training set: Average accuracy: 85.68%
Validation set: Average loss: 0.782856, Accuracy: 835/1050 (80%)

Epoch: 87
Training set [0/6430 (0%)] Loss: 0.381765
Training set [4480/6430 (67%)] Loss: 0.374860
Training set: Average loss: 0.368130
Training set: Average accuracy: 84.67%
Validation set: Average loss: 1.229597, Accuracy: 734/1050 (70%)

Epoch: 88
Training set [0/6430 (0%)] Loss: 0.359695
Training set [4480/6430 (67%)] Loss: 0.420591
Training set: Average loss: 0.373779
Training set: Average accuracy: 84.34%
Validation set: Average loss: 0.735743, Accuracy: 820/1050 (78%)

Epoch: 89
Training set [0/6430 (0%)] Loss: 0.421986
Training set [4480/6430 (67%)] Loss: 0.369260
Training set: Average loss: 0.377784
Training set: Average accuracy: 85.15%
Validation set: Average loss: 0.797042, Accuracy: 828/1050 (79%)

Epoch: 90
Training set [0/6430 (0%)] Loss: 0.306315
Training set [4480/6430 (67%)] Loss: 0.402529
Training set: Average loss: 0.366178
Training set: Average accuracy: 84.99%
Validation set: Average loss: 0.765995, Accuracy: 829/1050 (79%)

Epoch: 91
Training set [0/6430 (0%)] Loss: 0.340532
Training set [4480/6430 (67%)] Loss: 0.367403
Training set: Average loss: 0.353826
Training set: Average accuracy: 86.00%
Validation set: Average loss: 0.853654, Accuracy: 813/1050 (77%)

Epoch: 92
Training set [0/6430 (0%)] Loss: 0.319585
Training set [4480/6430 (67%)] Loss: 0.389822
Training set: Average loss: 0.378064
Training set: Average accuracy: 84.48%
Validation set: Average loss: 0.812861, Accuracy: 835/1050 (80%)

Epoch: 93
Training set [0/6430 (0%)] Loss: 0.348113
Training set [4480/6430 (67%)] Loss: 0.324672
Training set: Average loss: 0.369975
Training set: Average accuracy: 84.82%
Validation set: Average loss: 0.884268, Accuracy: 817/1050 (78%)

Epoch: 94
Training set [0/6430 (0%)] Loss: 0.351243
Training set [4480/6430 (67%)] Loss: 0.385490
Training set: Average loss: 0.360632
Training set: Average accuracy: 85.72%
Validation set: Average loss: 1.202091, Accuracy: 772/1050 (74%)

Epoch: 95
Training set [0/6430 (0%)] Loss: 0.397256
Training set [4480/6430 (67%)] Loss: 0.379240
Training set: Average loss: 0.367029
Training set: Average accuracy: 84.57%
Validation set: Average loss: 0.832057, Accuracy: 817/1050 (78%)

Epoch: 96
Training set [0/6430 (0%)] Loss: 0.381005
Training set [4480/6430 (67%)] Loss: 0.347836
Training set: Average loss: 0.356210
Training set: Average accuracy: 86.16%
Validation set: Average loss: 0.974474, Accuracy: 806/1050 (77%)

Epoch: 97
Training set [0/6430 (0%)] Loss: 0.362787
Training set [4480/6430 (67%)] Loss: 0.376377
Training set: Average loss: 0.344083
Training set: Average accuracy: 85.88%
Validation set: Average loss: 0.967568, Accuracy: 808/1050 (77%)

Epoch: 98
Training set [0/6430 (0%)] Loss: 0.348272
Training set [4480/6430 (67%)] Loss: 0.306023
Training set: Average loss: 0.342243
Training set: Average accuracy: 86.22%
Validation set: Average loss: 1.105891, Accuracy: 781/1050 (74%)

Epoch: 99
Training set [0/6430 (0%)] Loss: 0.326182
Training set [4480/6430 (67%)] Loss: 0.301568
Training set: Average loss: 0.335868
Training set: Average accuracy: 86.59%
Validation set: Average loss: 0.840317, Accuracy: 833/1050 (79%)

Epoch: 100
Training set [0/6430 (0%)] Loss: 0.363773
Training set [4480/6430 (67%)] Loss: 0.401820
Training set: Average loss: 0.357373
Training set: Average accuracy: 84.99%
Validation set: Average loss: 2.042625, Accuracy: 684/1050 (65%)

Epoch: 101
Training set [0/6430 (0%)] Loss: 0.389342
Training set [4480/6430 (67%)] Loss: 0.350960
Training set: Average loss: 0.360368
Training set: Average accuracy: 85.38%
Validation set: Average loss: 1.091553, Accuracy: 786/1050 (75%)

Epoch: 102
Training set [0/6430 (0%)] Loss: 0.361867
Training set [4480/6430 (67%)] Loss: 0.358953
Training set: Average loss: 0.347629
Training set: Average accuracy: 85.89%
Validation set: Average loss: 1.164634, Accuracy: 754/1050 (72%)

Epoch: 103
Training set [0/6430 (0%)] Loss: 0.303782
Training set [4480/6430 (67%)] Loss: 0.274350
Training set: Average loss: 0.332852
Training set: Average accuracy: 86.63%
Validation set: Average loss: 0.803622, Accuracy: 820/1050 (78%)

Epoch: 104
Training set [0/6430 (0%)] Loss: 0.360466
Training set [4480/6430 (67%)] Loss: 0.413625
Training set: Average loss: 0.355884
Training set: Average accuracy: 86.11%
Validation set: Average loss: 0.929617, Accuracy: 795/1050 (76%)

Epoch: 105
Training set [0/6430 (0%)] Loss: 0.335514
Training set [4480/6430 (67%)] Loss: 0.362117
Training set: Average loss: 0.335862
Training set: Average accuracy: 86.19%
Validation set: Average loss: 0.963361, Accuracy: 799/1050 (76%)

Epoch: 106
Training set [0/6430 (0%)] Loss: 0.354790
Training set [4480/6430 (67%)] Loss: 0.342620
Training set: Average loss: 0.333025
Training set: Average accuracy: 86.05%
Validation set: Average loss: 0.745679, Accuracy: 833/1050 (79%)

Epoch: 107
Training set [0/6430 (0%)] Loss: 0.349326
Training set [4480/6430 (67%)] Loss: 0.307359
Training set: Average loss: 0.317438
Training set: Average accuracy: 87.23%
Validation set: Average loss: 0.898031, Accuracy: 819/1050 (78%)

Epoch: 108
Training set [0/6430 (0%)] Loss: 0.317310
Training set [4480/6430 (67%)] Loss: 0.318282
Training set: Average loss: 0.354509
Training set: Average accuracy: 85.83%
Validation set: Average loss: 0.876881, Accuracy: 813/1050 (77%)

Epoch: 109
Training set [0/6430 (0%)] Loss: 0.364519
Training set [4480/6430 (67%)] Loss: 0.356682
Training set: Average loss: 0.349136
Training set: Average accuracy: 86.05%
Validation set: Average loss: 0.832789, Accuracy: 834/1050 (79%)

Epoch: 110
Training set [0/6430 (0%)] Loss: 0.375094
Training set [4480/6430 (67%)] Loss: 0.346748
Training set: Average loss: 0.335505
Training set: Average accuracy: 86.64%
Validation set: Average loss: 0.961155, Accuracy: 792/1050 (75%)

Epoch: 111
Training set [0/6430 (0%)] Loss: 0.321157
Training set [4480/6430 (67%)] Loss: 0.305673
Training set: Average loss: 0.333578
Training set: Average accuracy: 87.11%
Validation set: Average loss: 1.185556, Accuracy: 782/1050 (74%)

Epoch: 112
Training set [0/6430 (0%)] Loss: 0.313033
Training set [4480/6430 (67%)] Loss: 0.312382
Training set: Average loss: 0.335818
Training set: Average accuracy: 86.35%
Validation set: Average loss: 0.916124, Accuracy: 835/1050 (80%)

Epoch: 113
Training set [0/6430 (0%)] Loss: 0.313742
Training set [4480/6430 (67%)] Loss: 0.360308
Training set: Average loss: 0.338822
Training set: Average accuracy: 85.86%
Validation set: Average loss: 0.820369, Accuracy: 799/1050 (76%)

Epoch: 114
Training set [0/6430 (0%)] Loss: 0.338263
Training set [4480/6430 (67%)] Loss: 0.353626
Training set: Average loss: 0.343427
Training set: Average accuracy: 86.56%
Validation set: Average loss: 1.016910, Accuracy: 811/1050 (77%)

Epoch: 115
Training set [0/6430 (0%)] Loss: 0.340050
Training set [4480/6430 (67%)] Loss: 0.302004
Training set: Average loss: 0.322409
Training set: Average accuracy: 87.22%
Validation set: Average loss: 0.980875, Accuracy: 808/1050 (77%)

Epoch: 116
Training set [0/6430 (0%)] Loss: 0.332552
Training set [4480/6430 (67%)] Loss: 0.302826
Training set: Average loss: 0.339392
Training set: Average accuracy: 86.81%
Validation set: Average loss: 0.853925, Accuracy: 815/1050 (78%)

Epoch: 117
Training set [0/6430 (0%)] Loss: 0.323200
Training set [4480/6430 (67%)] Loss: 0.305312
Training set: Average loss: 0.327493
Training set: Average accuracy: 86.84%
Validation set: Average loss: 1.132040, Accuracy: 793/1050 (76%)

Early stopping: no improvement for 10 epochs
BasicNet
training_loss -- validation_loss
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117]
[2.781095600128174, 1.8041626850763957, 1.7300884882609049, 1.6556164741516113, 1.5939055283864338, 1.546737790107727, 1.480840023358663, 1.391052277882894, 1.34465545018514, 1.3007459878921508, 1.230192232131958, 1.200002392133077, 1.158803908030192, 1.1017340421676636, 1.0453539848327638, 1.0103344321250916, 0.9858505407969157, 0.9538469990094502, 0.9246914386749268, 0.9108007828394572, 0.873385222752889, 0.8675971666971842, 0.8207492828369141, 0.7901844541231792, 0.7825710773468018, 0.7592146714528402, 0.7853302796681721, 0.7292391498883565, 0.7168468594551086, 0.7116090933481852, 0.6945489327112834, 0.6616813182830811, 0.6844429969787598, 0.6618081132570902, 0.6611448089281718, 0.6214421113332113, 0.6194111625353496, 0.6088783979415894, 0.6011649449666341, 0.6275688568751018, 0.6324371774991353, 0.5985186835130055, 0.5991124153137207, 0.563051184018453, 0.560382342338562, 0.548416797320048, 0.5377813776334127, 0.5501758615175883, 0.5316258708635966, 0.5384550869464875, 0.5134089907010396, 0.5085643291473388, 0.5144018630186716, 0.498781156539917, 0.50484539270401, 0.5187184790770213, 0.4866122603416443, 0.501922994852066, 0.4910837332407633, 0.4913016219933828, 0.46292895873387657, 0.45858911275863645, 0.47143887281417846, 0.4490189254283905, 0.4559415956338247, 0.43822670380274453, 0.42944722175598143, 0.4315328379472097, 0.4260255813598633, 0.4312839130560557, 0.4235286096731822, 0.4391433338324229, 0.4243714650472005, 0.42236945033073425, 0.392642209927241, 0.4199451684951782, 0.40370606184005736, 0.41892749071121216, 0.4344272871812185, 0.4117240011692047, 0.40184805790583294, 0.4206339200337728, 0.3915209670861562, 0.3903270939985911, 0.36761963764826455, 0.372478711605072, 0.3562275171279907, 0.3681303779284159, 0.3737794280052185, 0.37778425415356953, 0.36617812315622966, 0.3538256386915843, 0.378064219156901, 0.36997517744700115, 0.36063186526298524, 0.3670294423898061, 0.3562101721763611, 0.34408289988835655, 0.3422434667746226, 0.33586766918500266, 0.35737284620602927, 0.36036837498346963, 0.3476289431254069, 0.3328518788019816, 0.3558841447035472, 0.33586172858874, 0.33302491108576454, 0.317437748114268, 0.35450910528500873, 0.3491355776786804, 0.33550456364949544, 0.333577952782313, 0.3358183801174164, 0.33882155219713844, 0.3434266984462738, 0.3224094271659851, 0.3393924673398336, 0.3274929920832316]
[1.9249505996704102, 1.7777522802352905, 1.6828511555989583, 1.6300544341405232, 1.6152178446451824, 1.5518113374710083, 1.439947525660197, 1.405930757522583, 1.4771323601404827, 1.254942536354065, 1.2410367727279663, 1.139719843864441, 4.192943016688029, 1.102208177248637, 1.0547774036725361, 1.0536603331565857, 2.564600110054016, 0.9518234729766846, 1.1479948957761128, 1.0310194094975789, 1.1263230244318645, 1.7019670009613037, 0.9877475301424662, 0.9812876582145691, 0.9106970032056173, 1.705745259920756, 0.9157911737759908, 0.8204063971837362, 0.9618263641993204, 0.8425899346669515, 0.9362011353174845, 1.0711278120676677, 0.9498021205266317, 2.2073023319244385, 1.165566662947337, 0.7657819191614786, 0.7516650557518005, 0.9340635389089584, 0.7952812115351359, 1.1036212642987568, 0.7872113486131033, 0.8156952261924744, 0.7750360667705536, 1.619869073232015, 0.7177156408627828, 1.325413664182027, 1.1359647115071614, 1.022803525129954, 1.0087671130895615, 0.8332908153533936, 0.8483505646387736, 0.7979510128498077, 0.836788535118103, 1.0198195179303486, 0.9872091313203176, 0.7708514531453451, 1.5152767499287922, 0.9529034097989401, 0.8625868757565817, 1.040042241414388, 1.286027987798055, 0.8655564983685812, 1.397843360900879, 1.0875643491744995, 0.8682506680488586, 1.2816606561342876, 0.9522301355997721, 0.8301817178726196, 0.7600210110346476, 0.8868446946144104, 0.9152885476748148, 0.9869287411371866, 1.0147475997606914, 0.8343174060185751, 0.8534625569979349, 1.0815478364626567, 0.9670668045679728, 1.0401357014973958, 0.7808117071787516, 0.8887676994005839, 1.1824279030164082, 0.8360135952631632, 1.399309794108073, 0.9987344145774841, 0.8967500329017639, 1.0808281898498535, 0.7828555107116699, 1.2295965751012166, 0.7357428471247355, 0.7970421810944875, 0.7659948567549387, 0.8536537090937296, 0.8128611842791239, 0.8842682838439941, 1.2020910382270813, 0.8320571680863699, 0.9744737843672434, 0.9675681988398234, 1.1058912575244904, 0.8403170704841614, 2.042625347773234, 1.091553231080373, 1.1646335025628407, 0.8036218484242758, 0.9296165804068247, 0.9633611341317495, 0.745679239432017, 0.8980307678381602, 0.8768812914689382, 0.8327890833218893, 0.9611551761627197, 1.1855563322703044, 0.9161243339379629, 0.8203687866528829, 1.0169104238351185, 0.9808746973673502, 0.8539250989754995, 1.1320402026176453]
BasicNet
training_accuracy -- validation_accuracy
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117]
[18.42923794712286, 28.08709175738725, 31.866251944012443, 34.183514774494554, 36.6407465007776, 38.429237947122864, 41.306376360808706, 44.96111975116641, 47.01399688958009, 48.88024883359253, 51.81959564541213, 52.363919129082426, 55.47433903576983, 57.44945567651633, 58.77138413685847, 60.13996889580093, 60.79315707620529, 62.892690513219286, 63.312597200622086, 64.58786936236392, 66.06531881804044, 66.09642301710731, 68.46034214618973, 69.40902021772939, 70.0, 69.93779160186625, 69.2846034214619, 71.47744945567652, 71.6796267496112, 71.91290824261276, 72.62830482115085, 73.84136858475894, 73.03265940902021, 74.04354587869362, 74.13685847589424, 75.2099533437014, 75.25660964230171, 76.54743390357699, 75.98755832037325, 75.41213063763608, 74.89891135303266, 76.06531881804044, 76.28304821150856, 76.56298600311042, 77.72939346811819, 78.04043545878693, 78.95800933125972, 78.4447900466563, 78.70917573872472, 78.36702954898911, 79.72006220839813, 79.47122861586314, 79.22239502332815, 79.65785381026438, 79.93779160186625, 79.14463452566096, 80.46656298600311, 80.23328149300156, 80.46656298600311, 80.31104199066874, 81.60186625194402, 81.66407465007777, 81.15085536547434, 81.88180404354588, 82.31726283048212, 82.2239502332815, 82.92379471228615, 82.27060653188181, 82.6905132192846, 83.15707620528771, 83.07931570762052, 82.64385692068429, 83.42146189735614, 83.31259720062208, 83.98133748055987, 83.17262830482115, 83.85692068429238, 82.67496111975116, 83.00155520995334, 83.43701399688958, 83.62363919129082, 83.26594090202177, 84.83670295489891, 84.05909797822706, 85.58320373250389, 84.51010886469673, 85.67651632970451, 84.6656298600311, 84.33903576982893, 85.14774494556765, 84.99222395023328, 86.00311041990669, 84.47900466562986, 84.82115085536547, 85.72317262830482, 84.57231726283048, 86.15863141524106, 85.8786936236392, 86.22083981337481, 86.5940902021773, 84.99222395023328, 85.38102643856921, 85.89424572317263, 86.62519440124417, 86.11197511664075, 86.18973561430793, 86.049766718507, 87.23172628304822, 85.83203732503888, 86.049766718507, 86.64074650077761, 87.10730948678072, 86.3452566096423, 85.86314152410576, 86.56298600311042, 87.21617418351478, 86.81181959564542, 86.84292379471229]
[15.714285714285714, 18.19047619047619, 34.857142857142854, 40.095238095238095, 41.142857142857146, 44.38095238095238, 48.19047619047619, 47.80952380952381, 44.19047619047619, 52.857142857142854, 55.142857142857146, 59.80952380952381, 21.904761904761905, 60.57142857142857, 62.285714285714285, 60.666666666666664, 34.666666666666664, 66.38095238095238, 57.523809523809526, 61.714285714285715, 61.23809523809524, 45.714285714285715, 65.71428571428571, 68.66666666666667, 69.9047619047619, 51.61904761904762, 72.76190476190476, 71.42857142857143, 66.47619047619048, 73.23809523809524, 69.52380952380952, 64.66666666666667, 70.85714285714286, 48.57142857142857, 62.095238095238095, 75.23809523809524, 74.47619047619048, 69.61904761904762, 74.66666666666667, 68.38095238095238, 74.85714285714286, 72.0, 75.42857142857143, 61.04761904761905, 78.28571428571429, 66.0, 68.0952380952381, 72.47619047619048, 70.95238095238095, 75.61904761904762, 72.66666666666667, 73.61904761904762, 75.04761904761905, 72.19047619047619, 71.42857142857143, 75.23809523809524, 63.904761904761905, 73.9047619047619, 72.0952380952381, 72.47619047619048, 67.52380952380952, 74.0, 65.33333333333333, 74.19047619047619, 75.04761904761905, 68.85714285714286, 75.42857142857143, 76.57142857142857, 78.57142857142857, 75.61904761904762, 75.61904761904762, 74.85714285714286, 74.76190476190476, 78.0952380952381, 74.95238095238095, 73.52380952380952, 76.85714285714286, 72.57142857142857, 77.14285714285714, 75.14285714285714, 71.71428571428571, 75.80952380952381, 67.52380952380952, 76.57142857142857, 78.0952380952381, 75.42857142857143, 79.52380952380952, 69.9047619047619, 78.0952380952381, 78.85714285714286, 78.95238095238095, 77.42857142857143, 79.52380952380952, 77.80952380952381, 73.52380952380952, 77.80952380952381, 76.76190476190476, 76.95238095238095, 74.38095238095238, 79.33333333333333, 65.14285714285714, 74.85714285714286, 71.80952380952381, 78.0952380952381, 75.71428571428571, 76.0952380952381, 79.33333333333333, 78.0, 77.42857142857143, 79.42857142857143, 75.42857142857143, 74.47619047619048, 79.52380952380952, 76.0952380952381, 77.23809523809524, 76.95238095238095, 77.61904761904762, 75.52380952380952]
model saved as model_store_448/cnn_car_BasicNet.pt
Getting predictions from test set...
BasicNet
[[112   7   0   0  23   3   5]
 [  1 110   0   2   5   0  32]
 [  3  17  98   2   5   7  18]
 [ 42   2   0  79  10   6  11]
 [  0   4   0   0 138   0   8]
 [  4  12   0   1   8 118   7]
 [  1   2   1   0   8   0 138]]
=============================
ImprovedNet
=============================
Epoch: 0
Training set [0/6430 (0%)] Loss: 1.944838
Training set [4480/6430 (67%)] Loss: 1.923236
Training set: Average loss: 1.978802
Training set: Average accuracy: 17.36%
Validation set: Average loss: 1.891761, Accuracy: 275/1050 (26%)

Epoch: 1
Training set [0/6430 (0%)] Loss: 1.831401
Training set [4480/6430 (67%)] Loss: 1.749508
Training set: Average loss: 1.791465
Training set: Average accuracy: 29.95%
Validation set: Average loss: 1.832255, Accuracy: 339/1050 (32%)

Epoch: 2
Training set [0/6430 (0%)] Loss: 1.777383
Training set [4480/6430 (67%)] Loss: 1.553237
Training set: Average loss: 1.645793
Training set: Average accuracy: 38.66%
Validation set: Average loss: 1.559337, Accuracy: 407/1050 (39%)

Epoch: 3
Training set [0/6430 (0%)] Loss: 1.536455
Training set [4480/6430 (67%)] Loss: 1.507165
Training set: Average loss: 1.485851
Training set: Average accuracy: 45.02%
Validation set: Average loss: 1.551771, Accuracy: 477/1050 (45%)

Epoch: 4
Training set [0/6430 (0%)] Loss: 1.387071
Training set [4480/6430 (67%)] Loss: 1.334659
Training set: Average loss: 1.326264
Training set: Average accuracy: 51.51%
Validation set: Average loss: 1.329787, Accuracy: 530/1050 (50%)

Epoch: 5
Training set [0/6430 (0%)] Loss: 1.238682
Training set [4480/6430 (67%)] Loss: 1.151461
Training set: Average loss: 1.194538
Training set: Average accuracy: 57.11%
Validation set: Average loss: 1.359975, Accuracy: 524/1050 (50%)

Epoch: 6
Training set [0/6430 (0%)] Loss: 1.142013
Training set [4480/6430 (67%)] Loss: 1.045206
Training set: Average loss: 1.060217
Training set: Average accuracy: 61.79%
Validation set: Average loss: 1.221896, Accuracy: 579/1050 (55%)

Epoch: 7
Training set [0/6430 (0%)] Loss: 1.029565
Training set [4480/6430 (67%)] Loss: 0.946874
Training set: Average loss: 0.928290
Training set: Average accuracy: 67.90%
Validation set: Average loss: 1.262368, Accuracy: 589/1050 (56%)

Epoch: 8
Training set [0/6430 (0%)] Loss: 0.891164
Training set [4480/6430 (67%)] Loss: 0.746876
Training set: Average loss: 0.794888
Training set: Average accuracy: 72.99%
Validation set: Average loss: 1.153090, Accuracy: 639/1050 (61%)

Epoch: 9
Training set [0/6430 (0%)] Loss: 0.682192
Training set [4480/6430 (67%)] Loss: 0.702851
Training set: Average loss: 0.667565
Training set: Average accuracy: 77.05%
Validation set: Average loss: 1.157652, Accuracy: 653/1050 (62%)

Epoch: 10
Training set [0/6430 (0%)] Loss: 0.544045
Training set [4480/6430 (67%)] Loss: 0.602202
Training set: Average loss: 0.555968
Training set: Average accuracy: 81.42%
Validation set: Average loss: 1.130132, Accuracy: 669/1050 (64%)

Epoch: 11
Training set [0/6430 (0%)] Loss: 0.477023
Training set [4480/6430 (67%)] Loss: 0.419009
Training set: Average loss: 0.462350
Training set: Average accuracy: 84.54%
Validation set: Average loss: 1.189557, Accuracy: 672/1050 (64%)

Epoch: 12
Training set [0/6430 (0%)] Loss: 0.406001
Training set [4480/6430 (67%)] Loss: 0.324343
Training set: Average loss: 0.382845
Training set: Average accuracy: 87.62%
Validation set: Average loss: 1.072294, Accuracy: 680/1050 (65%)

Epoch: 13
Training set [0/6430 (0%)] Loss: 0.334579
Training set [4480/6430 (67%)] Loss: 0.322555
Training set: Average loss: 0.321973
Training set: Average accuracy: 89.52%
Validation set: Average loss: 1.031184, Accuracy: 687/1050 (65%)

Epoch: 14
Training set [0/6430 (0%)] Loss: 0.244752
Training set [4480/6430 (67%)] Loss: 0.232484
Training set: Average loss: 0.250431
Training set: Average accuracy: 91.84%
Validation set: Average loss: 1.067267, Accuracy: 703/1050 (67%)

Epoch: 15
Training set [0/6430 (0%)] Loss: 0.216420
Training set [4480/6430 (67%)] Loss: 0.246478
Training set: Average loss: 0.238116
Training set: Average accuracy: 92.07%
Validation set: Average loss: 1.206202, Accuracy: 704/1050 (67%)

Epoch: 16
Training set [0/6430 (0%)] Loss: 0.200582
Training set [4480/6430 (67%)] Loss: 0.206912
Training set: Average loss: 0.198816
Training set: Average accuracy: 93.65%
Validation set: Average loss: 1.139607, Accuracy: 706/1050 (67%)

Epoch: 17
Training set [0/6430 (0%)] Loss: 0.143538
Training set [4480/6430 (67%)] Loss: 0.148579
Training set: Average loss: 0.153123
Training set: Average accuracy: 95.37%
Validation set: Average loss: 1.229358, Accuracy: 707/1050 (67%)

Epoch: 18
Training set [0/6430 (0%)] Loss: 0.154376
Training set [4480/6430 (67%)] Loss: 0.134212
Training set: Average loss: 0.150489
Training set: Average accuracy: 95.09%
Validation set: Average loss: 1.165182, Accuracy: 708/1050 (67%)

Epoch: 19
Training set [0/6430 (0%)] Loss: 0.122458
Training set [4480/6430 (67%)] Loss: 0.144567
Training set: Average loss: 0.139948
Training set: Average accuracy: 95.43%
Validation set: Average loss: 1.165196, Accuracy: 702/1050 (67%)

Epoch: 20
Training set [0/6430 (0%)] Loss: 0.105366
Training set [4480/6430 (67%)] Loss: 0.109941
Training set: Average loss: 0.112336
Training set: Average accuracy: 96.30%
Validation set: Average loss: 1.247229, Accuracy: 707/1050 (67%)

Epoch: 21
Training set [0/6430 (0%)] Loss: 0.105083
Training set [4480/6430 (67%)] Loss: 0.096661
Training set: Average loss: 0.098561
Training set: Average accuracy: 96.95%
Validation set: Average loss: 1.323537, Accuracy: 702/1050 (67%)

Epoch: 22
Training set [0/6430 (0%)] Loss: 0.055852
Training set [4480/6430 (67%)] Loss: 0.066260
Training set: Average loss: 0.091056
Training set: Average accuracy: 97.34%
Validation set: Average loss: 1.289613, Accuracy: 711/1050 (68%)

Epoch: 23
Training set [0/6430 (0%)] Loss: 0.082323
Training set [4480/6430 (67%)] Loss: 0.081018
Training set: Average loss: 0.079737
Training set: Average accuracy: 97.56%
Validation set: Average loss: 1.422739, Accuracy: 693/1050 (66%)

Epoch: 24
Training set [0/6430 (0%)] Loss: 0.066316
Training set [4480/6430 (67%)] Loss: 0.092322
Training set: Average loss: 0.090943
Training set: Average accuracy: 97.19%
Validation set: Average loss: 1.453950, Accuracy: 706/1050 (67%)

Epoch: 25
Training set [0/6430 (0%)] Loss: 0.048378
Training set [4480/6430 (67%)] Loss: 0.076844
Training set: Average loss: 0.071457
Training set: Average accuracy: 97.82%
Validation set: Average loss: 1.355576, Accuracy: 702/1050 (67%)

Epoch: 26
Training set [0/6430 (0%)] Loss: 0.052055
Training set [4480/6430 (67%)] Loss: 0.081664
Training set: Average loss: 0.061724
Training set: Average accuracy: 98.15%
Validation set: Average loss: 1.412976, Accuracy: 707/1050 (67%)

Epoch: 27
Training set [0/6430 (0%)] Loss: 0.069292
Training set [4480/6430 (67%)] Loss: 0.067958
Training set: Average loss: 0.060944
Training set: Average accuracy: 98.23%
Validation set: Average loss: 1.478979, Accuracy: 705/1050 (67%)

Epoch: 28
Training set [0/6430 (0%)] Loss: 0.066531
Training set [4480/6430 (67%)] Loss: 0.053755
Training set: Average loss: 0.056190
Training set: Average accuracy: 98.24%
Validation set: Average loss: 1.466030, Accuracy: 693/1050 (66%)

Epoch: 29
Training set [0/6430 (0%)] Loss: 0.051404
Training set [4480/6430 (67%)] Loss: 0.056850
Training set: Average loss: 0.056392
Training set: Average accuracy: 98.26%
Validation set: Average loss: 1.503804, Accuracy: 700/1050 (67%)

Epoch: 30
Training set [0/6430 (0%)] Loss: 0.037723
Training set [4480/6430 (67%)] Loss: 0.052092
Training set: Average loss: 0.052922
Training set: Average accuracy: 98.23%
Validation set: Average loss: 1.539717, Accuracy: 718/1050 (68%)

Epoch: 31
Training set [0/6430 (0%)] Loss: 0.053556
Training set [4480/6430 (67%)] Loss: 0.048308
Training set: Average loss: 0.049168
Training set: Average accuracy: 98.46%
Validation set: Average loss: 1.526747, Accuracy: 713/1050 (68%)

Epoch: 32
Training set [0/6430 (0%)] Loss: 0.057279
Training set [4480/6430 (67%)] Loss: 0.042740
Training set: Average loss: 0.044861
Training set: Average accuracy: 98.57%
Validation set: Average loss: 1.554889, Accuracy: 716/1050 (68%)

Epoch: 33
Training set [0/6430 (0%)] Loss: 0.049186
Training set [4480/6430 (67%)] Loss: 0.030726
Training set: Average loss: 0.040225
Training set: Average accuracy: 98.82%
Validation set: Average loss: 1.583567, Accuracy: 715/1050 (68%)

Epoch: 34
Training set [0/6430 (0%)] Loss: 0.059376
Training set [4480/6430 (67%)] Loss: 0.043682
Training set: Average loss: 0.039306
Training set: Average accuracy: 98.71%
Validation set: Average loss: 1.655230, Accuracy: 713/1050 (68%)

Epoch: 35
Training set [0/6430 (0%)] Loss: 0.022518
Training set [4480/6430 (67%)] Loss: 0.038355
Training set: Average loss: 0.036340
Training set: Average accuracy: 98.85%
Validation set: Average loss: 1.745873, Accuracy: 717/1050 (68%)

Epoch: 36
Training set [0/6430 (0%)] Loss: 0.028324
Training set [4480/6430 (67%)] Loss: 0.048405
Training set: Average loss: 0.047452
Training set: Average accuracy: 98.40%
Validation set: Average loss: 1.516960, Accuracy: 718/1050 (68%)

Epoch: 37
Training set [0/6430 (0%)] Loss: 0.020966
Training set [4480/6430 (67%)] Loss: 0.033159
Training set: Average loss: 0.040859
Training set: Average accuracy: 98.69%
Validation set: Average loss: 1.693417, Accuracy: 708/1050 (67%)

Epoch: 38
Training set [0/6430 (0%)] Loss: 0.047265
Training set [4480/6430 (67%)] Loss: 0.026583
Training set: Average loss: 0.042489
Training set: Average accuracy: 98.68%
Validation set: Average loss: 1.547085, Accuracy: 722/1050 (69%)

Epoch: 39
Training set [0/6430 (0%)] Loss: 0.022934
Training set [4480/6430 (67%)] Loss: 0.031728
Training set: Average loss: 0.033698
Training set: Average accuracy: 98.97%
Validation set: Average loss: 1.777552, Accuracy: 717/1050 (68%)

Epoch: 40
Training set [0/6430 (0%)] Loss: 0.036843
Training set [4480/6430 (67%)] Loss: 0.031123
Training set: Average loss: 0.032172
Training set: Average accuracy: 98.97%
Validation set: Average loss: 1.549527, Accuracy: 715/1050 (68%)

Epoch: 41
Training set [0/6430 (0%)] Loss: 0.040701
Training set [4480/6430 (67%)] Loss: 0.046846
Training set: Average loss: 0.038838
Training set: Average accuracy: 98.97%
Validation set: Average loss: 1.688845, Accuracy: 717/1050 (68%)

Epoch: 42
Training set [0/6430 (0%)] Loss: 0.019408
Training set [4480/6430 (67%)] Loss: 0.031254
Training set: Average loss: 0.037972
Training set: Average accuracy: 98.83%
Validation set: Average loss: 1.562801, Accuracy: 718/1050 (68%)

Epoch: 43
Training set [0/6430 (0%)] Loss: 0.024669
Training set [4480/6430 (67%)] Loss: 0.034020
Training set: Average loss: 0.037952
Training set: Average accuracy: 98.99%
Validation set: Average loss: 1.625980, Accuracy: 713/1050 (68%)

Epoch: 44
Training set [0/6430 (0%)] Loss: 0.021975
Training set [4480/6430 (67%)] Loss: 0.036207
Training set: Average loss: 0.032819
Training set: Average accuracy: 98.86%
Validation set: Average loss: 1.574278, Accuracy: 713/1050 (68%)

Epoch: 45
Training set [0/6430 (0%)] Loss: 0.013237
Training set [4480/6430 (67%)] Loss: 0.021528
Training set: Average loss: 0.027743
Training set: Average accuracy: 99.19%
Validation set: Average loss: 1.577920, Accuracy: 737/1050 (70%)

Epoch: 46
Training set [0/6430 (0%)] Loss: 0.038187
Training set [4480/6430 (67%)] Loss: 0.039816
Training set: Average loss: 0.026971
Training set: Average accuracy: 99.10%
Validation set: Average loss: 1.721695, Accuracy: 725/1050 (69%)

Epoch: 47
Training set [0/6430 (0%)] Loss: 0.022939
Training set [4480/6430 (67%)] Loss: 0.031024
Training set: Average loss: 0.025059
Training set: Average accuracy: 99.25%
Validation set: Average loss: 1.655956, Accuracy: 728/1050 (69%)

Epoch: 48
Training set [0/6430 (0%)] Loss: 0.014838
Training set [4480/6430 (67%)] Loss: 0.015482
Training set: Average loss: 0.024300
Training set: Average accuracy: 99.27%
Validation set: Average loss: 1.608971, Accuracy: 726/1050 (69%)

Epoch: 49
Training set [0/6430 (0%)] Loss: 0.014221
Training set [4480/6430 (67%)] Loss: 0.027876
Training set: Average loss: 0.028766
Training set: Average accuracy: 99.24%
Validation set: Average loss: 1.612104, Accuracy: 728/1050 (69%)

Epoch: 50
Training set [0/6430 (0%)] Loss: 0.020262
Training set [4480/6430 (67%)] Loss: 0.019250
Training set: Average loss: 0.029087
Training set: Average accuracy: 99.19%
Validation set: Average loss: 1.580419, Accuracy: 724/1050 (69%)

Epoch: 51
Training set [0/6430 (0%)] Loss: 0.027770
Training set [4480/6430 (67%)] Loss: 0.012199
Training set: Average loss: 0.023433
Training set: Average accuracy: 99.32%
Validation set: Average loss: 1.668190, Accuracy: 724/1050 (69%)

Epoch: 52
Training set [0/6430 (0%)] Loss: 0.030629
Training set [4480/6430 (67%)] Loss: 0.015720
Training set: Average loss: 0.021839
Training set: Average accuracy: 99.32%
Validation set: Average loss: 1.661405, Accuracy: 718/1050 (68%)

Epoch: 53
Training set [0/6430 (0%)] Loss: 0.049493
Training set [4480/6430 (67%)] Loss: 0.018772
Training set: Average loss: 0.026480
Training set: Average accuracy: 99.18%
Validation set: Average loss: 1.658583, Accuracy: 728/1050 (69%)

Epoch: 54
Training set [0/6430 (0%)] Loss: 0.039753
Training set [4480/6430 (67%)] Loss: 0.009626
Training set: Average loss: 0.017834
Training set: Average accuracy: 99.49%
Validation set: Average loss: 1.787698, Accuracy: 720/1050 (69%)

Epoch: 55
Training set [0/6430 (0%)] Loss: 0.016737
Training set [4480/6430 (67%)] Loss: 0.032215
Training set: Average loss: 0.025880
Training set: Average accuracy: 99.21%
Validation set: Average loss: 1.596809, Accuracy: 724/1050 (69%)

Epoch: 56
Training set [0/6430 (0%)] Loss: 0.021655
Training set [4480/6430 (67%)] Loss: 0.014587
Training set: Average loss: 0.022372
Training set: Average accuracy: 99.39%
Validation set: Average loss: 1.737827, Accuracy: 725/1050 (69%)

Epoch: 57
Training set [0/6430 (0%)] Loss: 0.022239
Training set [4480/6430 (67%)] Loss: 0.017543
Training set: Average loss: 0.025047
Training set: Average accuracy: 99.35%
Validation set: Average loss: 1.651962, Accuracy: 713/1050 (68%)

Epoch: 58
Training set [0/6430 (0%)] Loss: 0.037942
Training set [4480/6430 (67%)] Loss: 0.019149
Training set: Average loss: 0.025017
Training set: Average accuracy: 99.24%
Validation set: Average loss: 1.778917, Accuracy: 718/1050 (68%)

Epoch: 59
Training set [0/6430 (0%)] Loss: 0.023178
Training set [4480/6430 (67%)] Loss: 0.014276
Training set: Average loss: 0.025642
Training set: Average accuracy: 99.21%
Validation set: Average loss: 1.660783, Accuracy: 718/1050 (68%)

Epoch: 60
Training set [0/6430 (0%)] Loss: 0.029340
Training set [4480/6430 (67%)] Loss: 0.012537
Training set: Average loss: 0.022297
Training set: Average accuracy: 99.24%
Validation set: Average loss: 1.773411, Accuracy: 711/1050 (68%)

Epoch: 61
Training set [0/6430 (0%)] Loss: 0.011421
Training set [4480/6430 (67%)] Loss: 0.039160
Training set: Average loss: 0.021979
Training set: Average accuracy: 99.32%
Validation set: Average loss: 1.812643, Accuracy: 713/1050 (68%)

Epoch: 62
Training set [0/6430 (0%)] Loss: 0.012998
Training set [4480/6430 (67%)] Loss: 0.021533
Training set: Average loss: 0.021405
Training set: Average accuracy: 99.32%
Validation set: Average loss: 1.826588, Accuracy: 722/1050 (69%)

Epoch: 63
Training set [0/6430 (0%)] Loss: 0.027897
Training set [4480/6430 (67%)] Loss: 0.015023
Training set: Average loss: 0.021842
Training set: Average accuracy: 99.25%
Validation set: Average loss: 1.725051, Accuracy: 728/1050 (69%)

Epoch: 64
Training set [0/6430 (0%)] Loss: 0.039677
Training set [4480/6430 (67%)] Loss: 0.007363
Training set: Average loss: 0.023000
Training set: Average accuracy: 99.30%
Validation set: Average loss: 1.709479, Accuracy: 717/1050 (68%)

Early stopping: no improvement for 10 epochs
ImprovedNet
training_loss -- validation_loss
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]
[1.9788015286127727, 1.7914649804433187, 1.6457926114400228, 1.485851256052653, 1.3262640714645386, 1.1945383071899414, 1.060217273235321, 0.9282901128133138, 0.7948875228563944, 0.6675651987393697, 0.5559677898883819, 0.46235021352767947, 0.38284522891044614, 0.3219729999701182, 0.25043076475461323, 0.2381164183219274, 0.19881553053855897, 0.15312269578377405, 0.15048929701248806, 0.13994806855916977, 0.11233596603075663, 0.09856061935424805, 0.09105573097864787, 0.07973703444004059, 0.09094294408957164, 0.07145694767435391, 0.06172421822945277, 0.06094427506128947, 0.0561899778743585, 0.05639239102602005, 0.05292223940292994, 0.04916755358378092, 0.044860554734865825, 0.04022540263831616, 0.039306300381819405, 0.03634018525481224, 0.04745161297420661, 0.04085945288340251, 0.04248945297052463, 0.03369772893687089, 0.032172249257564546, 0.038838212564587596, 0.03797246317068736, 0.037951631223162016, 0.032819348573684695, 0.027743318987389406, 0.0269713306799531, 0.025059457682073117, 0.02430022054662307, 0.02876637987792492, 0.0290866124133269, 0.02343336697667837, 0.02183883860707283, 0.026479904353618623, 0.01783386655151844, 0.025879726372659208, 0.02237175777554512, 0.025047084068258604, 0.02501706350594759, 0.025641968411703905, 0.022297284472733735, 0.021978810553749402, 0.02140547651797533, 0.021842155264069636, 0.022999947207669416]
[1.8917605876922607, 1.8322546482086182, 1.5593374172846477, 1.5517713626225789, 1.3297869364420574, 1.3599745829900105, 1.2218961715698242, 1.2623679637908936, 1.1530895630518596, 1.1576515038808186, 1.1301324168841045, 1.1895567973454793, 1.0722941756248474, 1.0311843951543171, 1.0672672192255657, 1.2062015334765117, 1.1396074692408245, 1.2293581366539001, 1.1651819149653118, 1.165196379025777, 1.2472285230954487, 1.3235369126001995, 1.2896130482355754, 1.4227391084035237, 1.4539499680201213, 1.355576495329539, 1.412975509961446, 1.4789793888727825, 1.4660300413767497, 1.5038039684295654, 1.539717157681783, 1.5267470677693684, 1.5548886060714722, 1.5835665861765544, 1.6552301247914631, 1.7458731333414714, 1.5169596473375957, 1.6934173504511516, 1.5470854838689168, 1.7775518894195557, 1.5495270490646362, 1.688844919204712, 1.5628007650375366, 1.6259797016779582, 1.5742778380711873, 1.5779204368591309, 1.721695065498352, 1.6559560298919678, 1.6089711586634319, 1.6121042172114055, 1.5804185668627422, 1.668190360069275, 1.6614053845405579, 1.658583442370097, 1.7876983483632405, 1.5968085527420044, 1.7378273804982503, 1.651962399482727, 1.778916637102763, 1.6607829729715984, 1.7734111547470093, 1.8126426935195923, 1.8265877564748128, 1.7250508467356365, 1.7094788551330566]
ImprovedNet
training_accuracy -- validation_accuracy
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]
[17.356143079315707, 29.95334370139969, 38.66251944012442, 45.023328149300156, 51.50855365474339, 57.107309486780714, 61.788491446345255, 67.900466562986, 72.9860031104199, 77.04510108864697, 81.41524105754277, 84.5412130637636, 87.62052877138413, 89.51788491446345, 91.83514774494557, 92.06842923794713, 93.6547433903577, 95.36547433903577, 95.0855365474339, 95.42768273716952, 96.298600311042, 96.95178849144635, 97.34059097978228, 97.55832037325038, 97.1850699844479, 97.82270606531881, 98.14930015552099, 98.22706065318818, 98.24261275272161, 98.25816485225505, 98.22706065318818, 98.46034214618973, 98.56920684292379, 98.81804043545878, 98.70917573872472, 98.84914463452566, 98.39813374805598, 98.69362363919129, 98.67807153965785, 98.97356143079315, 98.97356143079315, 98.97356143079315, 98.83359253499222, 98.98911353032659, 98.8646967340591, 99.19129082426127, 99.09797822706065, 99.25349922239502, 99.26905132192846, 99.23794712286158, 99.19129082426127, 99.31570762052877, 99.31570762052877, 99.17573872472784, 99.48678071539658, 99.20684292379471, 99.39346811819595, 99.34681181959564, 99.23794712286158, 99.20684292379471, 99.23794712286158, 99.31570762052877, 99.31570762052877, 99.25349922239502, 99.30015552099533]
[26.19047619047619, 32.285714285714285, 38.76190476190476, 45.42857142857143, 50.476190476190474, 49.904761904761905, 55.142857142857146, 56.095238095238095, 60.857142857142854, 62.19047619047619, 63.714285714285715, 64.0, 64.76190476190476, 65.42857142857143, 66.95238095238095, 67.04761904761905, 67.23809523809524, 67.33333333333333, 67.42857142857143, 66.85714285714286, 67.33333333333333, 66.85714285714286, 67.71428571428571, 66.0, 67.23809523809524, 66.85714285714286, 67.33333333333333, 67.14285714285714, 66.0, 66.66666666666667, 68.38095238095238, 67.9047619047619, 68.19047619047619, 68.0952380952381, 67.9047619047619, 68.28571428571429, 68.38095238095238, 67.42857142857143, 68.76190476190476, 68.28571428571429, 68.0952380952381, 68.28571428571429, 68.38095238095238, 67.9047619047619, 67.9047619047619, 70.19047619047619, 69.04761904761905, 69.33333333333333, 69.14285714285714, 69.33333333333333, 68.95238095238095, 68.95238095238095, 68.38095238095238, 69.33333333333333, 68.57142857142857, 68.95238095238095, 69.04761904761905, 67.9047619047619, 68.38095238095238, 68.38095238095238, 67.71428571428571, 67.9047619047619, 68.76190476190476, 69.33333333333333, 68.28571428571429]
model saved as model_store_448/cnn_car_ImprovedNet.pt
Getting predictions from test set...
ImprovedNet
[[ 90   7   4  20  17   8   4]
 [ 12  81   7   7  15   7  21]
 [ 10   4 107   4   4   6  15]
 [ 37   2  11  83   7   1   9]
 [ 10   6   0   0 124   2   8]
 [  1   7   7  12   5 117   1]
 [  1  11   5   2  13   3 115]]
=============================
ImprovedNetLite
=============================
Epoch: 0
Training set [0/6430 (0%)] Loss: 2.067175
Training set [4480/6430 (67%)] Loss: 1.916587
Training set: Average loss: 2.724642
Training set: Average accuracy: 18.58%
Validation set: Average loss: 1.950389, Accuracy: 150/1050 (14%)

Epoch: 1
Training set [0/6430 (0%)] Loss: 1.898320
Training set [4480/6430 (67%)] Loss: 1.840463
Training set: Average loss: 1.846994
Training set: Average accuracy: 24.20%
Validation set: Average loss: 1.899154, Accuracy: 190/1050 (18%)

Epoch: 2
Training set [0/6430 (0%)] Loss: 1.777256
Training set [4480/6430 (67%)] Loss: 1.776276
Training set: Average loss: 1.767581
Training set: Average accuracy: 29.04%
Validation set: Average loss: 1.864143, Accuracy: 298/1050 (28%)

Epoch: 3
Training set [0/6430 (0%)] Loss: 1.663421
Training set [4480/6430 (67%)] Loss: 1.694475
Training set: Average loss: 1.691539
Training set: Average accuracy: 32.95%
Validation set: Average loss: 1.773774, Accuracy: 324/1050 (31%)

Epoch: 4
Training set [0/6430 (0%)] Loss: 1.683558
Training set [4480/6430 (67%)] Loss: 1.621405
Training set: Average loss: 1.616102
Training set: Average accuracy: 36.78%
Validation set: Average loss: 1.601918, Accuracy: 443/1050 (42%)

Epoch: 5
Training set [0/6430 (0%)] Loss: 1.594571
Training set [4480/6430 (67%)] Loss: 1.565828
Training set: Average loss: 1.559287
Training set: Average accuracy: 39.25%
Validation set: Average loss: 1.638480, Accuracy: 434/1050 (41%)

Epoch: 6
Training set [0/6430 (0%)] Loss: 1.467508
Training set [4480/6430 (67%)] Loss: 1.538139
Training set: Average loss: 1.505215
Training set: Average accuracy: 41.32%
Validation set: Average loss: 1.450705, Accuracy: 508/1050 (48%)

Epoch: 7
Training set [0/6430 (0%)] Loss: 1.450933
Training set [4480/6430 (67%)] Loss: 1.466780
Training set: Average loss: 1.452035
Training set: Average accuracy: 43.64%
Validation set: Average loss: 1.617073, Accuracy: 452/1050 (43%)

Epoch: 8
Training set [0/6430 (0%)] Loss: 1.438927
Training set [4480/6430 (67%)] Loss: 1.322232
Training set: Average loss: 1.386159
Training set: Average accuracy: 46.14%
Validation set: Average loss: 1.381105, Accuracy: 559/1050 (53%)

Epoch: 9
Training set [0/6430 (0%)] Loss: 1.370748
Training set [4480/6430 (67%)] Loss: 1.308118
Training set: Average loss: 1.336079
Training set: Average accuracy: 47.96%
Validation set: Average loss: 1.320699, Accuracy: 537/1050 (51%)

Epoch: 10
Training set [0/6430 (0%)] Loss: 1.307620
Training set [4480/6430 (67%)] Loss: 1.327837
Training set: Average loss: 1.306460
Training set: Average accuracy: 48.77%
Validation set: Average loss: 1.365401, Accuracy: 566/1050 (54%)

Epoch: 11
Training set [0/6430 (0%)] Loss: 1.224539
Training set [4480/6430 (67%)] Loss: 1.221135
Training set: Average loss: 1.261829
Training set: Average accuracy: 50.16%
Validation set: Average loss: 1.205219, Accuracy: 617/1050 (59%)

Epoch: 12
Training set [0/6430 (0%)] Loss: 1.223050
Training set [4480/6430 (67%)] Loss: 1.182344
Training set: Average loss: 1.217676
Training set: Average accuracy: 51.38%
Validation set: Average loss: 1.274153, Accuracy: 591/1050 (56%)

Epoch: 13
Training set [0/6430 (0%)] Loss: 1.192076
Training set [4480/6430 (67%)] Loss: 1.152629
Training set: Average loss: 1.165468
Training set: Average accuracy: 54.32%
Validation set: Average loss: 1.456280, Accuracy: 525/1050 (50%)

Epoch: 14
Training set [0/6430 (0%)] Loss: 1.147414
Training set [4480/6430 (67%)] Loss: 1.157521
Training set: Average loss: 1.124892
Training set: Average accuracy: 54.90%
Validation set: Average loss: 1.134017, Accuracy: 639/1050 (61%)

Epoch: 15
Training set [0/6430 (0%)] Loss: 1.046157
Training set [4480/6430 (67%)] Loss: 1.063740
Training set: Average loss: 1.078432
Training set: Average accuracy: 57.37%
Validation set: Average loss: 1.105072, Accuracy: 653/1050 (62%)

Epoch: 16
Training set [0/6430 (0%)] Loss: 1.054203
Training set [4480/6430 (67%)] Loss: 1.011218
Training set: Average loss: 1.073089
Training set: Average accuracy: 57.88%
Validation set: Average loss: 1.162603, Accuracy: 651/1050 (62%)

Epoch: 17
Training set [0/6430 (0%)] Loss: 1.034911
Training set [4480/6430 (67%)] Loss: 1.152731
Training set: Average loss: 1.022354
Training set: Average accuracy: 58.57%
Validation set: Average loss: 1.275312, Accuracy: 570/1050 (54%)

Epoch: 18
Training set [0/6430 (0%)] Loss: 1.069294
Training set [4480/6430 (67%)] Loss: 0.968697
Training set: Average loss: 0.982956
Training set: Average accuracy: 60.61%
Validation set: Average loss: 0.929467, Accuracy: 704/1050 (67%)

Epoch: 19
Training set [0/6430 (0%)] Loss: 0.947438
Training set [4480/6430 (67%)] Loss: 0.898061
Training set: Average loss: 0.948238
Training set: Average accuracy: 62.07%
Validation set: Average loss: 1.004629, Accuracy: 700/1050 (67%)

Epoch: 20
Training set [0/6430 (0%)] Loss: 0.984467
Training set [4480/6430 (67%)] Loss: 0.887825
Training set: Average loss: 0.946863
Training set: Average accuracy: 62.47%
Validation set: Average loss: 1.240662, Accuracy: 634/1050 (60%)

Epoch: 21
Training set [0/6430 (0%)] Loss: 0.937877
Training set [4480/6430 (67%)] Loss: 0.914136
Training set: Average loss: 0.937505
Training set: Average accuracy: 62.94%
Validation set: Average loss: 1.068683, Accuracy: 662/1050 (63%)

Epoch: 22
Training set [0/6430 (0%)] Loss: 0.815640
Training set [4480/6430 (67%)] Loss: 0.942846
Training set: Average loss: 0.878273
Training set: Average accuracy: 64.42%
Validation set: Average loss: 0.935619, Accuracy: 724/1050 (69%)

Epoch: 23
Training set [0/6430 (0%)] Loss: 0.784923
Training set [4480/6430 (67%)] Loss: 0.920236
Training set: Average loss: 0.860739
Training set: Average accuracy: 65.80%
Validation set: Average loss: 1.051403, Accuracy: 691/1050 (66%)

Epoch: 24
Training set [0/6430 (0%)] Loss: 0.803892
Training set [4480/6430 (67%)] Loss: 0.828005
Training set: Average loss: 0.840944
Training set: Average accuracy: 66.50%
Validation set: Average loss: 0.859812, Accuracy: 725/1050 (69%)

Epoch: 25
Training set [0/6430 (0%)] Loss: 0.827603
Training set [4480/6430 (67%)] Loss: 0.923654
Training set: Average loss: 0.811510
Training set: Average accuracy: 67.42%
Validation set: Average loss: 0.806267, Accuracy: 768/1050 (73%)

Epoch: 26
Training set [0/6430 (0%)] Loss: 0.759526
Training set [4480/6430 (67%)] Loss: 0.794043
Training set: Average loss: 0.797183
Training set: Average accuracy: 68.41%
Validation set: Average loss: 0.851678, Accuracy: 731/1050 (70%)

Epoch: 27
Training set [0/6430 (0%)] Loss: 0.785252
Training set [4480/6430 (67%)] Loss: 0.722534
Training set: Average loss: 0.760444
Training set: Average accuracy: 69.58%
Validation set: Average loss: 1.004478, Accuracy: 681/1050 (65%)

Epoch: 28
Training set [0/6430 (0%)] Loss: 0.748440
Training set [4480/6430 (67%)] Loss: 0.755365
Training set: Average loss: 0.742790
Training set: Average accuracy: 69.38%
Validation set: Average loss: 0.831127, Accuracy: 755/1050 (72%)

Epoch: 29
Training set [0/6430 (0%)] Loss: 0.817994
Training set [4480/6430 (67%)] Loss: 0.720645
Training set: Average loss: 0.765392
Training set: Average accuracy: 69.56%
Validation set: Average loss: 1.321079, Accuracy: 661/1050 (63%)

Epoch: 30
Training set [0/6430 (0%)] Loss: 0.679411
Training set [4480/6430 (67%)] Loss: 0.788972
Training set: Average loss: 0.761629
Training set: Average accuracy: 68.99%
Validation set: Average loss: 1.050198, Accuracy: 693/1050 (66%)

Epoch: 31
Training set [0/6430 (0%)] Loss: 0.828541
Training set [4480/6430 (67%)] Loss: 0.766941
Training set: Average loss: 0.752415
Training set: Average accuracy: 69.52%
Validation set: Average loss: 0.804252, Accuracy: 764/1050 (73%)

Epoch: 32
Training set [0/6430 (0%)] Loss: 0.684665
Training set [4480/6430 (67%)] Loss: 0.669295
Training set: Average loss: 0.692949
Training set: Average accuracy: 71.93%
Validation set: Average loss: 0.820471, Accuracy: 763/1050 (73%)

Epoch: 33
Training set [0/6430 (0%)] Loss: 0.617500
Training set [4480/6430 (67%)] Loss: 0.668128
Training set: Average loss: 0.664941
Training set: Average accuracy: 72.58%
Validation set: Average loss: 0.951100, Accuracy: 737/1050 (70%)

Epoch: 34
Training set [0/6430 (0%)] Loss: 0.653559
Training set [4480/6430 (67%)] Loss: 0.619769
Training set: Average loss: 0.663733
Training set: Average accuracy: 72.72%
Validation set: Average loss: 0.816890, Accuracy: 785/1050 (75%)

Epoch: 35
Training set [0/6430 (0%)] Loss: 0.625015
Training set [4480/6430 (67%)] Loss: 0.732448
Training set: Average loss: 0.661630
Training set: Average accuracy: 73.16%
Validation set: Average loss: 0.874038, Accuracy: 738/1050 (70%)

Epoch: 36
Training set [0/6430 (0%)] Loss: 0.693586
Training set [4480/6430 (67%)] Loss: 0.726820
Training set: Average loss: 0.666918
Training set: Average accuracy: 72.40%
Validation set: Average loss: 1.144969, Accuracy: 675/1050 (64%)

Epoch: 37
Training set [0/6430 (0%)] Loss: 0.686346
Training set [4480/6430 (67%)] Loss: 0.637285
Training set: Average loss: 0.661591
Training set: Average accuracy: 72.85%
Validation set: Average loss: 0.801623, Accuracy: 759/1050 (72%)

Epoch: 38
Training set [0/6430 (0%)] Loss: 0.660174
Training set [4480/6430 (67%)] Loss: 0.614116
Training set: Average loss: 0.634513
Training set: Average accuracy: 73.89%
Validation set: Average loss: 1.133427, Accuracy: 706/1050 (67%)

Epoch: 39
Training set [0/6430 (0%)] Loss: 0.631957
Training set [4480/6430 (67%)] Loss: 0.643844
Training set: Average loss: 0.625726
Training set: Average accuracy: 74.06%
Validation set: Average loss: 0.997473, Accuracy: 723/1050 (69%)

Epoch: 40
Training set [0/6430 (0%)] Loss: 0.704909
Training set [4480/6430 (67%)] Loss: 0.608656
Training set: Average loss: 0.646822
Training set: Average accuracy: 73.44%
Validation set: Average loss: 0.785671, Accuracy: 798/1050 (76%)

Epoch: 41
Training set [0/6430 (0%)] Loss: 0.691625
Training set [4480/6430 (67%)] Loss: 0.632729
Training set: Average loss: 0.612221
Training set: Average accuracy: 74.63%
Validation set: Average loss: 0.779264, Accuracy: 777/1050 (74%)

Epoch: 42
Training set [0/6430 (0%)] Loss: 0.577981
Training set [4480/6430 (67%)] Loss: 0.603265
Training set: Average loss: 0.602984
Training set: Average accuracy: 74.71%
Validation set: Average loss: 1.035269, Accuracy: 721/1050 (69%)

Epoch: 43
Training set [0/6430 (0%)] Loss: 0.583673
Training set [4480/6430 (67%)] Loss: 0.615214
Training set: Average loss: 0.591557
Training set: Average accuracy: 75.49%
Validation set: Average loss: 0.732112, Accuracy: 805/1050 (77%)

Epoch: 44
Training set [0/6430 (0%)] Loss: 0.548905
Training set [4480/6430 (67%)] Loss: 0.600217
Training set: Average loss: 0.591688
Training set: Average accuracy: 75.47%
Validation set: Average loss: 0.714263, Accuracy: 815/1050 (78%)

Epoch: 45
Training set [0/6430 (0%)] Loss: 0.575776
Training set [4480/6430 (67%)] Loss: 0.540829
Training set: Average loss: 0.570120
Training set: Average accuracy: 75.93%
Validation set: Average loss: 0.800657, Accuracy: 764/1050 (73%)

Epoch: 46
Training set [0/6430 (0%)] Loss: 0.589242
Training set [4480/6430 (67%)] Loss: 0.617383
Training set: Average loss: 0.580408
Training set: Average accuracy: 74.95%
Validation set: Average loss: 0.767544, Accuracy: 780/1050 (74%)

Epoch: 47
Training set [0/6430 (0%)] Loss: 0.564100
Training set [4480/6430 (67%)] Loss: 0.586353
Training set: Average loss: 0.564823
Training set: Average accuracy: 75.82%
Validation set: Average loss: 0.704347, Accuracy: 832/1050 (79%)

Epoch: 48
Training set [0/6430 (0%)] Loss: 0.529654
Training set [4480/6430 (67%)] Loss: 0.554138
Training set: Average loss: 0.546037
Training set: Average accuracy: 77.06%
Validation set: Average loss: 0.756593, Accuracy: 801/1050 (76%)

Epoch: 49
Training set [0/6430 (0%)] Loss: 0.564299
Training set [4480/6430 (67%)] Loss: 0.509204
Training set: Average loss: 0.542203
Training set: Average accuracy: 76.58%
Validation set: Average loss: 0.760340, Accuracy: 812/1050 (77%)

Epoch: 50
Training set [0/6430 (0%)] Loss: 0.513275
Training set [4480/6430 (67%)] Loss: 0.573774
Training set: Average loss: 0.520918
Training set: Average accuracy: 78.29%
Validation set: Average loss: 0.721897, Accuracy: 830/1050 (79%)

Epoch: 51
Training set [0/6430 (0%)] Loss: 0.458732
Training set [4480/6430 (67%)] Loss: 0.550858
Training set: Average loss: 0.529385
Training set: Average accuracy: 77.43%
Validation set: Average loss: 0.700297, Accuracy: 815/1050 (78%)

Epoch: 52
Training set [0/6430 (0%)] Loss: 0.559302
Training set [4480/6430 (67%)] Loss: 0.541737
Training set: Average loss: 0.525862
Training set: Average accuracy: 77.42%
Validation set: Average loss: 0.766415, Accuracy: 792/1050 (75%)

Epoch: 53
Training set [0/6430 (0%)] Loss: 0.513022
Training set [4480/6430 (67%)] Loss: 0.529999
Training set: Average loss: 0.519986
Training set: Average accuracy: 77.67%
Validation set: Average loss: 0.648920, Accuracy: 832/1050 (79%)

Epoch: 54
Training set [0/6430 (0%)] Loss: 0.522658
Training set [4480/6430 (67%)] Loss: 0.435186
Training set: Average loss: 0.501950
Training set: Average accuracy: 78.63%
Validation set: Average loss: 0.801512, Accuracy: 805/1050 (77%)

Epoch: 55
Training set [0/6430 (0%)] Loss: 0.576446
Training set [4480/6430 (67%)] Loss: 0.543697
Training set: Average loss: 0.512455
Training set: Average accuracy: 78.02%
Validation set: Average loss: 0.897394, Accuracy: 795/1050 (76%)

Epoch: 56
Training set [0/6430 (0%)] Loss: 0.398717
Training set [4480/6430 (67%)] Loss: 0.498836
Training set: Average loss: 0.501421
Training set: Average accuracy: 78.32%
Validation set: Average loss: 0.645995, Accuracy: 841/1050 (80%)

Epoch: 57
Training set [0/6430 (0%)] Loss: 0.407993
Training set [4480/6430 (67%)] Loss: 0.506250
Training set: Average loss: 0.495329
Training set: Average accuracy: 78.44%
Validation set: Average loss: 0.771441, Accuracy: 814/1050 (78%)

Epoch: 58
Training set [0/6430 (0%)] Loss: 0.530702
Training set [4480/6430 (67%)] Loss: 0.528395
Training set: Average loss: 0.527092
Training set: Average accuracy: 77.39%
Validation set: Average loss: 0.849339, Accuracy: 789/1050 (75%)

Epoch: 59
Training set [0/6430 (0%)] Loss: 0.572246
Training set [4480/6430 (67%)] Loss: 0.505667
Training set: Average loss: 0.509981
Training set: Average accuracy: 78.65%
Validation set: Average loss: 0.770261, Accuracy: 831/1050 (79%)

Epoch: 60
Training set [0/6430 (0%)] Loss: 0.481436
Training set [4480/6430 (67%)] Loss: 0.480311
Training set: Average loss: 0.506589
Training set: Average accuracy: 78.01%
Validation set: Average loss: 0.638744, Accuracy: 831/1050 (79%)

Epoch: 61
Training set [0/6430 (0%)] Loss: 0.515894
Training set [4480/6430 (67%)] Loss: 0.546734
Training set: Average loss: 0.486416
Training set: Average accuracy: 78.55%
Validation set: Average loss: 0.718356, Accuracy: 826/1050 (79%)

Epoch: 62
Training set [0/6430 (0%)] Loss: 0.406741
Training set [4480/6430 (67%)] Loss: 0.522498
Training set: Average loss: 0.504761
Training set: Average accuracy: 78.30%
Validation set: Average loss: 0.865675, Accuracy: 787/1050 (75%)

Epoch: 63
Training set [0/6430 (0%)] Loss: 0.422307
Training set [4480/6430 (67%)] Loss: 0.553389
Training set: Average loss: 0.499250
Training set: Average accuracy: 78.43%
Validation set: Average loss: 0.746223, Accuracy: 818/1050 (78%)

Epoch: 64
Training set [0/6430 (0%)] Loss: 0.510288
Training set [4480/6430 (67%)] Loss: 0.446750
Training set: Average loss: 0.490164
Training set: Average accuracy: 78.80%
Validation set: Average loss: 0.730574, Accuracy: 830/1050 (79%)

Epoch: 65
Training set [0/6430 (0%)] Loss: 0.416835
Training set [4480/6430 (67%)] Loss: 0.523888
Training set: Average loss: 0.475702
Training set: Average accuracy: 79.61%
Validation set: Average loss: 0.732186, Accuracy: 821/1050 (78%)

Epoch: 66
Training set [0/6430 (0%)] Loss: 0.434556
Training set [4480/6430 (67%)] Loss: 0.470819
Training set: Average loss: 0.463009
Training set: Average accuracy: 79.42%
Validation set: Average loss: 0.669971, Accuracy: 822/1050 (78%)

Epoch: 67
Training set [0/6430 (0%)] Loss: 0.409225
Training set [4480/6430 (67%)] Loss: 0.408107
Training set: Average loss: 0.458005
Training set: Average accuracy: 80.26%
Validation set: Average loss: 0.999004, Accuracy: 782/1050 (74%)

Epoch: 68
Training set [0/6430 (0%)] Loss: 0.501110
Training set [4480/6430 (67%)] Loss: 0.431251
Training set: Average loss: 0.453103
Training set: Average accuracy: 79.66%
Validation set: Average loss: 0.780377, Accuracy: 801/1050 (76%)

Epoch: 69
Training set [0/6430 (0%)] Loss: 0.445047
Training set [4480/6430 (67%)] Loss: 0.459521
Training set: Average loss: 0.461944
Training set: Average accuracy: 79.91%
Validation set: Average loss: 0.740861, Accuracy: 818/1050 (78%)

Epoch: 70
Training set [0/6430 (0%)] Loss: 0.446827
Training set [4480/6430 (67%)] Loss: 0.518960
Training set: Average loss: 0.468222
Training set: Average accuracy: 79.39%
Validation set: Average loss: 0.759115, Accuracy: 825/1050 (79%)

Epoch: 71
Training set [0/6430 (0%)] Loss: 0.433572
Training set [4480/6430 (67%)] Loss: 0.364673
Training set: Average loss: 0.448179
Training set: Average accuracy: 80.23%
Validation set: Average loss: 0.727423, Accuracy: 827/1050 (79%)

Epoch: 72
Training set [0/6430 (0%)] Loss: 0.450783
Training set [4480/6430 (67%)] Loss: 0.468813
Training set: Average loss: 0.461199
Training set: Average accuracy: 79.75%
Validation set: Average loss: 0.797671, Accuracy: 819/1050 (78%)

Epoch: 73
Training set [0/6430 (0%)] Loss: 0.446792
Training set [4480/6430 (67%)] Loss: 0.457380
Training set: Average loss: 0.449085
Training set: Average accuracy: 80.51%
Validation set: Average loss: 0.689362, Accuracy: 830/1050 (79%)

Epoch: 74
Training set [0/6430 (0%)] Loss: 0.384617
Training set [4480/6430 (67%)] Loss: 0.418268
Training set: Average loss: 0.448658
Training set: Average accuracy: 80.53%
Validation set: Average loss: 0.613970, Accuracy: 831/1050 (79%)

Epoch: 75
Training set [0/6430 (0%)] Loss: 0.454205
Training set [4480/6430 (67%)] Loss: 0.443471
Training set: Average loss: 0.440333
Training set: Average accuracy: 80.58%
Validation set: Average loss: 0.695233, Accuracy: 813/1050 (77%)

Epoch: 76
Training set [0/6430 (0%)] Loss: 0.357307
Training set [4480/6430 (67%)] Loss: 0.504834
Training set: Average loss: 0.424815
Training set: Average accuracy: 80.73%
Validation set: Average loss: 0.634773, Accuracy: 849/1050 (81%)

Epoch: 77
Training set [0/6430 (0%)] Loss: 0.526668
Training set [4480/6430 (67%)] Loss: 0.529049
Training set: Average loss: 0.451070
Training set: Average accuracy: 80.11%
Validation set: Average loss: 0.771187, Accuracy: 833/1050 (79%)

Epoch: 78
Training set [0/6430 (0%)] Loss: 0.422829
Training set [4480/6430 (67%)] Loss: 0.466023
Training set: Average loss: 0.438300
Training set: Average accuracy: 80.65%
Validation set: Average loss: 0.783086, Accuracy: 797/1050 (76%)

Epoch: 79
Training set [0/6430 (0%)] Loss: 0.383081
Training set [4480/6430 (67%)] Loss: 0.394046
Training set: Average loss: 0.421934
Training set: Average accuracy: 80.76%
Validation set: Average loss: 0.653502, Accuracy: 845/1050 (80%)

Epoch: 80
Training set [0/6430 (0%)] Loss: 0.387392
Training set [4480/6430 (67%)] Loss: 0.397021
Training set: Average loss: 0.407721
Training set: Average accuracy: 81.84%
Validation set: Average loss: 0.684243, Accuracy: 867/1050 (83%)

Epoch: 81
Training set [0/6430 (0%)] Loss: 0.414586
Training set [4480/6430 (67%)] Loss: 0.427498
Training set: Average loss: 0.414688
Training set: Average accuracy: 81.51%
Validation set: Average loss: 0.689378, Accuracy: 834/1050 (79%)

Epoch: 82
Training set [0/6430 (0%)] Loss: 0.381664
Training set [4480/6430 (67%)] Loss: 0.446221
Training set: Average loss: 0.423529
Training set: Average accuracy: 80.92%
Validation set: Average loss: 1.007100, Accuracy: 758/1050 (72%)

Epoch: 83
Training set [0/6430 (0%)] Loss: 0.416392
Training set [4480/6430 (67%)] Loss: 0.468196
Training set: Average loss: 0.432968
Training set: Average accuracy: 79.95%
Validation set: Average loss: 0.782803, Accuracy: 815/1050 (78%)

Epoch: 84
Training set [0/6430 (0%)] Loss: 0.403953
Training set [4480/6430 (67%)] Loss: 0.437431
Training set: Average loss: 0.423529
Training set: Average accuracy: 81.56%
Validation set: Average loss: 0.627502, Accuracy: 854/1050 (81%)

Epoch: 85
Training set [0/6430 (0%)] Loss: 0.399093
Training set [4480/6430 (67%)] Loss: 0.406184
Training set: Average loss: 0.432074
Training set: Average accuracy: 80.70%
Validation set: Average loss: 0.745273, Accuracy: 820/1050 (78%)

Epoch: 86
Training set [0/6430 (0%)] Loss: 0.446779
Training set [4480/6430 (67%)] Loss: 0.466321
Training set: Average loss: 0.427645
Training set: Average accuracy: 81.37%
Validation set: Average loss: 0.756140, Accuracy: 809/1050 (77%)

Epoch: 87
Training set [0/6430 (0%)] Loss: 0.439229
Training set [4480/6430 (67%)] Loss: 0.481799
Training set: Average loss: 0.412728
Training set: Average accuracy: 81.26%
Validation set: Average loss: 0.713309, Accuracy: 818/1050 (78%)

Epoch: 88
Training set [0/6430 (0%)] Loss: 0.452031
Training set [4480/6430 (67%)] Loss: 0.366854
Training set: Average loss: 0.398241
Training set: Average accuracy: 82.13%
Validation set: Average loss: 0.622801, Accuracy: 866/1050 (82%)

Epoch: 89
Training set [0/6430 (0%)] Loss: 0.372815
Training set [4480/6430 (67%)] Loss: 0.412291
Training set: Average loss: 0.400928
Training set: Average accuracy: 83.03%
Validation set: Average loss: 0.695006, Accuracy: 838/1050 (80%)

Epoch: 90
Training set [0/6430 (0%)] Loss: 0.403586
Training set [4480/6430 (67%)] Loss: 0.439349
Training set: Average loss: 0.407238
Training set: Average accuracy: 81.82%
Validation set: Average loss: 1.027198, Accuracy: 755/1050 (72%)

Epoch: 91
Training set [0/6430 (0%)] Loss: 0.410082
Training set [4480/6430 (67%)] Loss: 0.450595
Training set: Average loss: 0.421997
Training set: Average accuracy: 80.89%
Validation set: Average loss: 0.779393, Accuracy: 825/1050 (79%)

Epoch: 92
Training set [0/6430 (0%)] Loss: 0.409985
Training set [4480/6430 (67%)] Loss: 0.338958
Training set: Average loss: 0.403675
Training set: Average accuracy: 81.68%
Validation set: Average loss: 0.653433, Accuracy: 838/1050 (80%)

Epoch: 93
Training set [0/6430 (0%)] Loss: 0.373091
Training set [4480/6430 (67%)] Loss: 0.421143
Training set: Average loss: 0.416805
Training set: Average accuracy: 81.63%
Validation set: Average loss: 0.666385, Accuracy: 847/1050 (81%)

Epoch: 94
Training set [0/6430 (0%)] Loss: 0.403363
Training set [4480/6430 (67%)] Loss: 0.378614
Training set: Average loss: 0.381397
Training set: Average accuracy: 82.71%
Validation set: Average loss: 0.633711, Accuracy: 841/1050 (80%)

Epoch: 95
Training set [0/6430 (0%)] Loss: 0.398068
Training set [4480/6430 (67%)] Loss: 0.430694
Training set: Average loss: 0.397437
Training set: Average accuracy: 82.57%
Validation set: Average loss: 0.671709, Accuracy: 864/1050 (82%)

Epoch: 96
Training set [0/6430 (0%)] Loss: 0.405687
Training set [4480/6430 (67%)] Loss: 0.446889
Training set: Average loss: 0.406786
Training set: Average accuracy: 81.59%
Validation set: Average loss: 0.701864, Accuracy: 827/1050 (79%)

Epoch: 97
Training set [0/6430 (0%)] Loss: 0.370025
Training set [4480/6430 (67%)] Loss: 0.428304
Training set: Average loss: 0.399045
Training set: Average accuracy: 82.40%
Validation set: Average loss: 0.645599, Accuracy: 830/1050 (79%)

Epoch: 98
Training set [0/6430 (0%)] Loss: 0.398495
Training set [4480/6430 (67%)] Loss: 0.385557
Training set: Average loss: 0.396987
Training set: Average accuracy: 82.10%
Validation set: Average loss: 0.865577, Accuracy: 790/1050 (75%)

Epoch: 99
Training set [0/6430 (0%)] Loss: 0.399389
Training set [4480/6430 (67%)] Loss: 0.395475
Training set: Average loss: 0.386551
Training set: Average accuracy: 82.72%
Validation set: Average loss: 0.750745, Accuracy: 832/1050 (79%)

Epoch: 100
Training set [0/6430 (0%)] Loss: 0.340969
Training set [4480/6430 (67%)] Loss: 0.385887
Training set: Average loss: 0.404341
Training set: Average accuracy: 82.29%
Validation set: Average loss: 0.764668, Accuracy: 844/1050 (80%)

Epoch: 101
Training set [0/6430 (0%)] Loss: 0.423327
Training set [4480/6430 (67%)] Loss: 0.455355
Training set: Average loss: 0.395593
Training set: Average accuracy: 82.32%
Validation set: Average loss: 0.826644, Accuracy: 842/1050 (80%)

Epoch: 102
Training set [0/6430 (0%)] Loss: 0.395650
Training set [4480/6430 (67%)] Loss: 0.316121
Training set: Average loss: 0.389854
Training set: Average accuracy: 82.44%
Validation set: Average loss: 0.712148, Accuracy: 816/1050 (78%)

Epoch: 103
Training set [0/6430 (0%)] Loss: 0.424877
Training set [4480/6430 (67%)] Loss: 0.388552
Training set: Average loss: 0.379221
Training set: Average accuracy: 83.03%
Validation set: Average loss: 0.691617, Accuracy: 844/1050 (80%)

Epoch: 104
Training set [0/6430 (0%)] Loss: 0.411017
Training set [4480/6430 (67%)] Loss: 0.361653
Training set: Average loss: 0.381449
Training set: Average accuracy: 82.80%
Validation set: Average loss: 0.752053, Accuracy: 823/1050 (78%)

Epoch: 105
Training set [0/6430 (0%)] Loss: 0.371326
Training set [4480/6430 (67%)] Loss: 0.415321
Training set: Average loss: 0.380183
Training set: Average accuracy: 82.66%
Validation set: Average loss: 0.711711, Accuracy: 837/1050 (80%)

Epoch: 106
Training set [0/6430 (0%)] Loss: 0.345685
Training set [4480/6430 (67%)] Loss: 0.399254
Training set: Average loss: 0.389593
Training set: Average accuracy: 82.83%
Validation set: Average loss: 0.800284, Accuracy: 837/1050 (80%)

Epoch: 107
Training set [0/6430 (0%)] Loss: 0.393286
Training set [4480/6430 (67%)] Loss: 0.437993
Training set: Average loss: 0.397958
Training set: Average accuracy: 82.50%
Validation set: Average loss: 0.993897, Accuracy: 801/1050 (76%)

Epoch: 108
Training set [0/6430 (0%)] Loss: 0.419962
Training set [4480/6430 (67%)] Loss: 0.404933
Training set: Average loss: 0.394340
Training set: Average accuracy: 82.16%
Validation set: Average loss: 0.707721, Accuracy: 839/1050 (80%)

Epoch: 109
Training set [0/6430 (0%)] Loss: 0.432356
Training set [4480/6430 (67%)] Loss: 0.422607
Training set: Average loss: 0.387973
Training set: Average accuracy: 82.72%
Validation set: Average loss: 0.733271, Accuracy: 844/1050 (80%)

Epoch: 110
Training set [0/6430 (0%)] Loss: 0.338766
Training set [4480/6430 (67%)] Loss: 0.422131
Training set: Average loss: 0.382240
Training set: Average accuracy: 83.05%
Validation set: Average loss: 0.881607, Accuracy: 797/1050 (76%)

Epoch: 111
Training set [0/6430 (0%)] Loss: 0.397507
Training set [4480/6430 (67%)] Loss: 0.344194
Training set: Average loss: 0.386829
Training set: Average accuracy: 82.92%
Validation set: Average loss: 0.750486, Accuracy: 829/1050 (79%)

Epoch: 112
Training set [0/6430 (0%)] Loss: 0.403723
Training set [4480/6430 (67%)] Loss: 0.348763
Training set: Average loss: 0.375989
Training set: Average accuracy: 82.95%
Validation set: Average loss: 0.665870, Accuracy: 860/1050 (82%)

Epoch: 113
Training set [0/6430 (0%)] Loss: 0.350879
Training set [4480/6430 (67%)] Loss: 0.364973
Training set: Average loss: 0.376892
Training set: Average accuracy: 83.37%
Validation set: Average loss: 0.615805, Accuracy: 862/1050 (82%)

Epoch: 114
Training set [0/6430 (0%)] Loss: 0.330555
Training set [4480/6430 (67%)] Loss: 0.341726
Training set: Average loss: 0.363544
Training set: Average accuracy: 83.90%
Validation set: Average loss: 0.743519, Accuracy: 837/1050 (80%)

Epoch: 115
Training set [0/6430 (0%)] Loss: 0.330767
Training set [4480/6430 (67%)] Loss: 0.347463
Training set: Average loss: 0.350706
Training set: Average accuracy: 84.28%
Validation set: Average loss: 0.922161, Accuracy: 805/1050 (77%)

Epoch: 116
Training set [0/6430 (0%)] Loss: 0.321669
Training set [4480/6430 (67%)] Loss: 0.345741
Training set: Average loss: 0.374072
Training set: Average accuracy: 82.97%
Validation set: Average loss: 0.856325, Accuracy: 802/1050 (76%)

Epoch: 117
Training set [0/6430 (0%)] Loss: 0.393614
Training set [4480/6430 (67%)] Loss: 0.349367
Training set: Average loss: 0.373745
Training set: Average accuracy: 83.03%
Validation set: Average loss: 0.645246, Accuracy: 848/1050 (81%)

Epoch: 118
Training set [0/6430 (0%)] Loss: 0.318926
Training set [4480/6430 (67%)] Loss: 0.386459
Training set: Average loss: 0.360048
Training set: Average accuracy: 83.62%
Validation set: Average loss: 0.785908, Accuracy: 823/1050 (78%)

Epoch: 119
Training set [0/6430 (0%)] Loss: 0.375358
Training set [4480/6430 (67%)] Loss: 0.356168
Training set: Average loss: 0.349793
Training set: Average accuracy: 84.37%
Validation set: Average loss: 0.967669, Accuracy: 819/1050 (78%)

Epoch: 120
Training set [0/6430 (0%)] Loss: 0.378660
Training set [4480/6430 (67%)] Loss: 0.341833
Training set: Average loss: 0.357204
Training set: Average accuracy: 83.64%
Validation set: Average loss: 0.625452, Accuracy: 872/1050 (83%)

Epoch: 121
Training set [0/6430 (0%)] Loss: 0.355777
Training set [4480/6430 (67%)] Loss: 0.399924
Training set: Average loss: 0.364582
Training set: Average accuracy: 83.90%
Validation set: Average loss: 0.735213, Accuracy: 852/1050 (81%)

Epoch: 122
Training set [0/6430 (0%)] Loss: 0.349407
Training set [4480/6430 (67%)] Loss: 0.330319
Training set: Average loss: 0.378463
Training set: Average accuracy: 83.20%
Validation set: Average loss: 0.875099, Accuracy: 822/1050 (78%)

Epoch: 123
Training set [0/6430 (0%)] Loss: 0.394206
Training set [4480/6430 (67%)] Loss: 0.376170
Training set: Average loss: 0.375780
Training set: Average accuracy: 82.85%
Validation set: Average loss: 0.667065, Accuracy: 864/1050 (82%)

Epoch: 124
Training set [0/6430 (0%)] Loss: 0.413545
Training set [4480/6430 (67%)] Loss: 0.374396
Training set: Average loss: 0.360948
Training set: Average accuracy: 83.70%
Validation set: Average loss: 0.699584, Accuracy: 845/1050 (80%)

Epoch: 125
Training set [0/6430 (0%)] Loss: 0.323050
Training set [4480/6430 (67%)] Loss: 0.334825
Training set: Average loss: 0.364355
Training set: Average accuracy: 84.01%
Validation set: Average loss: 0.711851, Accuracy: 846/1050 (81%)

Epoch: 126
Training set [0/6430 (0%)] Loss: 0.429869
Training set [4480/6430 (67%)] Loss: 0.342563
Training set: Average loss: 0.372535
Training set: Average accuracy: 83.83%
Validation set: Average loss: 0.820643, Accuracy: 825/1050 (79%)

Epoch: 127
Training set [0/6430 (0%)] Loss: 0.338192
Training set [4480/6430 (67%)] Loss: 0.331142
Training set: Average loss: 0.364800
Training set: Average accuracy: 84.20%
Validation set: Average loss: 0.779298, Accuracy: 847/1050 (81%)

Epoch: 128
Training set [0/6430 (0%)] Loss: 0.362527
Training set [4480/6430 (67%)] Loss: 0.367963
Training set: Average loss: 0.371756
Training set: Average accuracy: 84.14%
Validation set: Average loss: 0.783377, Accuracy: 818/1050 (78%)

Epoch: 129
Training set [0/6430 (0%)] Loss: 0.334333
Training set [4480/6430 (67%)] Loss: 0.382133
Training set: Average loss: 0.363633
Training set: Average accuracy: 83.72%
Validation set: Average loss: 0.700331, Accuracy: 835/1050 (80%)

Early stopping: no improvement for 10 epochs
ImprovedNetLite
training_loss -- validation_loss
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129]
[2.7246418952941895, 1.8469935019810995, 1.7675810972849528, 1.6915387550989787, 1.6161020199457805, 1.5592869679133097, 1.5052147467931112, 1.4520346879959107, 1.3861594994862874, 1.3360787868499755, 1.3064602533976237, 1.2618287007013957, 1.21767631371816, 1.1654676834742228, 1.1248924096425374, 1.078432313601176, 1.073088562488556, 1.0223543564478557, 0.9829558293024699, 0.9482377648353577, 0.9468634088834127, 0.937504776318868, 0.8782729307810465, 0.8607394297917684, 0.8409441232681274, 0.8115095893541971, 0.7971826076507569, 0.7604437947273255, 0.7427903811136881, 0.7653920690218607, 0.7616292277971903, 0.7524151802062988, 0.6929493467013041, 0.6649409651756286, 0.6637326916058858, 0.6616303006807963, 0.6669180790583292, 0.6615908106168111, 0.6345126032829285, 0.6257263541221618, 0.6468217015266419, 0.6122211416562399, 0.6029840707778931, 0.5915567398071289, 0.5916881759961446, 0.5701200028260549, 0.580407992998759, 0.5648231863975525, 0.5460365235805511, 0.5422031819820404, 0.5209178924560547, 0.5293853441874187, 0.5258615036805471, 0.5199862400690715, 0.5019498407840729, 0.5124546349048614, 0.5014206608136494, 0.4953293999036153, 0.5270916938781738, 0.5099810500939687, 0.5065886596838634, 0.48641617099444073, 0.5047608097394307, 0.49924959341684977, 0.4901643693447113, 0.47570227781931557, 0.4630085349082947, 0.4580047865708669, 0.45310322046279905, 0.46194392442703247, 0.468221773703893, 0.4481789211432139, 0.46119937896728513, 0.4490848918755849, 0.44865785241127015, 0.4403332968552907, 0.424814776579539, 0.45106975038846336, 0.438300214211146, 0.42193403442700705, 0.4077208081881205, 0.41468847592671715, 0.42352853616078695, 0.43296790520350137, 0.4235285520553589, 0.4320735275745392, 0.42764468987782794, 0.41272836724917095, 0.398240872224172, 0.40092785358428956, 0.40723770260810854, 0.4219966471195221, 0.40367484887441, 0.4168049097061157, 0.38139716784159344, 0.3974367300669352, 0.4067863921324412, 0.39904489119847614, 0.39698711832364403, 0.3865514119466146, 0.4043410122394562, 0.3955929736296336, 0.38985445896784465, 0.37922062079111735, 0.38144922256469727, 0.380183215936025, 0.3895927647749583, 0.39795756538709004, 0.39434016942977906, 0.38797338008880616, 0.3822404722372691, 0.38682902852694195, 0.37598904967308044, 0.37689154942830405, 0.36354373693466185, 0.35070579051971434, 0.3740716377894084, 0.37374474803606667, 0.3600477715333303, 0.3497932275136312, 0.35720362067222594, 0.36458158294359844, 0.3784628291924795, 0.3757802943388621, 0.3609480301539103, 0.364355339606603, 0.37253456910451255, 0.3647998789946238, 0.3717562238375346, 0.3636327008406321]
[1.9503894646962483, 1.8991541067759197, 1.864142934481303, 1.7737739483515422, 1.6019182602564495, 1.6384798685709636, 1.4507050514221191, 1.6170730193456013, 1.3811045090357463, 1.3206986983617146, 1.3654005130132039, 1.2052192687988281, 1.2741527557373047, 1.456280032793681, 1.1340174476305644, 1.1050723791122437, 1.1626029809315999, 1.2753122647603352, 0.9294673204421997, 1.004629373550415, 1.2406622767448425, 1.068683127562205, 0.9356189767519633, 1.0514034827550252, 0.8598122596740723, 0.806266725063324, 0.8516775767008463, 1.0044777393341064, 0.8311274250348409, 1.3210789958635967, 1.0501978198687236, 0.8042524655659994, 0.820471465587616, 0.9511001110076904, 0.8168903191884359, 0.8740380803743998, 1.1449685494105022, 0.8016227682431539, 1.133427361647288, 0.9974727431933085, 0.7856714328130087, 0.7792636156082153, 1.0352694988250732, 0.7321121493975321, 0.7142630815505981, 0.8006567358970642, 0.7675442099571228, 0.7043466369311014, 0.7565931677818298, 0.760339617729187, 0.7218967874844869, 0.7002965211868286, 0.7664154271284739, 0.6489200294017792, 0.8015119234720866, 0.8973939418792725, 0.6459953586260477, 0.7714410821596781, 0.8493391076723734, 0.7702610492706299, 0.63874351978302, 0.7183562914530436, 0.8656754295031229, 0.7462231318155924, 0.7305743296941122, 0.732185979684194, 0.6699711084365845, 0.9990043640136719, 0.7803765734036764, 0.7408605416615804, 0.7591152588526408, 0.7274229526519775, 0.7976714571317037, 0.6893620193004608, 0.6139697333176931, 0.6952330271402994, 0.6347730358441671, 0.7711865107218424, 0.7830863992373148, 0.6535020967324575, 0.6842433214187622, 0.6893782218297323, 1.0070997873942058, 0.7828025023142496, 0.6275023917357127, 0.7452726364135742, 0.7561403413613638, 0.7133085529009501, 0.6228010952472687, 0.6950057943662008, 1.027197500069936, 0.7793926695982615, 0.6534333825111389, 0.6663851936658224, 0.6337112983067831, 0.6717094480991364, 0.7018643021583557, 0.6455990076065063, 0.8655773599942526, 0.7507452170054117, 0.7646678884824117, 0.8266435066858927, 0.71214792629083, 0.691616932551066, 0.7520527044932047, 0.7117108404636383, 0.8002835089961687, 0.9938967625300089, 0.7077214519182841, 0.7332712709903717, 0.8816066682338715, 0.750486413637797, 0.6658700505892435, 0.6158051490783691, 0.7435192465782166, 0.9221612016359965, 0.8563250601291656, 0.6452463865280151, 0.7859079639116923, 0.9676693280537924, 0.6254523495833079, 0.7352130015691122, 0.8750988642374674, 0.6670652528603872, 0.6995841016372045, 0.7118506828943888, 0.8206430474917094, 0.7792975505193075, 0.7833768626054128, 0.7003313302993774]
ImprovedNetLite
training_accuracy -- validation_accuracy
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129]
[18.58475894245723, 24.199066874027995, 29.035769828926906, 32.954898911353034, 36.780715396578536, 39.25349922239502, 41.32192846034214, 43.639191290824265, 46.143079315707624, 47.96267496111975, 48.77138413685847, 50.15552099533437, 51.38413685847589, 54.32348367029549, 54.89891135303266, 57.371695178849144, 57.88491446345257, 58.5692068429238, 60.606531881804045, 62.06842923794712, 62.472783825816485, 62.9393468118196, 64.41679626749611, 65.80093312597201, 66.50077760497668, 67.41835147744946, 68.41368584758942, 69.5800933125972, 69.37791601866252, 69.56454121306376, 68.98911353032659, 69.51788491446345, 71.9284603421462, 72.58164852255054, 72.72161741835147, 73.15707620528771, 72.3950233281493, 72.84603421461897, 73.88802488335925, 74.05909797822706, 73.43701399688958, 74.63452566096423, 74.71228615863141, 75.48989113530327, 75.47433903576983, 75.9253499222395, 74.94556765163297, 75.81648522550545, 77.06065318818041, 76.57853810264386, 78.28926905132192, 77.4339035769829, 77.41835147744946, 77.66718506998444, 78.63141524105754, 78.0248833592535, 78.3203732503888, 78.4447900466563, 77.38724727838259, 78.64696734059098, 78.00933125972006, 78.55365474339035, 78.30482115085536, 78.42923794712286, 78.80248833592535, 79.61119751166407, 79.42457231726283, 80.26438569206843, 79.65785381026438, 79.90668740279938, 79.39346811819595, 80.23328149300156, 79.751166407465, 80.51321928460342, 80.52877138413686, 80.57542768273717, 80.73094867807154, 80.10886469673406, 80.65318818040436, 80.76205287713842, 81.83514774494557, 81.5085536547434, 80.91757387247279, 79.95334370139969, 81.5552099533437, 80.69984447900467, 81.36858475894246, 81.2597200622084, 82.13063763608088, 83.03265940902021, 81.81959564541214, 80.88646967340591, 81.6796267496112, 81.63297045101089, 82.70606531881803, 82.5660964230171, 81.58631415241058, 82.3950233281493, 82.099533437014, 82.72161741835147, 82.28615863141525, 82.31726283048212, 82.44167962674962, 83.03265940902021, 82.79937791601866, 82.65940902021772, 82.83048211508553, 82.50388802488335, 82.16174183514775, 82.72161741835147, 83.04821150855365, 82.92379471228615, 82.95489891135303, 83.37480559875583, 83.90357698289269, 84.27682737169518, 82.97045101088646, 83.03265940902021, 83.62363919129082, 84.3701399688958, 83.63919129082426, 83.90357698289269, 83.20373250388802, 82.84603421461897, 83.701399688958, 84.01244167962675, 83.8258164852255, 84.19906687402799, 84.13685847589424, 83.71695178849144]
[14.285714285714286, 18.095238095238095, 28.38095238095238, 30.857142857142858, 42.19047619047619, 41.333333333333336, 48.38095238095238, 43.04761904761905, 53.23809523809524, 51.142857142857146, 53.904761904761905, 58.76190476190476, 56.285714285714285, 50.0, 60.857142857142854, 62.19047619047619, 62.0, 54.285714285714285, 67.04761904761905, 66.66666666666667, 60.38095238095238, 63.04761904761905, 68.95238095238095, 65.80952380952381, 69.04761904761905, 73.14285714285714, 69.61904761904762, 64.85714285714286, 71.9047619047619, 62.95238095238095, 66.0, 72.76190476190476, 72.66666666666667, 70.19047619047619, 74.76190476190476, 70.28571428571429, 64.28571428571429, 72.28571428571429, 67.23809523809524, 68.85714285714286, 76.0, 74.0, 68.66666666666667, 76.66666666666667, 77.61904761904762, 72.76190476190476, 74.28571428571429, 79.23809523809524, 76.28571428571429, 77.33333333333333, 79.04761904761905, 77.61904761904762, 75.42857142857143, 79.23809523809524, 76.66666666666667, 75.71428571428571, 80.0952380952381, 77.52380952380952, 75.14285714285714, 79.14285714285714, 79.14285714285714, 78.66666666666667, 74.95238095238095, 77.9047619047619, 79.04761904761905, 78.19047619047619, 78.28571428571429, 74.47619047619048, 76.28571428571429, 77.9047619047619, 78.57142857142857, 78.76190476190476, 78.0, 79.04761904761905, 79.14285714285714, 77.42857142857143, 80.85714285714286, 79.33333333333333, 75.9047619047619, 80.47619047619048, 82.57142857142857, 79.42857142857143, 72.19047619047619, 77.61904761904762, 81.33333333333333, 78.0952380952381, 77.04761904761905, 77.9047619047619, 82.47619047619048, 79.80952380952381, 71.9047619047619, 78.57142857142857, 79.80952380952381, 80.66666666666667, 80.0952380952381, 82.28571428571429, 78.76190476190476, 79.04761904761905, 75.23809523809524, 79.23809523809524, 80.38095238095238, 80.19047619047619, 77.71428571428571, 80.38095238095238, 78.38095238095238, 79.71428571428571, 79.71428571428571, 76.28571428571429, 79.9047619047619, 80.38095238095238, 75.9047619047619, 78.95238095238095, 81.9047619047619, 82.0952380952381, 79.71428571428571, 76.66666666666667, 76.38095238095238, 80.76190476190476, 78.38095238095238, 78.0, 83.04761904761905, 81.14285714285714, 78.28571428571429, 82.28571428571429, 80.47619047619048, 80.57142857142857, 78.57142857142857, 80.66666666666667, 77.9047619047619, 79.52380952380952]
model saved as model_store_448/cnn_car_ImprovedNetLite.pt
Getting predictions from test set...
ImprovedNetLite
[[123   1   0   8  10   4   4]
 [  2 104   0   1  12   8  23]
 [  2   3 109   3   7  13  13]
 [ 25   0   2 101   6  10   6]
 [  2   1   0   0 138   3   6]
 [  4   7   3   3   5 123   5]
 [  0   2   3   1   3   4 137]]
Data loaders ready
=============================
BasicNet
=============================
Epoch: 0
Training set [0/6430 (0%)] Loss: 1.996523
Training set [3840/6430 (59%)] Loss: 1.974201
Training set: Average loss: 2.954692
Training set: Average accuracy: 17.93%
Validation set: Average loss: 1.949843, Accuracy: 153/1050 (15%)

Epoch: 1
Training set [0/6430 (0%)] Loss: 1.929239
Training set [3840/6430 (59%)] Loss: 1.880252
Training set: Average loss: 1.887171
Training set: Average accuracy: 20.11%
Validation set: Average loss: 1.925686, Accuracy: 186/1050 (18%)

Epoch: 2
Training set [0/6430 (0%)] Loss: 1.899791
Training set [3840/6430 (59%)] Loss: 1.803514
Training set: Average loss: 1.830910
Training set: Average accuracy: 23.84%
Validation set: Average loss: 1.849965, Accuracy: 245/1050 (23%)

Epoch: 3
Training set [0/6430 (0%)] Loss: 1.874545
Training set [3840/6430 (59%)] Loss: 1.758924
Training set: Average loss: 1.774237
Training set: Average accuracy: 26.11%
Validation set: Average loss: 1.780982, Accuracy: 327/1050 (31%)

Epoch: 4
Training set [0/6430 (0%)] Loss: 1.772454
Training set [3840/6430 (59%)] Loss: 1.705802
Training set: Average loss: 1.721836
Training set: Average accuracy: 28.69%
Validation set: Average loss: 1.702110, Accuracy: 375/1050 (36%)

Epoch: 5
Training set [0/6430 (0%)] Loss: 1.715748
Training set [3840/6430 (59%)] Loss: 1.680452
Training set: Average loss: 1.661587
Training set: Average accuracy: 31.94%
Validation set: Average loss: 1.647566, Accuracy: 360/1050 (34%)

Epoch: 6
Training set [0/6430 (0%)] Loss: 1.653498
Training set [3840/6430 (59%)] Loss: 1.554440
Training set: Average loss: 1.618039
Training set: Average accuracy: 33.53%
Validation set: Average loss: 1.622482, Accuracy: 383/1050 (36%)

Epoch: 7
Training set [0/6430 (0%)] Loss: 1.594439
Training set [3840/6430 (59%)] Loss: 1.562302
Training set: Average loss: 1.570405
Training set: Average accuracy: 36.78%
Validation set: Average loss: 1.547260, Accuracy: 438/1050 (42%)

Epoch: 8
Training set [0/6430 (0%)] Loss: 1.574670
Training set [3840/6430 (59%)] Loss: 1.611697
Training set: Average loss: 1.524332
Training set: Average accuracy: 38.57%
Validation set: Average loss: 1.488406, Accuracy: 477/1050 (45%)

Epoch: 9
Training set [0/6430 (0%)] Loss: 1.494042
Training set [3840/6430 (59%)] Loss: 1.504303
Training set: Average loss: 1.478099
Training set: Average accuracy: 40.50%
Validation set: Average loss: 1.437194, Accuracy: 501/1050 (48%)

Epoch: 10
Training set [0/6430 (0%)] Loss: 1.406501
Training set [3840/6430 (59%)] Loss: 1.406213
Training set: Average loss: 1.420191
Training set: Average accuracy: 42.78%
Validation set: Average loss: 1.443057, Accuracy: 478/1050 (46%)

Epoch: 11
Training set [0/6430 (0%)] Loss: 1.344599
Training set [3840/6430 (59%)] Loss: 1.351498
Training set: Average loss: 1.353565
Training set: Average accuracy: 45.12%
Validation set: Average loss: 1.511710, Accuracy: 474/1050 (45%)

Epoch: 12
Training set [0/6430 (0%)] Loss: 1.397033
Training set [3840/6430 (59%)] Loss: 1.326826
Training set: Average loss: 1.321140
Training set: Average accuracy: 46.56%
Validation set: Average loss: 1.271018, Accuracy: 582/1050 (55%)

Epoch: 13
Training set [0/6430 (0%)] Loss: 1.290041
Training set [3840/6430 (59%)] Loss: 1.298354
Training set: Average loss: 1.291147
Training set: Average accuracy: 47.48%
Validation set: Average loss: 1.374381, Accuracy: 500/1050 (48%)

Epoch: 14
Training set [0/6430 (0%)] Loss: 1.192383
Training set [3840/6430 (59%)] Loss: 1.214639
Training set: Average loss: 1.220055
Training set: Average accuracy: 50.96%
Validation set: Average loss: 1.224731, Accuracy: 607/1050 (58%)

Epoch: 15
Training set [0/6430 (0%)] Loss: 1.208391
Training set [3840/6430 (59%)] Loss: 1.138763
Training set: Average loss: 1.178327
Training set: Average accuracy: 51.56%
Validation set: Average loss: 1.155090, Accuracy: 616/1050 (59%)

Epoch: 16
Training set [0/6430 (0%)] Loss: 1.207747
Training set [3840/6430 (59%)] Loss: 1.111823
Training set: Average loss: 1.145295
Training set: Average accuracy: 53.17%
Validation set: Average loss: 1.118310, Accuracy: 657/1050 (63%)

Epoch: 17
Training set [0/6430 (0%)] Loss: 1.081886
Training set [3840/6430 (59%)] Loss: 1.120907
Training set: Average loss: 1.110551
Training set: Average accuracy: 54.98%
Validation set: Average loss: 1.135293, Accuracy: 633/1050 (60%)

Epoch: 18
Training set [0/6430 (0%)] Loss: 1.065833
Training set [3840/6430 (59%)] Loss: 1.046008
Training set: Average loss: 1.082250
Training set: Average accuracy: 55.75%
Validation set: Average loss: 1.083888, Accuracy: 661/1050 (63%)

Epoch: 19
Training set [0/6430 (0%)] Loss: 1.029454
Training set [3840/6430 (59%)] Loss: 1.090882
Training set: Average loss: 1.025405
Training set: Average accuracy: 58.82%
Validation set: Average loss: 1.255983, Accuracy: 588/1050 (56%)

Epoch: 20
Training set [0/6430 (0%)] Loss: 0.981991
Training set [3840/6430 (59%)] Loss: 0.985023
Training set: Average loss: 1.000405
Training set: Average accuracy: 59.74%
Validation set: Average loss: 1.165619, Accuracy: 635/1050 (60%)

Epoch: 21
Training set [0/6430 (0%)] Loss: 0.960781
Training set [3840/6430 (59%)] Loss: 0.986331
Training set: Average loss: 0.983209
Training set: Average accuracy: 61.26%
Validation set: Average loss: 0.950789, Accuracy: 719/1050 (68%)

Epoch: 22
Training set [0/6430 (0%)] Loss: 0.979032
Training set [3840/6430 (59%)] Loss: 0.883764
Training set: Average loss: 0.961825
Training set: Average accuracy: 61.62%
Validation set: Average loss: 1.061552, Accuracy: 680/1050 (65%)

Epoch: 23
Training set [0/6430 (0%)] Loss: 0.900945
Training set [3840/6430 (59%)] Loss: 0.929333
Training set: Average loss: 0.910735
Training set: Average accuracy: 63.34%
Validation set: Average loss: 1.042877, Accuracy: 697/1050 (66%)

Epoch: 24
Training set [0/6430 (0%)] Loss: 0.848228
Training set [3840/6430 (59%)] Loss: 1.015546
Training set: Average loss: 0.891763
Training set: Average accuracy: 64.23%
Validation set: Average loss: 0.934313, Accuracy: 728/1050 (69%)

Epoch: 25
Training set [0/6430 (0%)] Loss: 0.839292
Training set [3840/6430 (59%)] Loss: 0.809023
Training set: Average loss: 0.852050
Training set: Average accuracy: 66.08%
Validation set: Average loss: 1.697875, Accuracy: 514/1050 (49%)

Epoch: 26
Training set [0/6430 (0%)] Loss: 0.836684
Training set [3840/6430 (59%)] Loss: 0.832488
Training set: Average loss: 0.837439
Training set: Average accuracy: 65.71%
Validation set: Average loss: 0.916986, Accuracy: 754/1050 (72%)

Epoch: 27
Training set [0/6430 (0%)] Loss: 0.866548
Training set [3840/6430 (59%)] Loss: 0.778116
Training set: Average loss: 0.812250
Training set: Average accuracy: 67.12%
Validation set: Average loss: 1.019767, Accuracy: 703/1050 (67%)

Epoch: 28
Training set [0/6430 (0%)] Loss: 0.728410
Training set [3840/6430 (59%)] Loss: 0.860187
Training set: Average loss: 0.812859
Training set: Average accuracy: 66.89%
Validation set: Average loss: 0.946998, Accuracy: 732/1050 (70%)

Epoch: 29
Training set [0/6430 (0%)] Loss: 0.740788
Training set [3840/6430 (59%)] Loss: 0.800255
Training set: Average loss: 0.783866
Training set: Average accuracy: 68.29%
Validation set: Average loss: 0.969551, Accuracy: 719/1050 (68%)

Epoch: 30
Training set [0/6430 (0%)] Loss: 0.804391
Training set [3840/6430 (59%)] Loss: 0.851638
Training set: Average loss: 0.759887
Training set: Average accuracy: 68.97%
Validation set: Average loss: 0.857014, Accuracy: 763/1050 (73%)

Epoch: 31
Training set [0/6430 (0%)] Loss: 0.793790
Training set [3840/6430 (59%)] Loss: 0.654551
Training set: Average loss: 0.746547
Training set: Average accuracy: 69.78%
Validation set: Average loss: 0.814620, Accuracy: 767/1050 (73%)

Epoch: 32
Training set [0/6430 (0%)] Loss: 0.704590
Training set [3840/6430 (59%)] Loss: 0.726582
Training set: Average loss: 0.696713
Training set: Average accuracy: 71.88%
Validation set: Average loss: 0.815088, Accuracy: 777/1050 (74%)

Epoch: 33
Training set [0/6430 (0%)] Loss: 0.704594
Training set [3840/6430 (59%)] Loss: 0.731850
Training set: Average loss: 0.690087
Training set: Average accuracy: 72.07%
Validation set: Average loss: 0.807571, Accuracy: 767/1050 (73%)

Epoch: 34
Training set [0/6430 (0%)] Loss: 0.627093
Training set [3840/6430 (59%)] Loss: 0.666236
Training set: Average loss: 0.680614
Training set: Average accuracy: 72.38%
Validation set: Average loss: 0.942664, Accuracy: 738/1050 (70%)

Epoch: 35
Training set [0/6430 (0%)] Loss: 0.699891
Training set [3840/6430 (59%)] Loss: 0.697857
Training set: Average loss: 0.671430
Training set: Average accuracy: 72.61%
Validation set: Average loss: 0.779684, Accuracy: 792/1050 (75%)

Epoch: 36
Training set [0/6430 (0%)] Loss: 0.692226
Training set [3840/6430 (59%)] Loss: 0.671360
Training set: Average loss: 0.674716
Training set: Average accuracy: 73.06%
Validation set: Average loss: 0.927513, Accuracy: 743/1050 (71%)

Epoch: 37
Training set [0/6430 (0%)] Loss: 0.769957
Training set [3840/6430 (59%)] Loss: 0.610506
Training set: Average loss: 0.648512
Training set: Average accuracy: 73.17%
Validation set: Average loss: 0.923019, Accuracy: 737/1050 (70%)

Epoch: 38
Training set [0/6430 (0%)] Loss: 0.615268
Training set [3840/6430 (59%)] Loss: 0.628336
Training set: Average loss: 0.634882
Training set: Average accuracy: 74.51%
Validation set: Average loss: 0.845839, Accuracy: 771/1050 (73%)

Epoch: 39
Training set [0/6430 (0%)] Loss: 0.665264
Training set [3840/6430 (59%)] Loss: 0.600379
Training set: Average loss: 0.634192
Training set: Average accuracy: 74.20%
Validation set: Average loss: 0.831024, Accuracy: 766/1050 (73%)

Epoch: 40
Training set [0/6430 (0%)] Loss: 0.637138
Training set [3840/6430 (59%)] Loss: 0.571133
Training set: Average loss: 0.587694
Training set: Average accuracy: 75.89%
Validation set: Average loss: 0.832898, Accuracy: 788/1050 (75%)

Epoch: 41
Training set [0/6430 (0%)] Loss: 0.695421
Training set [3840/6430 (59%)] Loss: 0.565707
Training set: Average loss: 0.608581
Training set: Average accuracy: 75.65%
Validation set: Average loss: 0.668755, Accuracy: 826/1050 (79%)

Epoch: 42
Training set [0/6430 (0%)] Loss: 0.548931
Training set [3840/6430 (59%)] Loss: 0.660013
Training set: Average loss: 0.587488
Training set: Average accuracy: 76.69%
Validation set: Average loss: 0.872055, Accuracy: 773/1050 (74%)

Epoch: 43
Training set [0/6430 (0%)] Loss: 0.550847
Training set [3840/6430 (59%)] Loss: 0.550332
Training set: Average loss: 0.593508
Training set: Average accuracy: 76.44%
Validation set: Average loss: 0.939530, Accuracy: 736/1050 (70%)

Epoch: 44
Training set [0/6430 (0%)] Loss: 0.573904
Training set [3840/6430 (59%)] Loss: 0.685904
Training set: Average loss: 0.585535
Training set: Average accuracy: 76.80%
Validation set: Average loss: 0.894472, Accuracy: 764/1050 (73%)

Epoch: 45
Training set [0/6430 (0%)] Loss: 0.594924
Training set [3840/6430 (59%)] Loss: 0.599020
Training set: Average loss: 0.577421
Training set: Average accuracy: 76.67%
Validation set: Average loss: 1.006691, Accuracy: 733/1050 (70%)

Epoch: 46
Training set [0/6430 (0%)] Loss: 0.588992
Training set [3840/6430 (59%)] Loss: 0.454978
Training set: Average loss: 0.562890
Training set: Average accuracy: 77.79%
Validation set: Average loss: 1.008971, Accuracy: 739/1050 (70%)

Epoch: 47
Training set [0/6430 (0%)] Loss: 0.487983
Training set [3840/6430 (59%)] Loss: 0.602173
Training set: Average loss: 0.561921
Training set: Average accuracy: 77.62%
Validation set: Average loss: 0.735188, Accuracy: 833/1050 (79%)

Epoch: 48
Training set [0/6430 (0%)] Loss: 0.568632
Training set [3840/6430 (59%)] Loss: 0.535307
Training set: Average loss: 0.561094
Training set: Average accuracy: 77.92%
Validation set: Average loss: 0.695827, Accuracy: 822/1050 (78%)

Epoch: 49
Training set [0/6430 (0%)] Loss: 0.531008
Training set [3840/6430 (59%)] Loss: 0.580040
Training set: Average loss: 0.541685
Training set: Average accuracy: 78.58%
Validation set: Average loss: 0.704329, Accuracy: 818/1050 (78%)

Epoch: 50
Training set [0/6430 (0%)] Loss: 0.474953
Training set [3840/6430 (59%)] Loss: 0.696768
Training set: Average loss: 0.566571
Training set: Average accuracy: 77.90%
Validation set: Average loss: 1.007165, Accuracy: 751/1050 (72%)

Epoch: 51
Training set [0/6430 (0%)] Loss: 0.564765
Training set [3840/6430 (59%)] Loss: 0.564141
Training set: Average loss: 0.576921
Training set: Average accuracy: 77.25%
Validation set: Average loss: 0.899412, Accuracy: 765/1050 (73%)

Epoch: 52
Training set [0/6430 (0%)] Loss: 0.556693
Training set [3840/6430 (59%)] Loss: 0.488094
Training set: Average loss: 0.560569
Training set: Average accuracy: 77.98%
Validation set: Average loss: 0.900793, Accuracy: 764/1050 (73%)

Epoch: 53
Training set [0/6430 (0%)] Loss: 0.560937
Training set [3840/6430 (59%)] Loss: 0.478486
Training set: Average loss: 0.524214
Training set: Average accuracy: 79.74%
Validation set: Average loss: 0.982920, Accuracy: 749/1050 (71%)

Epoch: 54
Training set [0/6430 (0%)] Loss: 0.499901
Training set [3840/6430 (59%)] Loss: 0.456255
Training set: Average loss: 0.502677
Training set: Average accuracy: 79.95%
Validation set: Average loss: 0.711952, Accuracy: 816/1050 (78%)

Epoch: 55
Training set [0/6430 (0%)] Loss: 0.459270
Training set [3840/6430 (59%)] Loss: 0.470576
Training set: Average loss: 0.506647
Training set: Average accuracy: 79.97%
Validation set: Average loss: 0.772679, Accuracy: 799/1050 (76%)

Epoch: 56
Training set [0/6430 (0%)] Loss: 0.468567
Training set [3840/6430 (59%)] Loss: 0.457757
Training set: Average loss: 0.508891
Training set: Average accuracy: 80.16%
Validation set: Average loss: 0.721197, Accuracy: 814/1050 (78%)

Epoch: 57
Training set [0/6430 (0%)] Loss: 0.405756
Training set [3840/6430 (59%)] Loss: 0.435372
Training set: Average loss: 0.482195
Training set: Average accuracy: 80.51%
Validation set: Average loss: 0.944914, Accuracy: 775/1050 (74%)

Epoch: 58
Training set [0/6430 (0%)] Loss: 0.529459
Training set [3840/6430 (59%)] Loss: 0.430911
Training set: Average loss: 0.489047
Training set: Average accuracy: 81.10%
Validation set: Average loss: 0.704491, Accuracy: 830/1050 (79%)

Epoch: 59
Training set [0/6430 (0%)] Loss: 0.480322
Training set [3840/6430 (59%)] Loss: 0.488685
Training set: Average loss: 0.487969
Training set: Average accuracy: 80.87%
Validation set: Average loss: 0.971309, Accuracy: 764/1050 (73%)

Epoch: 60
Training set [0/6430 (0%)] Loss: 0.512853
Training set [3840/6430 (59%)] Loss: 0.449823
Training set: Average loss: 0.495564
Training set: Average accuracy: 80.59%
Validation set: Average loss: 0.875588, Accuracy: 797/1050 (76%)

Epoch: 61
Training set [0/6430 (0%)] Loss: 0.465046
Training set [3840/6430 (59%)] Loss: 0.530222
Training set: Average loss: 0.499303
Training set: Average accuracy: 80.34%
Validation set: Average loss: 0.787481, Accuracy: 797/1050 (76%)

Epoch: 62
Training set [0/6430 (0%)] Loss: 0.480076
Training set [3840/6430 (59%)] Loss: 0.539465
Training set: Average loss: 0.456982
Training set: Average accuracy: 82.27%
Validation set: Average loss: 0.831989, Accuracy: 805/1050 (77%)

Epoch: 63
Training set [0/6430 (0%)] Loss: 0.444991
Training set [3840/6430 (59%)] Loss: 0.447381
Training set: Average loss: 0.453059
Training set: Average accuracy: 81.94%
Validation set: Average loss: 0.870033, Accuracy: 806/1050 (77%)

Epoch: 64
Training set [0/6430 (0%)] Loss: 0.502161
Training set [3840/6430 (59%)] Loss: 0.464899
Training set: Average loss: 0.463022
Training set: Average accuracy: 81.63%
Validation set: Average loss: 0.733517, Accuracy: 821/1050 (78%)

Epoch: 65
Training set [0/6430 (0%)] Loss: 0.398720
Training set [3840/6430 (59%)] Loss: 0.476942
Training set: Average loss: 0.451766
Training set: Average accuracy: 82.44%
Validation set: Average loss: 0.757881, Accuracy: 821/1050 (78%)

Epoch: 66
Training set [0/6430 (0%)] Loss: 0.493165
Training set [3840/6430 (59%)] Loss: 0.423609
Training set: Average loss: 0.452164
Training set: Average accuracy: 82.32%
Validation set: Average loss: 0.814811, Accuracy: 801/1050 (76%)

Epoch: 67
Training set [0/6430 (0%)] Loss: 0.454993
Training set [3840/6430 (59%)] Loss: 0.467930
Training set: Average loss: 0.447929
Training set: Average accuracy: 82.75%
Validation set: Average loss: 0.895153, Accuracy: 798/1050 (76%)

Epoch: 68
Training set [0/6430 (0%)] Loss: 0.482597
Training set [3840/6430 (59%)] Loss: 0.440290
Training set: Average loss: 0.452168
Training set: Average accuracy: 81.98%
Validation set: Average loss: 0.672510, Accuracy: 840/1050 (80%)

Epoch: 69
Training set [0/6430 (0%)] Loss: 0.353441
Training set [3840/6430 (59%)] Loss: 0.457439
Training set: Average loss: 0.429740
Training set: Average accuracy: 83.13%
Validation set: Average loss: 0.843759, Accuracy: 805/1050 (77%)

Epoch: 70
Training set [0/6430 (0%)] Loss: 0.422500
Training set [3840/6430 (59%)] Loss: 0.482751
Training set: Average loss: 0.442385
Training set: Average accuracy: 82.64%
Validation set: Average loss: 1.402390, Accuracy: 729/1050 (69%)

Epoch: 71
Training set [0/6430 (0%)] Loss: 0.531914
Training set [3840/6430 (59%)] Loss: 0.428905
Training set: Average loss: 0.434952
Training set: Average accuracy: 83.39%
Validation set: Average loss: 0.734506, Accuracy: 843/1050 (80%)

Epoch: 72
Training set [0/6430 (0%)] Loss: 0.394176
Training set [3840/6430 (59%)] Loss: 0.438916
Training set: Average loss: 0.423626
Training set: Average accuracy: 83.34%
Validation set: Average loss: 0.756787, Accuracy: 822/1050 (78%)

Epoch: 73
Training set [0/6430 (0%)] Loss: 0.480310
Training set [3840/6430 (59%)] Loss: 0.497008
Training set: Average loss: 0.440931
Training set: Average accuracy: 82.74%
Validation set: Average loss: 0.741515, Accuracy: 837/1050 (80%)

Epoch: 74
Training set [0/6430 (0%)] Loss: 0.431593
Training set [3840/6430 (59%)] Loss: 0.471425
Training set: Average loss: 0.416773
Training set: Average accuracy: 83.78%
Validation set: Average loss: 0.679761, Accuracy: 831/1050 (79%)

Epoch: 75
Training set [0/6430 (0%)] Loss: 0.434055
Training set [3840/6430 (59%)] Loss: 0.400914
Training set: Average loss: 0.418704
Training set: Average accuracy: 83.45%
Validation set: Average loss: 1.079765, Accuracy: 774/1050 (74%)

Epoch: 76
Training set [0/6430 (0%)] Loss: 0.395338
Training set [3840/6430 (59%)] Loss: 0.411605
Training set: Average loss: 0.417325
Training set: Average accuracy: 83.84%
Validation set: Average loss: 0.708047, Accuracy: 833/1050 (79%)

Epoch: 77
Training set [0/6430 (0%)] Loss: 0.368825
Training set [3840/6430 (59%)] Loss: 0.360196
Training set: Average loss: 0.380687
Training set: Average accuracy: 84.98%
Validation set: Average loss: 0.717476, Accuracy: 845/1050 (80%)

Epoch: 78
Training set [0/6430 (0%)] Loss: 0.337882
Training set [3840/6430 (59%)] Loss: 0.411545
Training set: Average loss: 0.405489
Training set: Average accuracy: 83.75%
Validation set: Average loss: 0.958075, Accuracy: 800/1050 (76%)

Epoch: 79
Training set [0/6430 (0%)] Loss: 0.426486
Training set [3840/6430 (59%)] Loss: 0.408582
Training set: Average loss: 0.408400
Training set: Average accuracy: 84.18%
Validation set: Average loss: 0.791158, Accuracy: 828/1050 (79%)

Epoch: 80
Training set [0/6430 (0%)] Loss: 0.427299
Training set [3840/6430 (59%)] Loss: 0.451436
Training set: Average loss: 0.418800
Training set: Average accuracy: 83.72%
Validation set: Average loss: 1.127208, Accuracy: 758/1050 (72%)

Epoch: 81
Training set [0/6430 (0%)] Loss: 0.424041
Training set [3840/6430 (59%)] Loss: 0.397523
Training set: Average loss: 0.424287
Training set: Average accuracy: 84.00%
Validation set: Average loss: 0.795848, Accuracy: 842/1050 (80%)

Epoch: 82
Training set [0/6430 (0%)] Loss: 0.398745
Training set [3840/6430 (59%)] Loss: 0.376797
Training set: Average loss: 0.392661
Training set: Average accuracy: 84.57%
Validation set: Average loss: 1.077211, Accuracy: 786/1050 (75%)

Epoch: 83
Training set [0/6430 (0%)] Loss: 0.373607
Training set [3840/6430 (59%)] Loss: 0.369873
Training set: Average loss: 0.388081
Training set: Average accuracy: 84.15%
Validation set: Average loss: 0.756455, Accuracy: 841/1050 (80%)

Epoch: 84
Training set [0/6430 (0%)] Loss: 0.446058
Training set [3840/6430 (59%)] Loss: 0.420400
Training set: Average loss: 0.394264
Training set: Average accuracy: 84.76%
Validation set: Average loss: 0.778432, Accuracy: 853/1050 (81%)

Epoch: 85
Training set [0/6430 (0%)] Loss: 0.422352
Training set [3840/6430 (59%)] Loss: 0.363248
Training set: Average loss: 0.398929
Training set: Average accuracy: 85.13%
Validation set: Average loss: 0.955582, Accuracy: 779/1050 (74%)

Epoch: 86
Training set [0/6430 (0%)] Loss: 0.433352
Training set [3840/6430 (59%)] Loss: 0.382979
Training set: Average loss: 0.375884
Training set: Average accuracy: 85.30%
Validation set: Average loss: 0.687225, Accuracy: 859/1050 (82%)

Epoch: 87
Training set [0/6430 (0%)] Loss: 0.412425
Training set [3840/6430 (59%)] Loss: 0.335423
Training set: Average loss: 0.367869
Training set: Average accuracy: 85.33%
Validation set: Average loss: 0.742933, Accuracy: 850/1050 (81%)

Epoch: 88
Training set [0/6430 (0%)] Loss: 0.371390
Training set [3840/6430 (59%)] Loss: 0.383193
Training set: Average loss: 0.378614
Training set: Average accuracy: 85.23%
Validation set: Average loss: 0.871647, Accuracy: 815/1050 (78%)

Epoch: 89
Training set [0/6430 (0%)] Loss: 0.320564
Training set [3840/6430 (59%)] Loss: 0.419104
Training set: Average loss: 0.377951
Training set: Average accuracy: 85.38%
Validation set: Average loss: 0.891734, Accuracy: 815/1050 (78%)

Epoch: 90
Training set [0/6430 (0%)] Loss: 0.396662
Training set [3840/6430 (59%)] Loss: 0.396612
Training set: Average loss: 0.395684
Training set: Average accuracy: 84.25%
Validation set: Average loss: 0.717728, Accuracy: 853/1050 (81%)

Epoch: 91
Training set [0/6430 (0%)] Loss: 0.351179
Training set [3840/6430 (59%)] Loss: 0.444345
Training set: Average loss: 0.378539
Training set: Average accuracy: 85.05%
Validation set: Average loss: 0.656881, Accuracy: 843/1050 (80%)

Epoch: 92
Training set [0/6430 (0%)] Loss: 0.336990
Training set [3840/6430 (59%)] Loss: 0.390839
Training set: Average loss: 0.365038
Training set: Average accuracy: 85.79%
Validation set: Average loss: 1.164595, Accuracy: 793/1050 (76%)

Epoch: 93
Training set [0/6430 (0%)] Loss: 0.400401
Training set [3840/6430 (59%)] Loss: 0.379574
Training set: Average loss: 0.373584
Training set: Average accuracy: 85.71%
Validation set: Average loss: 0.809429, Accuracy: 827/1050 (79%)

Epoch: 94
Training set [0/6430 (0%)] Loss: 0.424566
Training set [3840/6430 (59%)] Loss: 0.377736
Training set: Average loss: 0.364015
Training set: Average accuracy: 86.02%
Validation set: Average loss: 0.659374, Accuracy: 850/1050 (81%)

Epoch: 95
Training set [0/6430 (0%)] Loss: 0.342103
Training set [3840/6430 (59%)] Loss: 0.371236
Training set: Average loss: 0.359323
Training set: Average accuracy: 85.71%
Validation set: Average loss: 0.708554, Accuracy: 837/1050 (80%)

Epoch: 96
Training set [0/6430 (0%)] Loss: 0.365278
Training set [3840/6430 (59%)] Loss: 0.390967
Training set: Average loss: 0.363327
Training set: Average accuracy: 85.65%
Validation set: Average loss: 0.823248, Accuracy: 830/1050 (79%)

Epoch: 97
Training set [0/6430 (0%)] Loss: 0.410329
Training set [3840/6430 (59%)] Loss: 0.376561
Training set: Average loss: 0.359460
Training set: Average accuracy: 85.44%
Validation set: Average loss: 0.714321, Accuracy: 827/1050 (79%)

Epoch: 98
Training set [0/6430 (0%)] Loss: 0.362074
Training set [3840/6430 (59%)] Loss: 0.312517
Training set: Average loss: 0.351487
Training set: Average accuracy: 85.91%
Validation set: Average loss: 0.774854, Accuracy: 834/1050 (79%)

Epoch: 99
Training set [0/6430 (0%)] Loss: 0.331920
Training set [3840/6430 (59%)] Loss: 0.377626
Training set: Average loss: 0.361599
Training set: Average accuracy: 85.80%
Validation set: Average loss: 0.908548, Accuracy: 798/1050 (76%)

Epoch: 100
Training set [0/6430 (0%)] Loss: 0.370600
Training set [3840/6430 (59%)] Loss: 0.320964
Training set: Average loss: 0.342935
Training set: Average accuracy: 87.01%
Validation set: Average loss: 1.364658, Accuracy: 730/1050 (70%)

Epoch: 101
Training set [0/6430 (0%)] Loss: 0.387848
Training set [3840/6430 (59%)] Loss: 0.411388
Training set: Average loss: 0.369512
Training set: Average accuracy: 85.71%
Validation set: Average loss: 0.894788, Accuracy: 815/1050 (78%)

Epoch: 102
Training set [0/6430 (0%)] Loss: 0.307849
Training set [3840/6430 (59%)] Loss: 0.458439
Training set: Average loss: 0.359156
Training set: Average accuracy: 85.85%
Validation set: Average loss: 0.794264, Accuracy: 831/1050 (79%)

Epoch: 103
Training set [0/6430 (0%)] Loss: 0.359519
Training set [3840/6430 (59%)] Loss: 0.339819
Training set: Average loss: 0.341395
Training set: Average accuracy: 86.17%
Validation set: Average loss: 0.782683, Accuracy: 858/1050 (82%)

Epoch: 104
Training set [0/6430 (0%)] Loss: 0.328079
Training set [3840/6430 (59%)] Loss: 0.340188
Training set: Average loss: 0.350827
Training set: Average accuracy: 85.96%
Validation set: Average loss: 0.798504, Accuracy: 828/1050 (79%)

Epoch: 105
Training set [0/6430 (0%)] Loss: 0.407153
Training set [3840/6430 (59%)] Loss: 0.339942
Training set: Average loss: 0.345940
Training set: Average accuracy: 85.94%
Validation set: Average loss: 0.798512, Accuracy: 854/1050 (81%)

Epoch: 106
Training set [0/6430 (0%)] Loss: 0.378600
Training set [3840/6430 (59%)] Loss: 0.382981
Training set: Average loss: 0.344275
Training set: Average accuracy: 86.39%
Validation set: Average loss: 0.786794, Accuracy: 829/1050 (79%)

Epoch: 107
Training set [0/6430 (0%)] Loss: 0.345804
Training set [3840/6430 (59%)] Loss: 0.298846
Training set: Average loss: 0.344053
Training set: Average accuracy: 86.84%
Validation set: Average loss: 0.970500, Accuracy: 807/1050 (77%)

Epoch: 108
Training set [0/6430 (0%)] Loss: 0.287187
Training set [3840/6430 (59%)] Loss: 0.302255
Training set: Average loss: 0.343657
Training set: Average accuracy: 86.21%
Validation set: Average loss: 0.686765, Accuracy: 846/1050 (81%)

Epoch: 109
Training set [0/6430 (0%)] Loss: 0.314039
Training set [3840/6430 (59%)] Loss: 0.325956
Training set: Average loss: 0.346181
Training set: Average accuracy: 86.50%
Validation set: Average loss: 0.782966, Accuracy: 823/1050 (78%)

Epoch: 110
Training set [0/6430 (0%)] Loss: 0.367651
Training set [3840/6430 (59%)] Loss: 0.343126
Training set: Average loss: 0.345631
Training set: Average accuracy: 86.38%
Validation set: Average loss: 0.893421, Accuracy: 820/1050 (78%)

Epoch: 111
Training set [0/6430 (0%)] Loss: 0.366303
Training set [3840/6430 (59%)] Loss: 0.309080
Training set: Average loss: 0.334845
Training set: Average accuracy: 87.06%
Validation set: Average loss: 0.778934, Accuracy: 850/1050 (81%)

Epoch: 112
Training set [0/6430 (0%)] Loss: 0.318316
Training set [3840/6430 (59%)] Loss: 0.322649
Training set: Average loss: 0.338565
Training set: Average accuracy: 86.63%
Validation set: Average loss: 0.747860, Accuracy: 855/1050 (81%)

Epoch: 113
Training set [0/6430 (0%)] Loss: 0.338226
Training set [3840/6430 (59%)] Loss: 0.348848
Training set: Average loss: 0.338367
Training set: Average accuracy: 86.59%
Validation set: Average loss: 1.220215, Accuracy: 778/1050 (74%)

Epoch: 114
Training set [0/6430 (0%)] Loss: 0.367231
Training set [3840/6430 (59%)] Loss: 0.375176
Training set: Average loss: 0.349891
Training set: Average accuracy: 86.17%
Validation set: Average loss: 0.884281, Accuracy: 828/1050 (79%)

Epoch: 115
Training set [0/6430 (0%)] Loss: 0.377805
Training set [3840/6430 (59%)] Loss: 0.347766
Training set: Average loss: 0.328162
Training set: Average accuracy: 86.98%
Validation set: Average loss: 0.830936, Accuracy: 821/1050 (78%)

Epoch: 116
Training set [0/6430 (0%)] Loss: 0.299906
Training set [3840/6430 (59%)] Loss: 0.251024
Training set: Average loss: 0.326950
Training set: Average accuracy: 86.77%
Validation set: Average loss: 0.763946, Accuracy: 854/1050 (81%)

Epoch: 117
Training set [0/6430 (0%)] Loss: 0.343744
Training set [3840/6430 (59%)] Loss: 0.327267
Training set: Average loss: 0.333501
Training set: Average accuracy: 87.25%
Validation set: Average loss: 0.764254, Accuracy: 851/1050 (81%)

Epoch: 118
Training set [0/6430 (0%)] Loss: 0.308054
Training set [3840/6430 (59%)] Loss: 0.362556
Training set: Average loss: 0.332653
Training set: Average accuracy: 86.97%
Validation set: Average loss: 0.894495, Accuracy: 807/1050 (77%)

Epoch: 119
Training set [0/6430 (0%)] Loss: 0.267788
Training set [3840/6430 (59%)] Loss: 0.352187
Training set: Average loss: 0.319521
Training set: Average accuracy: 87.68%
Validation set: Average loss: 1.007002, Accuracy: 828/1050 (79%)

Epoch: 120
Training set [0/6430 (0%)] Loss: 0.304355
Training set [3840/6430 (59%)] Loss: 0.258078
Training set: Average loss: 0.319980
Training set: Average accuracy: 87.45%
Validation set: Average loss: 0.785373, Accuracy: 836/1050 (80%)

Epoch: 121
Training set [0/6430 (0%)] Loss: 0.246769
Training set [3840/6430 (59%)] Loss: 0.300029
Training set: Average loss: 0.312428
Training set: Average accuracy: 87.87%
Validation set: Average loss: 0.707368, Accuracy: 866/1050 (82%)

Epoch: 122
Training set [0/6430 (0%)] Loss: 0.280563
Training set [3840/6430 (59%)] Loss: 0.322317
Training set: Average loss: 0.313163
Training set: Average accuracy: 87.20%
Validation set: Average loss: 0.930568, Accuracy: 803/1050 (76%)

Epoch: 123
Training set [0/6430 (0%)] Loss: 0.404559
Training set [3840/6430 (59%)] Loss: 0.289392
Training set: Average loss: 0.306116
Training set: Average accuracy: 87.96%
Validation set: Average loss: 0.775672, Accuracy: 861/1050 (82%)

Epoch: 124
Training set [0/6430 (0%)] Loss: 0.302800
Training set [3840/6430 (59%)] Loss: 0.285075
Training set: Average loss: 0.294867
Training set: Average accuracy: 88.15%
Validation set: Average loss: 0.906888, Accuracy: 835/1050 (80%)

Epoch: 125
Training set [0/6430 (0%)] Loss: 0.289014
Training set [3840/6430 (59%)] Loss: 0.307699
Training set: Average loss: 0.297473
Training set: Average accuracy: 88.06%
Validation set: Average loss: 0.743081, Accuracy: 861/1050 (82%)

Epoch: 126
Training set [0/6430 (0%)] Loss: 0.331923
Training set [3840/6430 (59%)] Loss: 0.266266
Training set: Average loss: 0.296787
Training set: Average accuracy: 88.55%
Validation set: Average loss: 0.630956, Accuracy: 866/1050 (82%)

Epoch: 127
Training set [0/6430 (0%)] Loss: 0.341623
Training set [3840/6430 (59%)] Loss: 0.274352
Training set: Average loss: 0.303844
Training set: Average accuracy: 88.21%
Validation set: Average loss: 0.789151, Accuracy: 838/1050 (80%)

Epoch: 128
Training set [0/6430 (0%)] Loss: 0.314241
Training set [3840/6430 (59%)] Loss: 0.292745
Training set: Average loss: 0.307965
Training set: Average accuracy: 88.09%
Validation set: Average loss: 0.795451, Accuracy: 871/1050 (83%)

Epoch: 129
Training set [0/6430 (0%)] Loss: 0.285589
Training set [3840/6430 (59%)] Loss: 0.290530
Training set: Average loss: 0.319911
Training set: Average accuracy: 87.12%
Validation set: Average loss: 0.860703, Accuracy: 842/1050 (80%)

Epoch: 130
Training set [0/6430 (0%)] Loss: 0.308889
Training set [3840/6430 (59%)] Loss: 0.243426
Training set: Average loss: 0.310352
Training set: Average accuracy: 88.26%
Validation set: Average loss: 0.942784, Accuracy: 831/1050 (79%)

Epoch: 131
Training set [0/6430 (0%)] Loss: 0.340436
Training set [3840/6430 (59%)] Loss: 0.307910
Training set: Average loss: 0.296243
Training set: Average accuracy: 88.01%
Validation set: Average loss: 0.766821, Accuracy: 855/1050 (81%)

Epoch: 132
Training set [0/6430 (0%)] Loss: 0.260744
Training set [3840/6430 (59%)] Loss: 0.283558
Training set: Average loss: 0.294645
Training set: Average accuracy: 88.54%
Validation set: Average loss: 0.940900, Accuracy: 828/1050 (79%)

Epoch: 133
Training set [0/6430 (0%)] Loss: 0.311395
Training set [3840/6430 (59%)] Loss: 0.272840
Training set: Average loss: 0.302659
Training set: Average accuracy: 88.35%
Validation set: Average loss: 0.678611, Accuracy: 872/1050 (83%)

Epoch: 134
Training set [0/6430 (0%)] Loss: 0.334355
Training set [3840/6430 (59%)] Loss: 0.316092
Training set: Average loss: 0.316397
Training set: Average accuracy: 87.70%
Validation set: Average loss: 0.821801, Accuracy: 846/1050 (81%)

Epoch: 135
Training set [0/6430 (0%)] Loss: 0.314361
Training set [3840/6430 (59%)] Loss: 0.269336
Training set: Average loss: 0.300988
Training set: Average accuracy: 87.99%
Validation set: Average loss: 1.419122, Accuracy: 786/1050 (75%)

Epoch: 136
Training set [0/6430 (0%)] Loss: 0.284530
Training set [3840/6430 (59%)] Loss: 0.279169
Training set: Average loss: 0.310459
Training set: Average accuracy: 88.04%
Validation set: Average loss: 0.889254, Accuracy: 844/1050 (80%)

Epoch: 137
Training set [0/6430 (0%)] Loss: 0.367267
Training set [3840/6430 (59%)] Loss: 0.289712
Training set: Average loss: 0.297581
Training set: Average accuracy: 88.65%
Validation set: Average loss: 0.880397, Accuracy: 836/1050 (80%)

Epoch: 138
Training set [0/6430 (0%)] Loss: 0.292084
Training set [3840/6430 (59%)] Loss: 0.302310
Training set: Average loss: 0.283876
Training set: Average accuracy: 89.13%
Validation set: Average loss: 0.718135, Accuracy: 870/1050 (83%)

Epoch: 139
Training set [0/6430 (0%)] Loss: 0.297395
Training set [3840/6430 (59%)] Loss: 0.279349
Training set: Average loss: 0.296474
Training set: Average accuracy: 88.74%
Validation set: Average loss: 0.721041, Accuracy: 861/1050 (82%)

Epoch: 140
Training set [0/6430 (0%)] Loss: 0.275117
Training set [3840/6430 (59%)] Loss: 0.331362
Training set: Average loss: 0.299749
Training set: Average accuracy: 88.52%
Validation set: Average loss: 0.759059, Accuracy: 866/1050 (82%)

Epoch: 141
Training set [0/6430 (0%)] Loss: 0.262697
Training set [3840/6430 (59%)] Loss: 0.353854
Training set: Average loss: 0.307085
Training set: Average accuracy: 87.95%
Validation set: Average loss: 0.933079, Accuracy: 830/1050 (79%)

Epoch: 142
Training set [0/6430 (0%)] Loss: 0.319547
Training set [3840/6430 (59%)] Loss: 0.357787
Training set: Average loss: 0.302035
Training set: Average accuracy: 88.01%
Validation set: Average loss: 0.759503, Accuracy: 859/1050 (82%)

Epoch: 143
Training set [0/6430 (0%)] Loss: 0.272305
Training set [3840/6430 (59%)] Loss: 0.284217
Training set: Average loss: 0.293990
Training set: Average accuracy: 88.79%
Validation set: Average loss: 1.245833, Accuracy: 786/1050 (75%)

Epoch: 144
Training set [0/6430 (0%)] Loss: 0.300274
Training set [3840/6430 (59%)] Loss: 0.311610
Training set: Average loss: 0.296579
Training set: Average accuracy: 88.18%
Validation set: Average loss: 0.725382, Accuracy: 880/1050 (84%)

Epoch: 145
Training set [0/6430 (0%)] Loss: 0.235807
Training set [3840/6430 (59%)] Loss: 0.286595
Training set: Average loss: 0.271257
Training set: Average accuracy: 89.55%
Validation set: Average loss: 0.955929, Accuracy: 820/1050 (78%)

Epoch: 146
Training set [0/6430 (0%)] Loss: 0.209562
Training set [3840/6430 (59%)] Loss: 0.267090
Training set: Average loss: 0.284527
Training set: Average accuracy: 88.74%
Validation set: Average loss: 0.811928, Accuracy: 859/1050 (82%)

Epoch: 147
Training set [0/6430 (0%)] Loss: 0.292106
Training set [3840/6430 (59%)] Loss: 0.363369
Training set: Average loss: 0.279454
Training set: Average accuracy: 88.99%
Validation set: Average loss: 0.730185, Accuracy: 863/1050 (82%)

Epoch: 148
Training set [0/6430 (0%)] Loss: 0.265255
Training set [3840/6430 (59%)] Loss: 0.266165
Training set: Average loss: 0.279527
Training set: Average accuracy: 88.91%
Validation set: Average loss: 0.767454, Accuracy: 853/1050 (81%)

Epoch: 149
Training set [0/6430 (0%)] Loss: 0.269375
Training set [3840/6430 (59%)] Loss: 0.284458
Training set: Average loss: 0.263356
Training set: Average accuracy: 89.86%
Validation set: Average loss: 0.817403, Accuracy: 856/1050 (82%)

BasicNet
training_loss -- validation_loss
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]
[2.9546916204340317, 1.8871713666354908, 1.830910374136532, 1.774237219025107, 1.7218364477157593, 1.6615865020190967, 1.618039103115306, 1.570405455196605, 1.5243324742597693, 1.4780985046835506, 1.4201910075019388, 1.3535645358702715, 1.321139847531038, 1.291146671070772, 1.2200546965879553, 1.1783270765753353, 1.1452946803149056, 1.1105508173213285, 1.0822498658124138, 1.0254046566346113, 1.0004050275858711, 0.9832092769005719, 0.9618247642236597, 0.9107350181130802, 0.8917626247686499, 0.8520497960202834, 0.8374388533480027, 0.8122504669077256, 0.8128585745306576, 0.7838663634131936, 0.7598868924028733, 0.7465466611525592, 0.6967126516734853, 0.6900871045449201, 0.6806135633412529, 0.6714303107822642, 0.6747155259637272, 0.6485115990919226, 0.6348820574143353, 0.6341918741955477, 0.5876935667851392, 0.6085806874667897, 0.587487683576696, 0.5935083452393027, 0.5855353334370781, 0.5774214127484489, 0.5628900633138769, 0.5619211109245524, 0.561094112255994, 0.5416852744186625, 0.566570767584969, 0.5769205479060903, 0.5605694756788366, 0.5242144500508028, 0.5026766219559837, 0.5066468768260058, 0.5088914702920353, 0.4821954106583315, 0.4890465911696939, 0.48796920040074515, 0.4955642977181603, 0.49930259234764995, 0.45698213752578287, 0.45305946644614725, 0.4630219726001515, 0.4517663243938895, 0.4521640065838309, 0.44792858292074766, 0.4521677984910853, 0.42974047099842744, 0.4423847741940442, 0.43495211706441994, 0.42362627387046814, 0.4409306277247036, 0.41677261450711417, 0.4187038330470814, 0.4173251670949599, 0.38068652328322916, 0.4054888451800627, 0.40839996583321514, 0.4188003049177282, 0.4242868037784801, 0.39266108940629396, 0.3880808756631963, 0.39426375311963696, 0.39892948024413166, 0.3758837598211625, 0.36786938414854164, 0.3786137209219091, 0.3779510662836187, 0.39568445787710305, 0.37853895566042733, 0.3650384843349457, 0.3735839058371151, 0.3640151234234081, 0.35932304578668933, 0.3633270596756655, 0.3594604327398188, 0.3514874174314387, 0.36159907193744883, 0.34293513262973113, 0.36951172702452717, 0.35915591085658355, 0.34139468214091134, 0.3508268734988044, 0.3459404251154731, 0.34427489603267, 0.3440530019647935, 0.34365682566867156, 0.3461810157579534, 0.3456310559721554, 0.3348454797969145, 0.3385649884448332, 0.33836675742093253, 0.34989098590963025, 0.32816231951994057, 0.3269501994637882, 0.33350129863795114, 0.33265341555371003, 0.3195209590827717, 0.3199795729973737, 0.3124282947357963, 0.3131633295732386, 0.3061160304967095, 0.2948666425312267, 0.29747337190543904, 0.29678742499912486, 0.30384378222858205, 0.30796514363849864, 0.31991147293764, 0.3103517951334224, 0.29624348440591025, 0.29464513589354124, 0.30265869638499093, 0.3163973049205892, 0.3009884971029618, 0.3104586934342104, 0.2975809346227085, 0.2838755407754113, 0.29647374240791097, 0.29974859865272746, 0.3070846349000931, 0.30203503370285034, 0.29398952161564545, 0.2965791725060519, 0.2712568702066646, 0.2845269862343283, 0.27945391658474417, 0.2795271987424177, 0.26335637884981494]
[1.9498426119486492, 1.9256859223047893, 1.8499648968378704, 1.7809818585713704, 1.7021104494730632, 1.6475660006205242, 1.622481902440389, 1.547259529431661, 1.488405704498291, 1.4371938705444336, 1.443057378133138, 1.511710286140442, 1.271018147468567, 1.374381383260091, 1.2247314453125, 1.1550896366437275, 1.1183096965154011, 1.1352933049201965, 1.08388751745224, 1.2559834122657776, 1.165619174639384, 0.9507894118626913, 1.0615521669387817, 1.0428773959477742, 0.9343127806981405, 1.6978750228881836, 0.916986346244812, 1.0197665492693584, 0.9469980398813883, 0.969550609588623, 0.8570138613382975, 0.814619779586792, 0.8150877356529236, 0.80757075548172, 0.9426636497179667, 0.7796839276949564, 0.9275128444035848, 0.9230191111564636, 0.8458390037218729, 0.8310243089993795, 0.8328975439071655, 0.668754518032074, 0.8720550537109375, 0.9395302534103394, 0.8944722811381022, 1.0066906809806824, 1.0089708964029949, 0.7351877689361572, 0.6958267092704773, 0.7043290932973226, 1.0071651538213093, 0.899412214756012, 0.900793174902598, 0.9829200903574625, 0.711952269077301, 0.7726794481277466, 0.7211974461873373, 0.9449141422907511, 0.7044907609621683, 0.9713093439737955, 0.8755878408749899, 0.7874812483787537, 0.831988513469696, 0.870032548904419, 0.7335166533788046, 0.7578807274500529, 0.814811090628306, 0.8951533238093058, 0.6725101470947266, 0.8437589804331461, 1.40239018201828, 0.7345059315363566, 0.7567873994509379, 0.7415147026379904, 0.6797614693641663, 1.079764982064565, 0.7080473105112711, 0.7174760500590006, 0.9580746094385783, 0.7911575436592102, 1.1272078156471252, 0.7958480914433798, 1.0772105852762859, 0.7564554015795389, 0.7784316539764404, 0.9555821021397909, 0.687225341796875, 0.7429326971371969, 0.8716470797856649, 0.8917343219121298, 0.717728316783905, 0.6568810939788818, 1.1645952065785725, 0.8094292481740316, 0.659373958905538, 0.708553691705068, 0.8232477903366089, 0.7143210073312124, 0.7748544812202454, 0.908548096815745, 1.364657739798228, 0.8947876294453939, 0.7942643165588379, 0.7826829353968302, 0.7985037366549174, 0.7985118627548218, 0.7867936094601949, 0.9705004692077637, 0.6867645382881165, 0.7829657991727194, 0.8934212923049927, 0.778934101263682, 0.7478602329889933, 1.220215340455373, 0.8842814763387045, 0.8309355775515238, 0.7639455397923788, 0.764253576596578, 0.89449542760849, 1.0070015788078308, 0.7853727539380392, 0.707367738087972, 0.9305684566497803, 0.7756719589233398, 0.9068883061408997, 0.7430813709894816, 0.63095623254776, 0.7891506950060526, 0.7954510351022085, 0.8607034683227539, 0.9427836338678995, 0.7668214539686838, 0.9408997694651285, 0.6786108613014221, 0.8218011260032654, 1.4191219210624695, 0.8892542918523153, 0.8803965449333191, 0.7181353370348612, 0.7210414409637451, 0.7590591112772623, 0.9330786267916361, 0.7595029274622599, 1.245833396911621, 0.7253824273745219, 0.9559287826220194, 0.8119284510612488, 0.7301852703094482, 0.7674537102381388, 0.8174028595288595]
BasicNet
training_accuracy -- validation_accuracy
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]
[17.93157076205288, 20.10886469673406, 23.841368584758943, 26.111975116640746, 28.69362363919129, 31.944012441679625, 33.530326594090205, 36.780715396578536, 38.5692068429238, 40.497667185069986, 42.783825816485226, 45.11664074650078, 46.56298600311042, 47.480559875583204, 50.9642301710731, 51.5552099533437, 53.17262830482115, 54.976671850699844, 55.7542768273717, 58.818040435458784, 59.73561430793157, 61.259720062208395, 61.61741835147745, 63.34370139968896, 64.23017107309487, 66.08087091757388, 65.70762052877139, 67.12286158631416, 66.8895800933126, 68.28926905132192, 68.97356143079315, 69.78227060653188, 71.88180404354588, 72.06842923794713, 72.37947122861587, 72.61275272161741, 73.06376360808709, 73.17262830482115, 74.51010886469673, 74.19906687402799, 75.89424572317263, 75.64541213063764, 76.68740279937792, 76.43856920684293, 76.79626749611198, 76.67185069984448, 77.79160186625194, 77.62052877138413, 77.91601866251943, 78.58475894245723, 77.900466562986, 77.24727838258165, 77.97822706065318, 79.73561430793157, 79.95334370139969, 79.96889580093313, 80.15552099533437, 80.51321928460342, 81.10419906687403, 80.87091757387248, 80.59097978227061, 80.34214618973562, 82.27060653188181, 81.94401244167963, 81.63297045101089, 82.44167962674962, 82.31726283048212, 82.75272161741835, 81.9751166407465, 83.12597200622083, 82.64385692068429, 83.39035769828926, 83.34370139968895, 82.73716951788491, 83.77916018662519, 83.45256609642301, 83.84136858475894, 84.97667185069984, 83.74805598755832, 84.18351477449455, 83.71695178849144, 83.99688958009331, 84.57231726283048, 84.15241057542768, 84.75894245723173, 85.13219284603421, 85.30326594090202, 85.3343701399689, 85.22550544323484, 85.38102643856921, 84.2457231726283, 85.05443234836703, 85.78538102643857, 85.70762052877139, 86.01866251944013, 85.70762052877139, 85.64541213063764, 85.44323483670296, 85.90979782270607, 85.80093312597201, 87.0139968895801, 85.70762052877139, 85.84758942457232, 86.1741835147745, 85.95645412130638, 85.94090202177294, 86.39191290824262, 86.84292379471229, 86.20528771384137, 86.50077760497668, 86.37636080870918, 87.06065318818041, 86.62519440124417, 86.5940902021773, 86.1741835147745, 86.98289269051322, 86.7651632970451, 87.24727838258165, 86.96734059097979, 87.68273716951788, 87.44945567651634, 87.86936236391912, 87.20062208398134, 87.96267496111975, 88.14930015552099, 88.05598755832037, 88.55365474339035, 88.21150855365474, 88.08709175738724, 87.12286158631416, 88.25816485225505, 88.00933125972006, 88.53810264385692, 88.35147744945567, 87.69828926905132, 87.99377916018662, 88.04043545878693, 88.64696734059098, 89.12908242612752, 88.7402799377916, 88.52255054432348, 87.94712286158631, 88.00933125972006, 88.78693623639191, 88.18040435458786, 89.54898911353033, 88.7402799377916, 88.98911353032659, 88.9113530326594, 89.86003110419907]
[14.571428571428571, 17.714285714285715, 23.333333333333332, 31.142857142857142, 35.714285714285715, 34.285714285714285, 36.476190476190474, 41.714285714285715, 45.42857142857143, 47.714285714285715, 45.523809523809526, 45.142857142857146, 55.42857142857143, 47.61904761904762, 57.80952380952381, 58.666666666666664, 62.57142857142857, 60.285714285714285, 62.95238095238095, 56.0, 60.476190476190474, 68.47619047619048, 64.76190476190476, 66.38095238095238, 69.33333333333333, 48.95238095238095, 71.80952380952381, 66.95238095238095, 69.71428571428571, 68.47619047619048, 72.66666666666667, 73.04761904761905, 74.0, 73.04761904761905, 70.28571428571429, 75.42857142857143, 70.76190476190476, 70.19047619047619, 73.42857142857143, 72.95238095238095, 75.04761904761905, 78.66666666666667, 73.61904761904762, 70.0952380952381, 72.76190476190476, 69.80952380952381, 70.38095238095238, 79.33333333333333, 78.28571428571429, 77.9047619047619, 71.52380952380952, 72.85714285714286, 72.76190476190476, 71.33333333333333, 77.71428571428571, 76.0952380952381, 77.52380952380952, 73.80952380952381, 79.04761904761905, 72.76190476190476, 75.9047619047619, 75.9047619047619, 76.66666666666667, 76.76190476190476, 78.19047619047619, 78.19047619047619, 76.28571428571429, 76.0, 80.0, 76.66666666666667, 69.42857142857143, 80.28571428571429, 78.28571428571429, 79.71428571428571, 79.14285714285714, 73.71428571428571, 79.33333333333333, 80.47619047619048, 76.19047619047619, 78.85714285714286, 72.19047619047619, 80.19047619047619, 74.85714285714286, 80.0952380952381, 81.23809523809524, 74.19047619047619, 81.80952380952381, 80.95238095238095, 77.61904761904762, 77.61904761904762, 81.23809523809524, 80.28571428571429, 75.52380952380952, 78.76190476190476, 80.95238095238095, 79.71428571428571, 79.04761904761905, 78.76190476190476, 79.42857142857143, 76.0, 69.52380952380952, 77.61904761904762, 79.14285714285714, 81.71428571428571, 78.85714285714286, 81.33333333333333, 78.95238095238095, 76.85714285714286, 80.57142857142857, 78.38095238095238, 78.0952380952381, 80.95238095238095, 81.42857142857143, 74.0952380952381, 78.85714285714286, 78.19047619047619, 81.33333333333333, 81.04761904761905, 76.85714285714286, 78.85714285714286, 79.61904761904762, 82.47619047619048, 76.47619047619048, 82.0, 79.52380952380952, 82.0, 82.47619047619048, 79.80952380952381, 82.95238095238095, 80.19047619047619, 79.14285714285714, 81.42857142857143, 78.85714285714286, 83.04761904761905, 80.57142857142857, 74.85714285714286, 80.38095238095238, 79.61904761904762, 82.85714285714286, 82.0, 82.47619047619048, 79.04761904761905, 81.80952380952381, 74.85714285714286, 83.80952380952381, 78.0952380952381, 81.80952380952381, 82.19047619047619, 81.23809523809524, 81.52380952380952]
model saved as model_store_384/cnn_car_BasicNet.pt
Getting predictions from test set...
BasicNet
[[104   1   1  25   8  11   0]
 [  2 120   9   6   8   5   0]
 [  0   3 134   6   2   2   3]
 [  9   4   3 129   3   2   0]
 [  4   0   0   2 139   0   5]
 [  2  10   8   6   0 122   2]
 [  2  10  21   2   3   4 108]]
=============================
ImprovedNet
=============================
Epoch: 0
Training set [0/6430 (0%)] Loss: 1.949582
Training set [3840/6430 (59%)] Loss: 1.946123
Training set: Average loss: 2.048886
Training set: Average accuracy: 15.32%
Validation set: Average loss: 1.927412, Accuracy: 236/1050 (22%)

Epoch: 1
Training set [0/6430 (0%)] Loss: 1.903833
Training set [3840/6430 (59%)] Loss: 1.894844
Training set: Average loss: 1.863540
Training set: Average accuracy: 23.76%
Validation set: Average loss: 1.795737, Accuracy: 299/1050 (28%)

Epoch: 2
Training set [0/6430 (0%)] Loss: 1.807267
Training set [3840/6430 (59%)] Loss: 1.621635
Training set: Average loss: 1.710239
Training set: Average accuracy: 34.59%
Validation set: Average loss: 1.667035, Accuracy: 422/1050 (40%)

Epoch: 3
Training set [0/6430 (0%)] Loss: 1.588981
Training set [3840/6430 (59%)] Loss: 1.609478
Training set: Average loss: 1.575540
Training set: Average accuracy: 41.65%
Validation set: Average loss: 1.517549, Accuracy: 479/1050 (46%)

Epoch: 4
Training set [0/6430 (0%)] Loss: 1.441293
Training set [3840/6430 (59%)] Loss: 1.389295
Training set: Average loss: 1.433152
Training set: Average accuracy: 47.84%
Validation set: Average loss: 1.428098, Accuracy: 511/1050 (49%)

Epoch: 5
Training set [0/6430 (0%)] Loss: 1.355404
Training set [3840/6430 (59%)] Loss: 1.277680
Training set: Average loss: 1.261149
Training set: Average accuracy: 54.31%
Validation set: Average loss: 1.328597, Accuracy: 548/1050 (52%)

Epoch: 6
Training set [0/6430 (0%)] Loss: 1.176194
Training set [3840/6430 (59%)] Loss: 1.086143
Training set: Average loss: 1.104995
Training set: Average accuracy: 60.82%
Validation set: Average loss: 1.238312, Accuracy: 592/1050 (56%)

Epoch: 7
Training set [0/6430 (0%)] Loss: 0.977186
Training set [3840/6430 (59%)] Loss: 0.923220
Training set: Average loss: 0.933889
Training set: Average accuracy: 67.33%
Validation set: Average loss: 1.169435, Accuracy: 633/1050 (60%)

Epoch: 8
Training set [0/6430 (0%)] Loss: 0.822603
Training set [3840/6430 (59%)] Loss: 0.788766
Training set: Average loss: 0.777089
Training set: Average accuracy: 73.48%
Validation set: Average loss: 1.110299, Accuracy: 644/1050 (61%)

Epoch: 9
Training set [0/6430 (0%)] Loss: 0.735896
Training set [3840/6430 (59%)] Loss: 0.588325
Training set: Average loss: 0.639079
Training set: Average accuracy: 78.02%
Validation set: Average loss: 1.081124, Accuracy: 670/1050 (64%)

Epoch: 10
Training set [0/6430 (0%)] Loss: 0.509592
Training set [3840/6430 (59%)] Loss: 0.556327
Training set: Average loss: 0.510017
Training set: Average accuracy: 82.50%
Validation set: Average loss: 1.041116, Accuracy: 701/1050 (67%)

Epoch: 11
Training set [0/6430 (0%)] Loss: 0.441339
Training set [3840/6430 (59%)] Loss: 0.364274
Training set: Average loss: 0.408233
Training set: Average accuracy: 85.88%
Validation set: Average loss: 1.049804, Accuracy: 716/1050 (68%)

Epoch: 12
Training set [0/6430 (0%)] Loss: 0.335915
Training set [3840/6430 (59%)] Loss: 0.371341
Training set: Average loss: 0.337617
Training set: Average accuracy: 88.99%
Validation set: Average loss: 1.112739, Accuracy: 725/1050 (69%)

Epoch: 13
Training set [0/6430 (0%)] Loss: 0.267076
Training set [3840/6430 (59%)] Loss: 0.229803
Training set: Average loss: 0.268744
Training set: Average accuracy: 90.78%
Validation set: Average loss: 1.087402, Accuracy: 728/1050 (69%)

Epoch: 14
Training set [0/6430 (0%)] Loss: 0.237120
Training set [3840/6430 (59%)] Loss: 0.224032
Training set: Average loss: 0.228339
Training set: Average accuracy: 92.46%
Validation set: Average loss: 1.148034, Accuracy: 733/1050 (70%)

Epoch: 15
Training set [0/6430 (0%)] Loss: 0.214250
Training set [3840/6430 (59%)] Loss: 0.183485
Training set: Average loss: 0.183418
Training set: Average accuracy: 94.07%
Validation set: Average loss: 1.173004, Accuracy: 742/1050 (71%)

Epoch: 16
Training set [0/6430 (0%)] Loss: 0.134513
Training set [3840/6430 (59%)] Loss: 0.150472
Training set: Average loss: 0.160378
Training set: Average accuracy: 94.68%
Validation set: Average loss: 1.106749, Accuracy: 757/1050 (72%)

Epoch: 17
Training set [0/6430 (0%)] Loss: 0.113655
Training set [3840/6430 (59%)] Loss: 0.123630
Training set: Average loss: 0.134088
Training set: Average accuracy: 95.63%
Validation set: Average loss: 1.233470, Accuracy: 732/1050 (70%)

Epoch: 18
Training set [0/6430 (0%)] Loss: 0.098445
Training set [3840/6430 (59%)] Loss: 0.106282
Training set: Average loss: 0.111443
Training set: Average accuracy: 96.66%
Validation set: Average loss: 1.248117, Accuracy: 753/1050 (72%)

Epoch: 19
Training set [0/6430 (0%)] Loss: 0.083023
Training set [3840/6430 (59%)] Loss: 0.108787
Training set: Average loss: 0.102197
Training set: Average accuracy: 96.92%
Validation set: Average loss: 1.221857, Accuracy: 748/1050 (71%)

Epoch: 20
Training set [0/6430 (0%)] Loss: 0.083779
Training set [3840/6430 (59%)] Loss: 0.066432
Training set: Average loss: 0.088799
Training set: Average accuracy: 97.20%
Validation set: Average loss: 1.225296, Accuracy: 766/1050 (73%)

Epoch: 21
Training set [0/6430 (0%)] Loss: 0.090956
Training set [3840/6430 (59%)] Loss: 0.079587
Training set: Average loss: 0.081761
Training set: Average accuracy: 97.45%
Validation set: Average loss: 1.288179, Accuracy: 749/1050 (71%)

Epoch: 22
Training set [0/6430 (0%)] Loss: 0.095484
Training set [3840/6430 (59%)] Loss: 0.066638
Training set: Average loss: 0.071947
Training set: Average accuracy: 97.84%
Validation set: Average loss: 1.286260, Accuracy: 753/1050 (72%)

Epoch: 23
Training set [0/6430 (0%)] Loss: 0.060626
Training set [3840/6430 (59%)] Loss: 0.060407
Training set: Average loss: 0.066472
Training set: Average accuracy: 97.84%
Validation set: Average loss: 1.330990, Accuracy: 757/1050 (72%)

Epoch: 24
Training set [0/6430 (0%)] Loss: 0.068555
Training set [3840/6430 (59%)] Loss: 0.074327
Training set: Average loss: 0.057096
Training set: Average accuracy: 98.23%
Validation set: Average loss: 1.351536, Accuracy: 767/1050 (73%)

Epoch: 25
Training set [0/6430 (0%)] Loss: 0.052448
Training set [3840/6430 (59%)] Loss: 0.044441
Training set: Average loss: 0.060010
Training set: Average accuracy: 98.16%
Validation set: Average loss: 1.406181, Accuracy: 736/1050 (70%)

Epoch: 26
Training set [0/6430 (0%)] Loss: 0.078063
Training set [3840/6430 (59%)] Loss: 0.046654
Training set: Average loss: 0.056168
Training set: Average accuracy: 98.37%
Validation set: Average loss: 1.349402, Accuracy: 745/1050 (71%)

Epoch: 27
Training set [0/6430 (0%)] Loss: 0.061681
Training set [3840/6430 (59%)] Loss: 0.066469
Training set: Average loss: 0.053172
Training set: Average accuracy: 98.37%
Validation set: Average loss: 1.511635, Accuracy: 743/1050 (71%)

Epoch: 28
Training set [0/6430 (0%)] Loss: 0.029349
Training set [3840/6430 (59%)] Loss: 0.036164
Training set: Average loss: 0.045734
Training set: Average accuracy: 98.63%
Validation set: Average loss: 1.456513, Accuracy: 748/1050 (71%)

Epoch: 29
Training set [0/6430 (0%)] Loss: 0.052344
Training set [3840/6430 (59%)] Loss: 0.077100
Training set: Average loss: 0.056148
Training set: Average accuracy: 98.41%
Validation set: Average loss: 1.393557, Accuracy: 744/1050 (71%)

Epoch: 30
Training set [0/6430 (0%)] Loss: 0.066914
Training set [3840/6430 (59%)] Loss: 0.053500
Training set: Average loss: 0.051600
Training set: Average accuracy: 98.37%
Validation set: Average loss: 1.425575, Accuracy: 757/1050 (72%)

Epoch: 31
Training set [0/6430 (0%)] Loss: 0.029014
Training set [3840/6430 (59%)] Loss: 0.039909
Training set: Average loss: 0.042285
Training set: Average accuracy: 98.58%
Validation set: Average loss: 1.568621, Accuracy: 739/1050 (70%)

Epoch: 32
Training set [0/6430 (0%)] Loss: 0.027737
Training set [3840/6430 (59%)] Loss: 0.035843
Training set: Average loss: 0.044150
Training set: Average accuracy: 98.76%
Validation set: Average loss: 1.488199, Accuracy: 753/1050 (72%)

Epoch: 33
Training set [0/6430 (0%)] Loss: 0.024269
Training set [3840/6430 (59%)] Loss: 0.044184
Training set: Average loss: 0.041293
Training set: Average accuracy: 98.69%
Validation set: Average loss: 1.501711, Accuracy: 742/1050 (71%)

Epoch: 34
Training set [0/6430 (0%)] Loss: 0.024958
Training set [3840/6430 (59%)] Loss: 0.046702
Training set: Average loss: 0.035555
Training set: Average accuracy: 98.91%
Validation set: Average loss: 1.535287, Accuracy: 744/1050 (71%)

Epoch: 35
Training set [0/6430 (0%)] Loss: 0.026632
Training set [3840/6430 (59%)] Loss: 0.048889
Training set: Average loss: 0.033960
Training set: Average accuracy: 98.93%
Validation set: Average loss: 1.590594, Accuracy: 754/1050 (72%)

Epoch: 36
Training set [0/6430 (0%)] Loss: 0.027184
Training set [3840/6430 (59%)] Loss: 0.018813
Training set: Average loss: 0.031467
Training set: Average accuracy: 99.02%
Validation set: Average loss: 1.530984, Accuracy: 768/1050 (73%)

Epoch: 37
Training set [0/6430 (0%)] Loss: 0.032396
Training set [3840/6430 (59%)] Loss: 0.025778
Training set: Average loss: 0.040432
Training set: Average accuracy: 98.69%
Validation set: Average loss: 1.511508, Accuracy: 736/1050 (70%)

Epoch: 38
Training set [0/6430 (0%)] Loss: 0.057082
Training set [3840/6430 (59%)] Loss: 0.041823
Training set: Average loss: 0.039804
Training set: Average accuracy: 98.74%
Validation set: Average loss: 1.435741, Accuracy: 757/1050 (72%)

Epoch: 39
Training set [0/6430 (0%)] Loss: 0.034766
Training set [3840/6430 (59%)] Loss: 0.029863
Training set: Average loss: 0.038012
Training set: Average accuracy: 98.82%
Validation set: Average loss: 1.515068, Accuracy: 757/1050 (72%)

Epoch: 40
Training set [0/6430 (0%)] Loss: 0.022220
Training set [3840/6430 (59%)] Loss: 0.034916
Training set: Average loss: 0.031381
Training set: Average accuracy: 99.07%
Validation set: Average loss: 1.611915, Accuracy: 737/1050 (70%)

Epoch: 41
Training set [0/6430 (0%)] Loss: 0.047835
Training set [3840/6430 (59%)] Loss: 0.036309
Training set: Average loss: 0.037942
Training set: Average accuracy: 98.65%
Validation set: Average loss: 1.539245, Accuracy: 738/1050 (70%)

Epoch: 42
Training set [0/6430 (0%)] Loss: 0.033491
Training set [3840/6430 (59%)] Loss: 0.035357
Training set: Average loss: 0.031495
Training set: Average accuracy: 99.05%
Validation set: Average loss: 1.441935, Accuracy: 760/1050 (72%)

Epoch: 43
Training set [0/6430 (0%)] Loss: 0.027747
Training set [3840/6430 (59%)] Loss: 0.034771
Training set: Average loss: 0.029643
Training set: Average accuracy: 98.97%
Validation set: Average loss: 1.459213, Accuracy: 753/1050 (72%)

Epoch: 44
Training set [0/6430 (0%)] Loss: 0.021530
Training set [3840/6430 (59%)] Loss: 0.026244
Training set: Average loss: 0.025910
Training set: Average accuracy: 99.19%
Validation set: Average loss: 1.485137, Accuracy: 762/1050 (73%)

Epoch: 45
Training set [0/6430 (0%)] Loss: 0.017280
Training set [3840/6430 (59%)] Loss: 0.022223
Training set: Average loss: 0.023599
Training set: Average accuracy: 99.27%
Validation set: Average loss: 1.613422, Accuracy: 758/1050 (72%)

Epoch: 46
Training set [0/6430 (0%)] Loss: 0.013230
Training set [3840/6430 (59%)] Loss: 0.033996
Training set: Average loss: 0.020675
Training set: Average accuracy: 99.44%
Validation set: Average loss: 1.517265, Accuracy: 760/1050 (72%)

Epoch: 47
Training set [0/6430 (0%)] Loss: 0.014775
Training set [3840/6430 (59%)] Loss: 0.017730
Training set: Average loss: 0.017512
Training set: Average accuracy: 99.50%
Validation set: Average loss: 1.617725, Accuracy: 771/1050 (73%)

Epoch: 48
Training set [0/6430 (0%)] Loss: 0.014179
Training set [3840/6430 (59%)] Loss: 0.037069
Training set: Average loss: 0.024391
Training set: Average accuracy: 99.27%
Validation set: Average loss: 1.567573, Accuracy: 755/1050 (72%)

Epoch: 49
Training set [0/6430 (0%)] Loss: 0.020633
Training set [3840/6430 (59%)] Loss: 0.019415
Training set: Average loss: 0.026616
Training set: Average accuracy: 99.02%
Validation set: Average loss: 1.531921, Accuracy: 751/1050 (72%)

Epoch: 50
Training set [0/6430 (0%)] Loss: 0.012833
Training set [3840/6430 (59%)] Loss: 0.013332
Training set: Average loss: 0.025698
Training set: Average accuracy: 99.22%
Validation set: Average loss: 1.542498, Accuracy: 748/1050 (71%)

Epoch: 51
Training set [0/6430 (0%)] Loss: 0.025197
Training set [3840/6430 (59%)] Loss: 0.030775
Training set: Average loss: 0.029787
Training set: Average accuracy: 99.13%
Validation set: Average loss: 1.539949, Accuracy: 752/1050 (72%)

Epoch: 52
Training set [0/6430 (0%)] Loss: 0.030297
Training set [3840/6430 (59%)] Loss: 0.017282
Training set: Average loss: 0.023423
Training set: Average accuracy: 99.25%
Validation set: Average loss: 1.525083, Accuracy: 742/1050 (71%)

Epoch: 53
Training set [0/6430 (0%)] Loss: 0.020000
Training set [3840/6430 (59%)] Loss: 0.032134
Training set: Average loss: 0.023264
Training set: Average accuracy: 99.32%
Validation set: Average loss: 1.530582, Accuracy: 756/1050 (72%)

Epoch: 54
Training set [0/6430 (0%)] Loss: 0.010334
Training set [3840/6430 (59%)] Loss: 0.022876
Training set: Average loss: 0.022846
Training set: Average accuracy: 99.21%
Validation set: Average loss: 1.584431, Accuracy: 764/1050 (73%)

Epoch: 55
Training set [0/6430 (0%)] Loss: 0.020251
Training set [3840/6430 (59%)] Loss: 0.009129
Training set: Average loss: 0.026187
Training set: Average accuracy: 99.13%
Validation set: Average loss: 1.429351, Accuracy: 762/1050 (73%)

Epoch: 56
Training set [0/6430 (0%)] Loss: 0.018080
Training set [3840/6430 (59%)] Loss: 0.026662
Training set: Average loss: 0.023728
Training set: Average accuracy: 99.25%
Validation set: Average loss: 1.606771, Accuracy: 753/1050 (72%)

Epoch: 57
Training set [0/6430 (0%)] Loss: 0.013530
Training set [3840/6430 (59%)] Loss: 0.072729
Training set: Average loss: 0.024756
Training set: Average accuracy: 99.28%
Validation set: Average loss: 1.643066, Accuracy: 760/1050 (72%)

Early stopping: no improvement for 10 epochs
ImprovedNet
training_loss -- validation_loss
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57]
[2.048886130837833, 1.8635396606781904, 1.7102387161815868, 1.575540353270138, 1.43315229696386, 1.2611487542881685, 1.1049951595418595, 0.9338894065688638, 0.7770887122434729, 0.6390787888975704, 0.5100169251946842, 0.4082330938647775, 0.3376167556818794, 0.26874368243357716, 0.2283388385001351, 0.18341761038583868, 0.16037778512519948, 0.134087935090065, 0.11144344859263476, 0.10219745491357411, 0.08879930153489113, 0.08176140268059338, 0.07194712407448713, 0.06647238069597412, 0.05709557848818162, 0.060010486337191915, 0.05616819179233383, 0.053171729668974876, 0.04573448594002163, 0.05614803205518162, 0.05160031708724359, 0.04228498370331876, 0.04415035357370096, 0.041293499662595635, 0.03555527384228566, 0.033960335504482776, 0.031466518145273716, 0.04043177701532841, 0.039804254055899733, 0.03801241484196747, 0.03138121064094936, 0.03794161668595146, 0.031494536108392125, 0.029642977642224115, 0.025910492657738572, 0.023598793127080974, 0.02067489642649889, 0.017512492479427773, 0.024391478749320787, 0.026615804116077283, 0.025698365205351043, 0.029787498800193563, 0.02342263181858203, 0.02326358904075973, 0.02284604957436814, 0.026187392773435396, 0.023727634099914748, 0.024755904615363655]
[1.9274117549260457, 1.7957366704940796, 1.6670353412628174, 1.5175490379333496, 1.4280976454416912, 1.328597108523051, 1.2383115688959758, 1.1694351037343342, 1.1102992296218872, 1.0811243851979573, 1.041116197903951, 1.0498037338256836, 1.1127393245697021, 1.087402065594991, 1.1480339368184407, 1.1730039517084758, 1.1067489385604858, 1.2334695259730022, 1.2481168111165364, 1.221856713294983, 1.2252963781356812, 1.2881787618001301, 1.2862597703933716, 1.3309903939565022, 1.351535677909851, 1.4061813751856487, 1.3494020700454712, 1.511635184288025, 1.4565132061640422, 1.393557071685791, 1.4255750974019368, 1.5686211983362834, 1.4881994724273682, 1.5017112096150715, 1.5352874994277954, 1.5905937751134236, 1.5309836467107136, 1.5115082263946533, 1.43574055035909, 1.5150679349899292, 1.6119149923324585, 1.5392447710037231, 1.4419352610905964, 1.459213137626648, 1.485136866569519, 1.613422195116679, 1.5172653595606487, 1.617725133895874, 1.5675730307896931, 1.53192142645518, 1.5424983104070027, 1.5399487813313801, 1.5250834226608276, 1.5305822292963664, 1.5844311316808064, 1.4293510913848877, 1.6067707935969036, 1.64306644598643]
ImprovedNet
training_accuracy -- validation_accuracy
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57]
[15.318818040435458, 23.763608087091757, 34.58786936236392, 41.64852255054432, 47.838258164852256, 54.30793157076205, 60.824261275272164, 67.32503888024884, 73.48367029548989, 78.0248833592535, 82.50388802488335, 85.8786936236392, 88.98911353032659, 90.77760497667185, 92.45723172628306, 94.0746500777605, 94.68118195956454, 95.6298600311042, 96.65629860031105, 96.92068429237948, 97.20062208398134, 97.44945567651634, 97.83825816485225, 97.83825816485225, 98.22706065318818, 98.16485225505443, 98.36702954898911, 98.36702954898911, 98.63141524105754, 98.41368584758942, 98.36702954898911, 98.58475894245723, 98.75583203732504, 98.69362363919129, 98.9113530326594, 98.92690513219284, 99.02021772939347, 98.69362363919129, 98.7402799377916, 98.81804043545878, 99.06687402799378, 98.64696734059098, 99.05132192846034, 98.97356143079315, 99.19129082426127, 99.26905132192846, 99.44012441679627, 99.50233281493001, 99.26905132192846, 99.02021772939347, 99.22239502332815, 99.12908242612752, 99.25349922239502, 99.31570762052877, 99.20684292379471, 99.12908242612752, 99.25349922239502, 99.2846034214619]
[22.476190476190474, 28.476190476190474, 40.19047619047619, 45.61904761904762, 48.666666666666664, 52.19047619047619, 56.38095238095238, 60.285714285714285, 61.333333333333336, 63.80952380952381, 66.76190476190476, 68.19047619047619, 69.04761904761905, 69.33333333333333, 69.80952380952381, 70.66666666666667, 72.0952380952381, 69.71428571428571, 71.71428571428571, 71.23809523809524, 72.95238095238095, 71.33333333333333, 71.71428571428571, 72.0952380952381, 73.04761904761905, 70.0952380952381, 70.95238095238095, 70.76190476190476, 71.23809523809524, 70.85714285714286, 72.0952380952381, 70.38095238095238, 71.71428571428571, 70.66666666666667, 70.85714285714286, 71.80952380952381, 73.14285714285714, 70.0952380952381, 72.0952380952381, 72.0952380952381, 70.19047619047619, 70.28571428571429, 72.38095238095238, 71.71428571428571, 72.57142857142857, 72.19047619047619, 72.38095238095238, 73.42857142857143, 71.9047619047619, 71.52380952380952, 71.23809523809524, 71.61904761904762, 70.66666666666667, 72.0, 72.76190476190476, 72.57142857142857, 71.71428571428571, 72.38095238095238]
model saved as model_store_384/cnn_car_ImprovedNet.pt
Getting predictions from test set...
ImprovedNet
[[110  10   0  18   6   1   5]
 [ 11  87   4   5  14   5  24]
 [ 10   4 115   2   1   4  14]
 [ 35   3   7  76   2   9  18]
 [  3   2   2   2 133   0   8]
 [  2   6   9   5   1 120   7]
 [  5   6  11   4   3   2 119]]
=============================
ImprovedNetLite
=============================
Epoch: 0
Training set [0/6430 (0%)] Loss: 2.053060
Training set [3840/6430 (59%)] Loss: 1.895393
Training set: Average loss: 2.495047
Training set: Average accuracy: 17.84%
Validation set: Average loss: 1.938280, Accuracy: 183/1050 (17%)

Epoch: 1
Training set [0/6430 (0%)] Loss: 1.894394
Training set [3840/6430 (59%)] Loss: 1.818457
Training set: Average loss: 1.861093
Training set: Average accuracy: 22.44%
Validation set: Average loss: 1.912859, Accuracy: 185/1050 (18%)

Epoch: 2
Training set [0/6430 (0%)] Loss: 1.793855
Training set [3840/6430 (59%)] Loss: 1.797113
Training set: Average loss: 1.782487
Training set: Average accuracy: 26.67%
Validation set: Average loss: 1.813059, Accuracy: 299/1050 (28%)

Epoch: 3
Training set [0/6430 (0%)] Loss: 1.771523
Training set [3840/6430 (59%)] Loss: 1.693636
Training set: Average loss: 1.728061
Training set: Average accuracy: 30.75%
Validation set: Average loss: 1.733904, Accuracy: 343/1050 (33%)

Epoch: 4
Training set [0/6430 (0%)] Loss: 1.689003
Training set [3840/6430 (59%)] Loss: 1.655541
Training set: Average loss: 1.668123
Training set: Average accuracy: 33.64%
Validation set: Average loss: 1.614402, Accuracy: 432/1050 (41%)

Epoch: 5
Training set [0/6430 (0%)] Loss: 1.613820
Training set [3840/6430 (59%)] Loss: 1.593596
Training set: Average loss: 1.614844
Training set: Average accuracy: 36.91%
Validation set: Average loss: 1.573593, Accuracy: 447/1050 (43%)

Epoch: 6
Training set [0/6430 (0%)] Loss: 1.588352
Training set [3840/6430 (59%)] Loss: 1.489943
Training set: Average loss: 1.548122
Training set: Average accuracy: 39.07%
Validation set: Average loss: 1.493631, Accuracy: 482/1050 (46%)

Epoch: 7
Training set [0/6430 (0%)] Loss: 1.537580
Training set [3840/6430 (59%)] Loss: 1.469712
Training set: Average loss: 1.497316
Training set: Average accuracy: 40.82%
Validation set: Average loss: 1.428699, Accuracy: 508/1050 (48%)

Epoch: 8
Training set [0/6430 (0%)] Loss: 1.416700
Training set [3840/6430 (59%)] Loss: 1.397090
Training set: Average loss: 1.430980
Training set: Average accuracy: 44.42%
Validation set: Average loss: 1.412545, Accuracy: 512/1050 (49%)

Epoch: 9
Training set [0/6430 (0%)] Loss: 1.335190
Training set [3840/6430 (59%)] Loss: 1.442364
Training set: Average loss: 1.367797
Training set: Average accuracy: 46.84%
Validation set: Average loss: 1.354613, Accuracy: 558/1050 (53%)

Epoch: 10
Training set [0/6430 (0%)] Loss: 1.355005
Training set [3840/6430 (59%)] Loss: 1.201090
Training set: Average loss: 1.296243
Training set: Average accuracy: 49.16%
Validation set: Average loss: 1.314444, Accuracy: 554/1050 (53%)

Epoch: 11
Training set [0/6430 (0%)] Loss: 1.199409
Training set [3840/6430 (59%)] Loss: 1.213516
Training set: Average loss: 1.251918
Training set: Average accuracy: 50.54%
Validation set: Average loss: 1.290046, Accuracy: 573/1050 (55%)

Epoch: 12
Training set [0/6430 (0%)] Loss: 1.176406
Training set [3840/6430 (59%)] Loss: 1.297010
Training set: Average loss: 1.195040
Training set: Average accuracy: 52.35%
Validation set: Average loss: 1.414360, Accuracy: 514/1050 (49%)

Epoch: 13
Training set [0/6430 (0%)] Loss: 1.209170
Training set [3840/6430 (59%)] Loss: 1.205955
Training set: Average loss: 1.150495
Training set: Average accuracy: 54.76%
Validation set: Average loss: 1.079265, Accuracy: 639/1050 (61%)

Epoch: 14
Training set [0/6430 (0%)] Loss: 1.040446
Training set [3840/6430 (59%)] Loss: 1.258622
Training set: Average loss: 1.115806
Training set: Average accuracy: 55.97%
Validation set: Average loss: 1.122155, Accuracy: 661/1050 (63%)

Epoch: 15
Training set [0/6430 (0%)] Loss: 1.157132
Training set [3840/6430 (59%)] Loss: 1.044748
Training set: Average loss: 1.111928
Training set: Average accuracy: 55.49%
Validation set: Average loss: 1.147010, Accuracy: 620/1050 (59%)

Epoch: 16
Training set [0/6430 (0%)] Loss: 1.128206
Training set [3840/6430 (59%)] Loss: 1.020524
Training set: Average loss: 1.066280
Training set: Average accuracy: 57.08%
Validation set: Average loss: 1.099601, Accuracy: 631/1050 (60%)

Epoch: 17
Training set [0/6430 (0%)] Loss: 1.034814
Training set [3840/6430 (59%)] Loss: 1.001035
Training set: Average loss: 1.029531
Training set: Average accuracy: 58.86%
Validation set: Average loss: 1.082697, Accuracy: 664/1050 (63%)

Epoch: 18
Training set [0/6430 (0%)] Loss: 0.998230
Training set [3840/6430 (59%)] Loss: 0.918749
Training set: Average loss: 1.001903
Training set: Average accuracy: 59.19%
Validation set: Average loss: 1.066252, Accuracy: 643/1050 (61%)

Epoch: 19
Training set [0/6430 (0%)] Loss: 0.965468
Training set [3840/6430 (59%)] Loss: 1.027001
Training set: Average loss: 0.968288
Training set: Average accuracy: 61.10%
Validation set: Average loss: 0.995948, Accuracy: 699/1050 (67%)

Epoch: 20
Training set [0/6430 (0%)] Loss: 0.914084
Training set [3840/6430 (59%)] Loss: 0.977875
Training set: Average loss: 0.956279
Training set: Average accuracy: 61.38%
Validation set: Average loss: 1.078303, Accuracy: 664/1050 (63%)

Epoch: 21
Training set [0/6430 (0%)] Loss: 0.898236
Training set [3840/6430 (59%)] Loss: 0.981950
Training set: Average loss: 0.922970
Training set: Average accuracy: 62.36%
Validation set: Average loss: 0.944222, Accuracy: 717/1050 (68%)

Epoch: 22
Training set [0/6430 (0%)] Loss: 0.941868
Training set [3840/6430 (59%)] Loss: 0.855467
Training set: Average loss: 0.908025
Training set: Average accuracy: 62.69%
Validation set: Average loss: 1.176762, Accuracy: 621/1050 (59%)

Epoch: 23
Training set [0/6430 (0%)] Loss: 0.819390
Training set [3840/6430 (59%)] Loss: 0.844791
Training set: Average loss: 0.884448
Training set: Average accuracy: 63.62%
Validation set: Average loss: 0.872237, Accuracy: 747/1050 (71%)

Epoch: 24
Training set [0/6430 (0%)] Loss: 0.829532
Training set [3840/6430 (59%)] Loss: 0.885140
Training set: Average loss: 0.861088
Training set: Average accuracy: 64.68%
Validation set: Average loss: 1.042355, Accuracy: 696/1050 (66%)

Epoch: 25
Training set [0/6430 (0%)] Loss: 0.804483
Training set [3840/6430 (59%)] Loss: 0.875361
Training set: Average loss: 0.849686
Training set: Average accuracy: 64.85%
Validation set: Average loss: 0.983042, Accuracy: 724/1050 (69%)

Epoch: 26
Training set [0/6430 (0%)] Loss: 0.961032
Training set [3840/6430 (59%)] Loss: 0.858388
Training set: Average loss: 0.833162
Training set: Average accuracy: 65.74%
Validation set: Average loss: 1.016492, Accuracy: 677/1050 (64%)

Epoch: 27
Training set [0/6430 (0%)] Loss: 0.802461
Training set [3840/6430 (59%)] Loss: 0.800198
Training set: Average loss: 0.822721
Training set: Average accuracy: 65.96%
Validation set: Average loss: 0.867854, Accuracy: 750/1050 (71%)

Epoch: 28
Training set [0/6430 (0%)] Loss: 0.714616
Training set [3840/6430 (59%)] Loss: 0.862335
Training set: Average loss: 0.792857
Training set: Average accuracy: 66.92%
Validation set: Average loss: 0.963861, Accuracy: 721/1050 (69%)

Epoch: 29
Training set [0/6430 (0%)] Loss: 0.824470
Training set [3840/6430 (59%)] Loss: 0.846150
Training set: Average loss: 0.793620
Training set: Average accuracy: 67.08%
Validation set: Average loss: 0.921799, Accuracy: 752/1050 (72%)

Epoch: 30
Training set [0/6430 (0%)] Loss: 0.764417
Training set [3840/6430 (59%)] Loss: 0.812298
Training set: Average loss: 0.789810
Training set: Average accuracy: 67.22%
Validation set: Average loss: 0.906834, Accuracy: 735/1050 (70%)

Epoch: 31
Training set [0/6430 (0%)] Loss: 0.688086
Training set [3840/6430 (59%)] Loss: 0.812497
Training set: Average loss: 0.764433
Training set: Average accuracy: 67.53%
Validation set: Average loss: 0.999052, Accuracy: 731/1050 (70%)

Epoch: 32
Training set [0/6430 (0%)] Loss: 0.793807
Training set [3840/6430 (59%)] Loss: 0.761115
Training set: Average loss: 0.758339
Training set: Average accuracy: 67.42%
Validation set: Average loss: 1.075837, Accuracy: 667/1050 (64%)

Epoch: 33
Training set [0/6430 (0%)] Loss: 0.756257
Training set [3840/6430 (59%)] Loss: 0.681356
Training set: Average loss: 0.749614
Training set: Average accuracy: 68.16%
Validation set: Average loss: 0.820723, Accuracy: 750/1050 (71%)

Epoch: 34
Training set [0/6430 (0%)] Loss: 0.724501
Training set [3840/6430 (59%)] Loss: 0.742297
Training set: Average loss: 0.744038
Training set: Average accuracy: 69.10%
Validation set: Average loss: 1.173677, Accuracy: 649/1050 (62%)

Epoch: 35
Training set [0/6430 (0%)] Loss: 0.677529
Training set [3840/6430 (59%)] Loss: 0.720618
Training set: Average loss: 0.713084
Training set: Average accuracy: 70.03%
Validation set: Average loss: 1.007885, Accuracy: 715/1050 (68%)

Epoch: 36
Training set [0/6430 (0%)] Loss: 0.656731
Training set [3840/6430 (59%)] Loss: 0.702994
Training set: Average loss: 0.722133
Training set: Average accuracy: 70.14%
Validation set: Average loss: 0.966267, Accuracy: 760/1050 (72%)

Epoch: 37
Training set [0/6430 (0%)] Loss: 0.644040
Training set [3840/6430 (59%)] Loss: 0.714405
Training set: Average loss: 0.730855
Training set: Average accuracy: 68.85%
Validation set: Average loss: 0.969079, Accuracy: 727/1050 (69%)

Epoch: 38
Training set [0/6430 (0%)] Loss: 0.744076
Training set [3840/6430 (59%)] Loss: 0.712742
Training set: Average loss: 0.736028
Training set: Average accuracy: 68.94%
Validation set: Average loss: 0.950553, Accuracy: 742/1050 (71%)

Epoch: 39
Training set [0/6430 (0%)] Loss: 0.696497
Training set [3840/6430 (59%)] Loss: 0.652400
Training set: Average loss: 0.692120
Training set: Average accuracy: 70.42%
Validation set: Average loss: 0.795151, Accuracy: 792/1050 (75%)

Epoch: 40
Training set [0/6430 (0%)] Loss: 0.735436
Training set [3840/6430 (59%)] Loss: 0.611168
Training set: Average loss: 0.688469
Training set: Average accuracy: 70.31%
Validation set: Average loss: 0.861689, Accuracy: 784/1050 (75%)

Epoch: 41
Training set [0/6430 (0%)] Loss: 0.645260
Training set [3840/6430 (59%)] Loss: 0.706526
Training set: Average loss: 0.679599
Training set: Average accuracy: 70.12%
Validation set: Average loss: 0.969766, Accuracy: 732/1050 (70%)

Epoch: 42
Training set [0/6430 (0%)] Loss: 0.629365
Training set [3840/6430 (59%)] Loss: 0.661702
Training set: Average loss: 0.678701
Training set: Average accuracy: 70.68%
Validation set: Average loss: 0.962666, Accuracy: 760/1050 (72%)

Epoch: 43
Training set [0/6430 (0%)] Loss: 0.626998
Training set [3840/6430 (59%)] Loss: 0.745442
Training set: Average loss: 0.672701
Training set: Average accuracy: 71.09%
Validation set: Average loss: 0.823535, Accuracy: 802/1050 (76%)

Epoch: 44
Training set [0/6430 (0%)] Loss: 0.683881
Training set [3840/6430 (59%)] Loss: 0.633367
Training set: Average loss: 0.658528
Training set: Average accuracy: 71.65%
Validation set: Average loss: 1.099264, Accuracy: 706/1050 (67%)

Epoch: 45
Training set [0/6430 (0%)] Loss: 0.645348
Training set [3840/6430 (59%)] Loss: 0.684149
Training set: Average loss: 0.665604
Training set: Average accuracy: 71.09%
Validation set: Average loss: 0.945793, Accuracy: 755/1050 (72%)

Epoch: 46
Training set [0/6430 (0%)] Loss: 0.598906
Training set [3840/6430 (59%)] Loss: 0.715997
Training set: Average loss: 0.656483
Training set: Average accuracy: 71.80%
Validation set: Average loss: 0.829338, Accuracy: 776/1050 (74%)

Epoch: 47
Training set [0/6430 (0%)] Loss: 0.642839
Training set [3840/6430 (59%)] Loss: 0.650889
Training set: Average loss: 0.643858
Training set: Average accuracy: 72.78%
Validation set: Average loss: 0.988030, Accuracy: 745/1050 (71%)

Epoch: 48
Training set [0/6430 (0%)] Loss: 0.584112
Training set [3840/6430 (59%)] Loss: 0.548747
Training set: Average loss: 0.608480
Training set: Average accuracy: 73.87%
Validation set: Average loss: 0.816482, Accuracy: 773/1050 (74%)

Epoch: 49
Training set [0/6430 (0%)] Loss: 0.628782
Training set [3840/6430 (59%)] Loss: 0.628904
Training set: Average loss: 0.641682
Training set: Average accuracy: 72.08%
Validation set: Average loss: 0.956871, Accuracy: 733/1050 (70%)

Epoch: 50
Training set [0/6430 (0%)] Loss: 0.589684
Training set [3840/6430 (59%)] Loss: 0.611247
Training set: Average loss: 0.618565
Training set: Average accuracy: 73.33%
Validation set: Average loss: 0.788214, Accuracy: 792/1050 (75%)

Epoch: 51
Training set [0/6430 (0%)] Loss: 0.657112
Training set [3840/6430 (59%)] Loss: 0.578532
Training set: Average loss: 0.589815
Training set: Average accuracy: 74.70%
Validation set: Average loss: 0.799092, Accuracy: 795/1050 (76%)

Epoch: 52
Training set [0/6430 (0%)] Loss: 0.619387
Training set [3840/6430 (59%)] Loss: 0.648235
Training set: Average loss: 0.622342
Training set: Average accuracy: 72.88%
Validation set: Average loss: 0.859349, Accuracy: 775/1050 (74%)

Epoch: 53
Training set [0/6430 (0%)] Loss: 0.640143
Training set [3840/6430 (59%)] Loss: 0.542257
Training set: Average loss: 0.586207
Training set: Average accuracy: 74.25%
Validation set: Average loss: 1.129977, Accuracy: 719/1050 (68%)

Epoch: 54
Training set [0/6430 (0%)] Loss: 0.604899
Training set [3840/6430 (59%)] Loss: 0.589500
Training set: Average loss: 0.598012
Training set: Average accuracy: 73.67%
Validation set: Average loss: 1.075929, Accuracy: 733/1050 (70%)

Epoch: 55
Training set [0/6430 (0%)] Loss: 0.585723
Training set [3840/6430 (59%)] Loss: 0.644167
Training set: Average loss: 0.604046
Training set: Average accuracy: 75.04%
Validation set: Average loss: 1.191025, Accuracy: 702/1050 (67%)

Epoch: 56
Training set [0/6430 (0%)] Loss: 0.611746
Training set [3840/6430 (59%)] Loss: 0.659756
Training set: Average loss: 0.596231
Training set: Average accuracy: 74.18%
Validation set: Average loss: 0.814734, Accuracy: 784/1050 (75%)

Epoch: 57
Training set [0/6430 (0%)] Loss: 0.545631
Training set [3840/6430 (59%)] Loss: 0.571359
Training set: Average loss: 0.587030
Training set: Average accuracy: 73.98%
Validation set: Average loss: 0.764625, Accuracy: 783/1050 (75%)

Epoch: 58
Training set [0/6430 (0%)] Loss: 0.579700
Training set [3840/6430 (59%)] Loss: 0.663798
Training set: Average loss: 0.607004
Training set: Average accuracy: 73.47%
Validation set: Average loss: 0.774784, Accuracy: 788/1050 (75%)

Epoch: 59
Training set [0/6430 (0%)] Loss: 0.562330
Training set [3840/6430 (59%)] Loss: 0.562921
Training set: Average loss: 0.568070
Training set: Average accuracy: 74.88%
Validation set: Average loss: 0.788646, Accuracy: 816/1050 (78%)

Epoch: 60
Training set [0/6430 (0%)] Loss: 0.548763
Training set [3840/6430 (59%)] Loss: 0.537451
Training set: Average loss: 0.575174
Training set: Average accuracy: 74.31%
Validation set: Average loss: 0.826653, Accuracy: 795/1050 (76%)

Epoch: 61
Training set [0/6430 (0%)] Loss: 0.474071
Training set [3840/6430 (59%)] Loss: 0.523926
Training set: Average loss: 0.547253
Training set: Average accuracy: 76.49%
Validation set: Average loss: 0.911800, Accuracy: 796/1050 (76%)

Epoch: 62
Training set [0/6430 (0%)] Loss: 0.548086
Training set [3840/6430 (59%)] Loss: 0.637346
Training set: Average loss: 0.575480
Training set: Average accuracy: 74.28%
Validation set: Average loss: 0.919217, Accuracy: 772/1050 (74%)

Epoch: 63
Training set [0/6430 (0%)] Loss: 0.551655
Training set [3840/6430 (59%)] Loss: 0.617268
Training set: Average loss: 0.550769
Training set: Average accuracy: 76.11%
Validation set: Average loss: 0.805446, Accuracy: 803/1050 (76%)

Epoch: 64
Training set [0/6430 (0%)] Loss: 0.503561
Training set [3840/6430 (59%)] Loss: 0.547453
Training set: Average loss: 0.549377
Training set: Average accuracy: 75.85%
Validation set: Average loss: 0.983955, Accuracy: 753/1050 (72%)

Epoch: 65
Training set [0/6430 (0%)] Loss: 0.611029
Training set [3840/6430 (59%)] Loss: 0.548993
Training set: Average loss: 0.568041
Training set: Average accuracy: 75.47%
Validation set: Average loss: 2.288774, Accuracy: 552/1050 (53%)

Epoch: 66
Training set [0/6430 (0%)] Loss: 0.543230
Training set [3840/6430 (59%)] Loss: 0.560676
Training set: Average loss: 0.545616
Training set: Average accuracy: 75.93%
Validation set: Average loss: 1.331346, Accuracy: 711/1050 (68%)

Epoch: 67
Training set [0/6430 (0%)] Loss: 0.542976
Training set [3840/6430 (59%)] Loss: 0.545440
Training set: Average loss: 0.540070
Training set: Average accuracy: 76.38%
Validation set: Average loss: 0.800868, Accuracy: 799/1050 (76%)

Epoch: 68
Training set [0/6430 (0%)] Loss: 0.540215
Training set [3840/6430 (59%)] Loss: 0.496959
Training set: Average loss: 0.541571
Training set: Average accuracy: 75.93%
Validation set: Average loss: 0.798832, Accuracy: 804/1050 (77%)

Epoch: 69
Training set [0/6430 (0%)] Loss: 0.537142
Training set [3840/6430 (59%)] Loss: 0.564372
Training set: Average loss: 0.550745
Training set: Average accuracy: 76.73%
Validation set: Average loss: 1.991151, Accuracy: 590/1050 (56%)

Epoch: 70
Training set [0/6430 (0%)] Loss: 0.557692
Training set [3840/6430 (59%)] Loss: 0.555605
Training set: Average loss: 0.564530
Training set: Average accuracy: 75.44%
Validation set: Average loss: 0.872962, Accuracy: 776/1050 (74%)

Epoch: 71
Training set [0/6430 (0%)] Loss: 0.622939
Training set [3840/6430 (59%)] Loss: 0.525139
Training set: Average loss: 0.539792
Training set: Average accuracy: 75.85%
Validation set: Average loss: 0.808638, Accuracy: 799/1050 (76%)

Epoch: 72
Training set [0/6430 (0%)] Loss: 0.500265
Training set [3840/6430 (59%)] Loss: 0.481747
Training set: Average loss: 0.538439
Training set: Average accuracy: 76.07%
Validation set: Average loss: 0.953761, Accuracy: 766/1050 (73%)

Epoch: 73
Training set [0/6430 (0%)] Loss: 0.608802
Training set [3840/6430 (59%)] Loss: 0.554658
Training set: Average loss: 0.529371
Training set: Average accuracy: 77.29%
Validation set: Average loss: 1.124297, Accuracy: 745/1050 (71%)

Epoch: 74
Training set [0/6430 (0%)] Loss: 0.464275
Training set [3840/6430 (59%)] Loss: 0.552795
Training set: Average loss: 0.508686
Training set: Average accuracy: 77.64%
Validation set: Average loss: 0.763231, Accuracy: 826/1050 (79%)

Epoch: 75
Training set [0/6430 (0%)] Loss: 0.505592
Training set [3840/6430 (59%)] Loss: 0.496652
Training set: Average loss: 0.534746
Training set: Average accuracy: 77.12%
Validation set: Average loss: 1.478311, Accuracy: 686/1050 (65%)

Epoch: 76
Training set [0/6430 (0%)] Loss: 0.508220
Training set [3840/6430 (59%)] Loss: 0.473923
Training set: Average loss: 0.518734
Training set: Average accuracy: 77.34%
Validation set: Average loss: 0.823492, Accuracy: 811/1050 (77%)

Epoch: 77
Training set [0/6430 (0%)] Loss: 0.533019
Training set [3840/6430 (59%)] Loss: 0.471688
Training set: Average loss: 0.500850
Training set: Average accuracy: 77.42%
Validation set: Average loss: 1.137102, Accuracy: 745/1050 (71%)

Epoch: 78
Training set [0/6430 (0%)] Loss: 0.502688
Training set [3840/6430 (59%)] Loss: 0.508583
Training set: Average loss: 0.499267
Training set: Average accuracy: 77.68%
Validation set: Average loss: 0.944213, Accuracy: 786/1050 (75%)

Epoch: 79
Training set [0/6430 (0%)] Loss: 0.467226
Training set [3840/6430 (59%)] Loss: 0.527113
Training set: Average loss: 0.498077
Training set: Average accuracy: 77.57%
Validation set: Average loss: 0.872613, Accuracy: 799/1050 (76%)

Epoch: 80
Training set [0/6430 (0%)] Loss: 0.541565
Training set [3840/6430 (59%)] Loss: 0.478093
Training set: Average loss: 0.506404
Training set: Average accuracy: 77.34%
Validation set: Average loss: 0.872746, Accuracy: 817/1050 (78%)

Epoch: 81
Training set [0/6430 (0%)] Loss: 0.505058
Training set [3840/6430 (59%)] Loss: 0.448098
Training set: Average loss: 0.490317
Training set: Average accuracy: 77.95%
Validation set: Average loss: 0.905229, Accuracy: 801/1050 (76%)

Epoch: 82
Training set [0/6430 (0%)] Loss: 0.500211
Training set [3840/6430 (59%)] Loss: 0.473007
Training set: Average loss: 0.472585
Training set: Average accuracy: 78.90%
Validation set: Average loss: 0.802635, Accuracy: 823/1050 (78%)

Epoch: 83
Training set [0/6430 (0%)] Loss: 0.492696
Training set [3840/6430 (59%)] Loss: 0.520300
Training set: Average loss: 0.489619
Training set: Average accuracy: 78.23%
Validation set: Average loss: 0.854098, Accuracy: 795/1050 (76%)

Epoch: 84
Training set [0/6430 (0%)] Loss: 0.441449
Training set [3840/6430 (59%)] Loss: 0.492625
Training set: Average loss: 0.478011
Training set: Average accuracy: 78.49%
Validation set: Average loss: 0.972027, Accuracy: 778/1050 (74%)

Epoch: 85
Training set [0/6430 (0%)] Loss: 0.477735
Training set [3840/6430 (59%)] Loss: 0.506213
Training set: Average loss: 0.494644
Training set: Average accuracy: 77.50%
Validation set: Average loss: 0.816535, Accuracy: 804/1050 (77%)

Epoch: 86
Training set [0/6430 (0%)] Loss: 0.482208
Training set [3840/6430 (59%)] Loss: 0.417931
Training set: Average loss: 0.490511
Training set: Average accuracy: 78.38%
Validation set: Average loss: 0.959991, Accuracy: 769/1050 (73%)

Epoch: 87
Training set [0/6430 (0%)] Loss: 0.508643
Training set [3840/6430 (59%)] Loss: 0.529537
Training set: Average loss: 0.485173
Training set: Average accuracy: 78.34%
Validation set: Average loss: 0.797117, Accuracy: 804/1050 (77%)

Epoch: 88
Training set [0/6430 (0%)] Loss: 0.469979
Training set [3840/6430 (59%)] Loss: 0.490135
Training set: Average loss: 0.470734
Training set: Average accuracy: 78.74%
Validation set: Average loss: 0.766688, Accuracy: 819/1050 (78%)

Epoch: 89
Training set [0/6430 (0%)] Loss: 0.487262
Training set [3840/6430 (59%)] Loss: 0.453208
Training set: Average loss: 0.470235
Training set: Average accuracy: 79.60%
Validation set: Average loss: 2.247666, Accuracy: 594/1050 (57%)

Epoch: 90
Training set [0/6430 (0%)] Loss: 0.506585
Training set [3840/6430 (59%)] Loss: 0.516781
Training set: Average loss: 0.469469
Training set: Average accuracy: 78.66%
Validation set: Average loss: 1.012219, Accuracy: 798/1050 (76%)

Epoch: 91
Training set [0/6430 (0%)] Loss: 0.483935
Training set [3840/6430 (59%)] Loss: 0.469990
Training set: Average loss: 0.466683
Training set: Average accuracy: 79.11%
Validation set: Average loss: 1.125489, Accuracy: 759/1050 (72%)

Epoch: 92
Training set [0/6430 (0%)] Loss: 0.459043
Training set [3840/6430 (59%)] Loss: 0.479466
Training set: Average loss: 0.497136
Training set: Average accuracy: 77.60%
Validation set: Average loss: 0.772982, Accuracy: 796/1050 (76%)

Epoch: 93
Training set [0/6430 (0%)] Loss: 0.473885
Training set [3840/6430 (59%)] Loss: 0.445026
Training set: Average loss: 0.463608
Training set: Average accuracy: 79.91%
Validation set: Average loss: 0.982218, Accuracy: 797/1050 (76%)

Epoch: 94
Training set [0/6430 (0%)] Loss: 0.464582
Training set [3840/6430 (59%)] Loss: 0.528125
Training set: Average loss: 0.481213
Training set: Average accuracy: 78.55%
Validation set: Average loss: 0.956883, Accuracy: 784/1050 (75%)

Epoch: 95
Training set [0/6430 (0%)] Loss: 0.505520
Training set [3840/6430 (59%)] Loss: 0.512757
Training set: Average loss: 0.462392
Training set: Average accuracy: 79.10%
Validation set: Average loss: 0.814111, Accuracy: 815/1050 (78%)

Epoch: 96
Training set [0/6430 (0%)] Loss: 0.444258
Training set [3840/6430 (59%)] Loss: 0.464767
Training set: Average loss: 0.461001
Training set: Average accuracy: 78.91%
Validation set: Average loss: 0.813634, Accuracy: 825/1050 (79%)

Epoch: 97
Training set [0/6430 (0%)] Loss: 0.408705
Training set [3840/6430 (59%)] Loss: 0.426652
Training set: Average loss: 0.470803
Training set: Average accuracy: 79.05%
Validation set: Average loss: 0.873583, Accuracy: 797/1050 (76%)

Epoch: 98
Training set [0/6430 (0%)] Loss: 0.564562
Training set [3840/6430 (59%)] Loss: 0.433176
Training set: Average loss: 0.456642
Training set: Average accuracy: 79.14%
Validation set: Average loss: 0.801776, Accuracy: 819/1050 (78%)

Epoch: 99
Training set [0/6430 (0%)] Loss: 0.483318
Training set [3840/6430 (59%)] Loss: 0.518533
Training set: Average loss: 0.472367
Training set: Average accuracy: 78.88%
Validation set: Average loss: 1.107376, Accuracy: 755/1050 (72%)

Epoch: 100
Training set [0/6430 (0%)] Loss: 0.496142
Training set [3840/6430 (59%)] Loss: 0.548021
Training set: Average loss: 0.484141
Training set: Average accuracy: 78.41%
Validation set: Average loss: 0.808397, Accuracy: 817/1050 (78%)

Epoch: 101
Training set [0/6430 (0%)] Loss: 0.532185
Training set [3840/6430 (59%)] Loss: 0.415996
Training set: Average loss: 0.462939
Training set: Average accuracy: 79.80%
Validation set: Average loss: 1.011245, Accuracy: 784/1050 (75%)

Epoch: 102
Training set [0/6430 (0%)] Loss: 0.437773
Training set [3840/6430 (59%)] Loss: 0.469162
Training set: Average loss: 0.463021
Training set: Average accuracy: 79.10%
Validation set: Average loss: 0.811386, Accuracy: 804/1050 (77%)

Epoch: 103
Training set [0/6430 (0%)] Loss: 0.477602
Training set [3840/6430 (59%)] Loss: 0.453840
Training set: Average loss: 0.435877
Training set: Average accuracy: 80.72%
Validation set: Average loss: 0.822671, Accuracy: 805/1050 (77%)

Epoch: 104
Training set [0/6430 (0%)] Loss: 0.453140
Training set [3840/6430 (59%)] Loss: 0.451796
Training set: Average loss: 0.446519
Training set: Average accuracy: 80.12%
Validation set: Average loss: 1.041691, Accuracy: 787/1050 (75%)

Epoch: 105
Training set [0/6430 (0%)] Loss: 0.426493
Training set [3840/6430 (59%)] Loss: 0.488674
Training set: Average loss: 0.437115
Training set: Average accuracy: 80.23%
Validation set: Average loss: 0.748598, Accuracy: 813/1050 (77%)

Epoch: 106
Training set [0/6430 (0%)] Loss: 0.401133
Training set [3840/6430 (59%)] Loss: 0.543374
Training set: Average loss: 0.444718
Training set: Average accuracy: 79.81%
Validation set: Average loss: 1.283491, Accuracy: 739/1050 (70%)

Epoch: 107
Training set [0/6430 (0%)] Loss: 0.453632
Training set [3840/6430 (59%)] Loss: 0.462813
Training set: Average loss: 0.457005
Training set: Average accuracy: 79.53%
Validation set: Average loss: 0.785898, Accuracy: 829/1050 (79%)

Epoch: 108
Training set [0/6430 (0%)] Loss: 0.462321
Training set [3840/6430 (59%)] Loss: 0.520057
Training set: Average loss: 0.455944
Training set: Average accuracy: 79.64%
Validation set: Average loss: 0.963766, Accuracy: 797/1050 (76%)

Epoch: 109
Training set [0/6430 (0%)] Loss: 0.497225
Training set [3840/6430 (59%)] Loss: 0.427168
Training set: Average loss: 0.436007
Training set: Average accuracy: 80.61%
Validation set: Average loss: 0.904845, Accuracy: 810/1050 (77%)

Epoch: 110
Training set [0/6430 (0%)] Loss: 0.389075
Training set [3840/6430 (59%)] Loss: 0.411934
Training set: Average loss: 0.447931
Training set: Average accuracy: 80.03%
Validation set: Average loss: 1.138345, Accuracy: 756/1050 (72%)

Epoch: 111
Training set [0/6430 (0%)] Loss: 0.466894
Training set [3840/6430 (59%)] Loss: 0.414752
Training set: Average loss: 0.448203
Training set: Average accuracy: 80.33%
Validation set: Average loss: 0.837847, Accuracy: 821/1050 (78%)

Epoch: 112
Training set [0/6430 (0%)] Loss: 0.401938
Training set [3840/6430 (59%)] Loss: 0.383874
Training set: Average loss: 0.437183
Training set: Average accuracy: 80.84%
Validation set: Average loss: 0.944369, Accuracy: 791/1050 (75%)

Epoch: 113
Training set [0/6430 (0%)] Loss: 0.430743
Training set [3840/6430 (59%)] Loss: 0.390521
Training set: Average loss: 0.444014
Training set: Average accuracy: 80.62%
Validation set: Average loss: 0.950783, Accuracy: 799/1050 (76%)

Early stopping: no improvement for 10 epochs
ImprovedNetLite
training_loss -- validation_loss
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113]
[2.495046713772942, 1.8610932967242073, 1.7824872802285587, 1.7280614376068115, 1.668122747365166, 1.6148437822566313, 1.5481219502056347, 1.4973158696118523, 1.430979896994198, 1.36779687685125, 1.2962428471621346, 1.2519178741118486, 1.1950401628718657, 1.15049507337458, 1.1158064183066874, 1.1119275934555952, 1.066280350965612, 1.029530637404498, 1.0019032814923454, 0.9682878781767452, 0.9562785800765542, 0.9229696918936336, 0.9080254856277915, 0.8844478831571692, 0.8610875711721533, 0.8496855146744672, 0.8331623708500582, 0.822721029029173, 0.7928574330666486, 0.79361974141177, 0.7898103840210858, 0.7644330122891594, 0.7583385004716761, 0.7496136567171883, 0.7440379156785852, 0.7130837230121388, 0.7221331245758954, 0.730855454416836, 0.7360276720103096, 0.6921200822381413, 0.6884691995732924, 0.6795991203364204, 0.6787008047103882, 0.6727005032932057, 0.6585284962373621, 0.6656036376953125, 0.6564833381596733, 0.6438577140078825, 0.6084803518126992, 0.641682084868936, 0.6185648791930255, 0.5898149784873513, 0.6223422429140877, 0.5862071759560529, 0.5980123000986436, 0.6040460888077231, 0.596230561242384, 0.5870302564957562, 0.6070036046645221, 0.5680704625213847, 0.5751741142833934, 0.5472526497700635, 0.5754795284832225, 0.5507688504808089, 0.5493772152592155, 0.5680413842201233, 0.5456161884700551, 0.5400704986908856, 0.5415713068316964, 0.5507452382760889, 0.5645304287181181, 0.5397921011728399, 0.5384392405257505, 0.5293708636480219, 0.508685687009026, 0.5347457791075987, 0.5187336364213158, 0.5008499096421635, 0.4992665490683387, 0.49807746796046987, 0.5064039528369904, 0.49031667148365693, 0.47258466131546917, 0.489618974573472, 0.4780110734350541, 0.4946444735807531, 0.49051088094711304, 0.48517287303419676, 0.47073403351447163, 0.4702354038462919, 0.46946854275815625, 0.46668348768178153, 0.4971359442262089, 0.46360791606061597, 0.48121266329989715, 0.46239151323542876, 0.46100110166213093, 0.4708026928060195, 0.45664230690282936, 0.4723665013032801, 0.48414070816601024, 0.46293905377388, 0.46302130117135887, 0.43587655530256386, 0.44651906279956594, 0.4371153326595531, 0.4447181312476887, 0.4570048924754648, 0.45594389473690705, 0.43600676515523124, 0.44793102671118346, 0.4482034059131847, 0.43718309437527375, 0.44401391464121204]
[1.9382797479629517, 1.9128591219584148, 1.813058614730835, 1.7339038848876953, 1.6144019762674968, 1.5735928217569988, 1.4936312834421794, 1.4286987781524658, 1.412544846534729, 1.354612946510315, 1.314443588256836, 1.2900458574295044, 1.4143600861231487, 1.079264760017395, 1.1221552689870198, 1.1470104058583577, 1.0996013879776, 1.0826974908510845, 1.0662520130475361, 0.9959475795427958, 1.0783032576243083, 0.9442223906517029, 1.176762064297994, 0.8722367286682129, 1.0423550407091777, 0.9830420017242432, 1.0164915124575298, 0.8678539395332336, 0.9638610283533732, 0.9217992027600607, 0.9068336884180704, 0.9990523060162863, 1.0758367379506428, 0.8207229773203532, 1.173676590124766, 1.0078853170077007, 0.9662672281265259, 0.9690789580345154, 0.9505530595779419, 0.7951505780220032, 0.86168905099233, 0.9697661201159159, 0.962665836016337, 0.823535164197286, 1.099263608455658, 0.9457932511965433, 0.829338014125824, 0.9880298177401224, 0.8164819081624349, 0.9568707148234049, 0.7882142265637716, 0.7990916967391968, 0.8593494693438212, 1.1299772659937541, 1.0759294827779133, 1.1910253167152405, 0.8147342006365458, 0.7646250327428182, 0.7747839291890463, 0.7886456449826559, 0.8266531427701315, 0.9118000864982605, 0.9192172090212504, 0.8054462273915609, 0.983955442905426, 2.2887741327285767, 1.3313459356625874, 0.8008677959442139, 0.7988318204879761, 1.9911511341730754, 0.8729620178540548, 0.8086381753285726, 0.9537606835365295, 1.1242970029513042, 0.7632308006286621, 1.4783106644948323, 0.8234917720158895, 1.1371018886566162, 0.9442126750946045, 0.8726133108139038, 0.8727460503578186, 0.9052291313807169, 0.8026351928710938, 0.8540982405344645, 0.972027321656545, 0.8165349960327148, 0.9599910378456116, 0.7971173922220866, 0.7666883865992228, 2.2476664781570435, 1.0122192700703938, 1.1254889567693074, 0.7729823986689249, 0.9822176297505697, 0.9568833311398824, 0.8141112327575684, 0.8136338194211324, 0.8735825220743815, 0.8017756740252177, 1.1073755621910095, 0.8083967367808024, 1.0112453699111938, 0.8113856315612793, 0.8226712544759115, 1.0416910648345947, 0.7485978007316589, 1.2834914525349934, 0.7858979304631551, 0.9637661774953207, 0.9048454165458679, 1.1383447448412578, 0.8378466765085856, 0.944368839263916, 0.9507831533749899]
ImprovedNetLite
training_accuracy -- validation_accuracy
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113]
[17.838258164852256, 22.44167962674961, 26.67185069984448, 30.746500777604975, 33.639191290824265, 36.90513219284603, 39.06687402799378, 40.824261275272164, 44.41679626749611, 46.842923794712284, 49.1601866251944, 50.5443234836703, 52.34836702954899, 54.758942457231726, 55.972006220839816, 55.48989113530327, 57.07620528771384, 58.864696734059095, 59.19129082426127, 61.10419906687403, 61.38413685847589, 62.363919129082426, 62.690513219284604, 63.62363919129083, 64.68118195956454, 64.85225505443235, 65.73872472783826, 65.95645412130638, 66.92068429237948, 67.07620528771385, 67.21617418351478, 67.52721617418351, 67.41835147744946, 68.16485225505443, 69.09797822706065, 70.03110419906687, 70.13996889580093, 68.84914463452566, 68.94245723172628, 70.4199066874028, 70.31104199066874, 70.1244167962675, 70.68429237947123, 71.0886469673406, 71.64852255054433, 71.0886469673406, 71.8040435458787, 72.78382581648522, 73.87247278382581, 72.08398133748057, 73.32814930015552, 74.69673405909798, 72.87713841368584, 74.2457231726283, 73.67029548989113, 75.03888024883359, 74.18351477449455, 73.98133748055987, 73.46811819595645, 74.88335925349922, 74.30793157076205, 76.48522550544324, 74.27682737169518, 76.11197511664075, 75.84758942457232, 75.47433903576983, 75.9253499222395, 76.37636080870918, 75.9253499222395, 76.73405909797823, 75.44323483670296, 75.84758942457232, 76.06531881804044, 77.29393468118197, 77.63608087091757, 77.12286158631416, 77.34059097978228, 77.41835147744946, 77.68273716951788, 77.57387247278382, 77.34059097978228, 77.94712286158631, 78.89580093312597, 78.22706065318818, 78.4914463452566, 77.49611197511665, 78.38258164852255, 78.33592534992223, 78.7402799377916, 79.59564541213064, 78.66251944012441, 79.11353032659409, 77.6049766718507, 79.90668740279938, 78.55365474339035, 79.09797822706065, 78.9113530326594, 79.05132192846034, 79.14463452566096, 78.88024883359253, 78.41368584758942, 79.79782270606532, 79.09797822706065, 80.7153965785381, 80.1244167962675, 80.23328149300156, 79.81337480559876, 79.53343701399689, 79.64230171073095, 80.60653188180405, 80.03110419906687, 80.32659409020218, 80.8398133748056, 80.62208398133748]
[17.428571428571427, 17.61904761904762, 28.476190476190474, 32.666666666666664, 41.142857142857146, 42.57142857142857, 45.904761904761905, 48.38095238095238, 48.76190476190476, 53.142857142857146, 52.76190476190476, 54.57142857142857, 48.95238095238095, 60.857142857142854, 62.95238095238095, 59.04761904761905, 60.095238095238095, 63.23809523809524, 61.23809523809524, 66.57142857142857, 63.23809523809524, 68.28571428571429, 59.142857142857146, 71.14285714285714, 66.28571428571429, 68.95238095238095, 64.47619047619048, 71.42857142857143, 68.66666666666667, 71.61904761904762, 70.0, 69.61904761904762, 63.523809523809526, 71.42857142857143, 61.80952380952381, 68.0952380952381, 72.38095238095238, 69.23809523809524, 70.66666666666667, 75.42857142857143, 74.66666666666667, 69.71428571428571, 72.38095238095238, 76.38095238095238, 67.23809523809524, 71.9047619047619, 73.9047619047619, 70.95238095238095, 73.61904761904762, 69.80952380952381, 75.42857142857143, 75.71428571428571, 73.80952380952381, 68.47619047619048, 69.80952380952381, 66.85714285714286, 74.66666666666667, 74.57142857142857, 75.04761904761905, 77.71428571428571, 75.71428571428571, 75.80952380952381, 73.52380952380952, 76.47619047619048, 71.71428571428571, 52.57142857142857, 67.71428571428571, 76.0952380952381, 76.57142857142857, 56.19047619047619, 73.9047619047619, 76.0952380952381, 72.95238095238095, 70.95238095238095, 78.66666666666667, 65.33333333333333, 77.23809523809524, 70.95238095238095, 74.85714285714286, 76.0952380952381, 77.80952380952381, 76.28571428571429, 78.38095238095238, 75.71428571428571, 74.0952380952381, 76.57142857142857, 73.23809523809524, 76.57142857142857, 78.0, 56.57142857142857, 76.0, 72.28571428571429, 75.80952380952381, 75.9047619047619, 74.66666666666667, 77.61904761904762, 78.57142857142857, 75.9047619047619, 78.0, 71.9047619047619, 77.80952380952381, 74.66666666666667, 76.57142857142857, 76.66666666666667, 74.95238095238095, 77.42857142857143, 70.38095238095238, 78.95238095238095, 75.9047619047619, 77.14285714285714, 72.0, 78.19047619047619, 75.33333333333333, 76.0952380952381]
model saved as model_store_384/cnn_car_ImprovedNetLite.pt
Getting predictions from test set...
ImprovedNetLite
[[108   0   0  29  10   0   3]
 [  5  91   5   0  10   4  35]
 [  9   0 121   8   3   0   9]
 [ 23   0   3 117   3   2   2]
 [  5   0   3   0 132   0  10]
 [ 17   5   7  10   9  98   4]
 [  1   1   9   0   6   1 132]]
Data loaders ready
=============================
BasicNet
=============================
Epoch: 0
Training set [0/6430 (0%)] Loss: 2.039676
Training set [3200/6430 (48%)] Loss: 2.060479
Training set [600/6430 (95%)] Loss: 2.002238
Training set: Average loss: 2.866913
Training set: Average accuracy: 17.62%
Validation set: Average loss: 1.962474, Accuracy: 150/1050 (14%)

Epoch: 1
Training set [0/6430 (0%)] Loss: 1.880059
Training set [3200/6430 (48%)] Loss: 1.865544
Training set [600/6430 (95%)] Loss: 1.864981
Training set: Average loss: 1.878678
Training set: Average accuracy: 21.57%
Validation set: Average loss: 1.864723, Accuracy: 248/1050 (24%)

Epoch: 2
Training set [0/6430 (0%)] Loss: 1.856900
Training set [3200/6430 (48%)] Loss: 1.796486
Training set [600/6430 (95%)] Loss: 1.691246
Training set: Average loss: 1.811925
Training set: Average accuracy: 25.35%
Validation set: Average loss: 1.771897, Accuracy: 350/1050 (33%)

Epoch: 3
Training set [0/6430 (0%)] Loss: 1.780426
Training set [3200/6430 (48%)] Loss: 1.825937
Training set [600/6430 (95%)] Loss: 1.510660
Training set: Average loss: 1.746803
Training set: Average accuracy: 28.97%
Validation set: Average loss: 1.707367, Accuracy: 374/1050 (36%)

Epoch: 4
Training set [0/6430 (0%)] Loss: 1.722188
Training set [3200/6430 (48%)] Loss: 1.713288
Training set [600/6430 (95%)] Loss: 1.639963
Training set: Average loss: 1.697710
Training set: Average accuracy: 31.12%
Validation set: Average loss: 1.702423, Accuracy: 363/1050 (35%)

Epoch: 5
Training set [0/6430 (0%)] Loss: 1.723849
Training set [3200/6430 (48%)] Loss: 1.680370
Training set [600/6430 (95%)] Loss: 1.721906
Training set: Average loss: 1.646574
Training set: Average accuracy: 35.33%
Validation set: Average loss: 1.582549, Accuracy: 441/1050 (42%)

Epoch: 6
Training set [0/6430 (0%)] Loss: 1.619243
Training set [3200/6430 (48%)] Loss: 1.597697
Training set [600/6430 (95%)] Loss: 1.681250
Training set: Average loss: 1.599844
Training set: Average accuracy: 36.50%
Validation set: Average loss: 1.490158, Accuracy: 516/1050 (49%)

Epoch: 7
Training set [0/6430 (0%)] Loss: 1.483495
Training set [3200/6430 (48%)] Loss: 1.543312
Training set [600/6430 (95%)] Loss: 1.530324
Training set: Average loss: 1.500036
Training set: Average accuracy: 39.94%
Validation set: Average loss: 1.490321, Accuracy: 453/1050 (43%)

Epoch: 8
Training set [0/6430 (0%)] Loss: 1.528788
Training set [3200/6430 (48%)] Loss: 1.455482
Training set [600/6430 (95%)] Loss: 1.532638
Training set: Average loss: 1.474322
Training set: Average accuracy: 41.91%
Validation set: Average loss: 1.446427, Accuracy: 466/1050 (44%)

Epoch: 9
Training set [0/6430 (0%)] Loss: 1.433513
Training set [3200/6430 (48%)] Loss: 1.492959
Training set [600/6430 (95%)] Loss: 1.453655
Training set: Average loss: 1.431720
Training set: Average accuracy: 43.22%
Validation set: Average loss: 1.346314, Accuracy: 516/1050 (49%)

Epoch: 10
Training set [0/6430 (0%)] Loss: 1.390052
Training set [3200/6430 (48%)] Loss: 1.374168
Training set [600/6430 (95%)] Loss: 1.451627
Training set: Average loss: 1.371967
Training set: Average accuracy: 45.15%
Validation set: Average loss: 1.279527, Accuracy: 545/1050 (52%)

Epoch: 11
Training set [0/6430 (0%)] Loss: 1.403537
Training set [3200/6430 (48%)] Loss: 1.324320
Training set [600/6430 (95%)] Loss: 1.447462
Training set: Average loss: 1.323913
Training set: Average accuracy: 46.98%
Validation set: Average loss: 1.246501, Accuracy: 555/1050 (53%)

Epoch: 12
Training set [0/6430 (0%)] Loss: 1.336663
Training set [3200/6430 (48%)] Loss: 1.325463
Training set [600/6430 (95%)] Loss: 1.121328
Training set: Average loss: 1.309974
Training set: Average accuracy: 47.37%
Validation set: Average loss: 1.256762, Accuracy: 587/1050 (56%)

Epoch: 13
Training set [0/6430 (0%)] Loss: 1.293090
Training set [3200/6430 (48%)] Loss: 1.331580
Training set [600/6430 (95%)] Loss: 1.063808
Training set: Average loss: 1.256441
Training set: Average accuracy: 48.66%
Validation set: Average loss: 1.260281, Accuracy: 625/1050 (60%)

Epoch: 14
Training set [0/6430 (0%)] Loss: 1.226300
Training set [3200/6430 (48%)] Loss: 1.222714
Training set [600/6430 (95%)] Loss: 1.431117
Training set: Average loss: 1.230181
Training set: Average accuracy: 50.81%
Validation set: Average loss: 1.142753, Accuracy: 570/1050 (54%)

Epoch: 15
Training set [0/6430 (0%)] Loss: 1.124780
Training set [3200/6430 (48%)] Loss: 1.229705
Training set [600/6430 (95%)] Loss: 1.221797
Training set: Average loss: 1.231546
Training set: Average accuracy: 50.78%
Validation set: Average loss: 1.107896, Accuracy: 643/1050 (61%)

Epoch: 16
Training set [0/6430 (0%)] Loss: 1.208476
Training set [3200/6430 (48%)] Loss: 1.157230
Training set [600/6430 (95%)] Loss: 1.023769
Training set: Average loss: 1.176018
Training set: Average accuracy: 52.19%
Validation set: Average loss: 1.073702, Accuracy: 656/1050 (62%)

Epoch: 17
Training set [0/6430 (0%)] Loss: 1.109062
Training set [3200/6430 (48%)] Loss: 1.102551
Training set [600/6430 (95%)] Loss: 1.109317
Training set: Average loss: 1.153702
Training set: Average accuracy: 52.99%
Validation set: Average loss: 1.071854, Accuracy: 666/1050 (63%)

Epoch: 18
Training set [0/6430 (0%)] Loss: 1.184647
Training set [3200/6430 (48%)] Loss: 1.040256
Training set [600/6430 (95%)] Loss: 1.040035
Training set: Average loss: 1.108039
Training set: Average accuracy: 55.01%
Validation set: Average loss: 1.525673, Accuracy: 518/1050 (49%)

Epoch: 19
Training set [0/6430 (0%)] Loss: 1.081268
Training set [3200/6430 (48%)] Loss: 1.057434
Training set [600/6430 (95%)] Loss: 1.301538
Training set: Average loss: 1.095529
Training set: Average accuracy: 55.32%
Validation set: Average loss: 1.039991, Accuracy: 664/1050 (63%)

Epoch: 20
Training set [0/6430 (0%)] Loss: 0.951227
Training set [3200/6430 (48%)] Loss: 1.121394
Training set [600/6430 (95%)] Loss: 1.089958
Training set: Average loss: 1.052612
Training set: Average accuracy: 56.78%
Validation set: Average loss: 1.035501, Accuracy: 654/1050 (62%)

Epoch: 21
Training set [0/6430 (0%)] Loss: 1.039844
Training set [3200/6430 (48%)] Loss: 0.997353
Training set [600/6430 (95%)] Loss: 0.868840
Training set: Average loss: 1.045666
Training set: Average accuracy: 56.16%
Validation set: Average loss: 1.096337, Accuracy: 606/1050 (58%)

Epoch: 22
Training set [0/6430 (0%)] Loss: 1.010062
Training set [3200/6430 (48%)] Loss: 1.075916
Training set [600/6430 (95%)] Loss: 0.911290
Training set: Average loss: 1.027787
Training set: Average accuracy: 57.70%
Validation set: Average loss: 1.011323, Accuracy: 659/1050 (63%)

Epoch: 23
Training set [0/6430 (0%)] Loss: 0.943603
Training set [3200/6430 (48%)] Loss: 0.939189
Training set [600/6430 (95%)] Loss: 0.989937
Training set: Average loss: 1.023351
Training set: Average accuracy: 56.81%
Validation set: Average loss: 1.030432, Accuracy: 675/1050 (64%)

Epoch: 24
Training set [0/6430 (0%)] Loss: 1.028151
Training set [3200/6430 (48%)] Loss: 1.030479
Training set [600/6430 (95%)] Loss: 0.928769
Training set: Average loss: 1.032160
Training set: Average accuracy: 57.15%
Validation set: Average loss: 0.976376, Accuracy: 691/1050 (66%)

Epoch: 25
Training set [0/6430 (0%)] Loss: 0.923394
Training set [3200/6430 (48%)] Loss: 0.962186
Training set [600/6430 (95%)] Loss: 1.219425
Training set: Average loss: 0.997277
Training set: Average accuracy: 58.18%
Validation set: Average loss: 0.913845, Accuracy: 716/1050 (68%)

Epoch: 26
Training set [0/6430 (0%)] Loss: 0.957506
Training set [3200/6430 (48%)] Loss: 0.987501
Training set [600/6430 (95%)] Loss: 1.221111
Training set: Average loss: 0.966527
Training set: Average accuracy: 59.95%
Validation set: Average loss: 0.917115, Accuracy: 697/1050 (66%)

Epoch: 27
Training set [0/6430 (0%)] Loss: 0.916939
Training set [3200/6430 (48%)] Loss: 0.972624
Training set [600/6430 (95%)] Loss: 1.095721
Training set: Average loss: 0.968706
Training set: Average accuracy: 58.97%
Validation set: Average loss: 1.035956, Accuracy: 671/1050 (64%)

Epoch: 28
Training set [0/6430 (0%)] Loss: 1.056298
Training set [3200/6430 (48%)] Loss: 0.904335
Training set [600/6430 (95%)] Loss: 0.926887
Training set: Average loss: 0.934598
Training set: Average accuracy: 60.50%
Validation set: Average loss: 0.876246, Accuracy: 730/1050 (70%)

Epoch: 29
Training set [0/6430 (0%)] Loss: 0.881590
Training set [3200/6430 (48%)] Loss: 0.927731
Training set [600/6430 (95%)] Loss: 0.740237
Training set: Average loss: 0.916839
Training set: Average accuracy: 60.64%
Validation set: Average loss: 0.902022, Accuracy: 745/1050 (71%)

Epoch: 30
Training set [0/6430 (0%)] Loss: 0.926940
Training set [3200/6430 (48%)] Loss: 0.927694
Training set [600/6430 (95%)] Loss: 0.820486
Training set: Average loss: 0.914319
Training set: Average accuracy: 60.89%
Validation set: Average loss: 0.778756, Accuracy: 741/1050 (71%)

Epoch: 31
Training set [0/6430 (0%)] Loss: 0.902967
Training set [3200/6430 (48%)] Loss: 1.018048
Training set [600/6430 (95%)] Loss: 0.715239
Training set: Average loss: 0.956705
Training set: Average accuracy: 60.25%
Validation set: Average loss: 0.850373, Accuracy: 716/1050 (68%)

Epoch: 32
Training set [0/6430 (0%)] Loss: 0.901606
Training set [3200/6430 (48%)] Loss: 0.913558
Training set [600/6430 (95%)] Loss: 0.812974
Training set: Average loss: 0.907960
Training set: Average accuracy: 61.28%
Validation set: Average loss: 0.875427, Accuracy: 753/1050 (72%)

Epoch: 33
Training set [0/6430 (0%)] Loss: 0.890721
Training set [3200/6430 (48%)] Loss: 0.809968
Training set [600/6430 (95%)] Loss: 0.937825
Training set: Average loss: 0.899510
Training set: Average accuracy: 61.80%
Validation set: Average loss: 0.793120, Accuracy: 744/1050 (71%)

Epoch: 34
Training set [0/6430 (0%)] Loss: 0.906129
Training set [3200/6430 (48%)] Loss: 0.837901
Training set [600/6430 (95%)] Loss: 0.867006
Training set: Average loss: 0.861839
Training set: Average accuracy: 62.55%
Validation set: Average loss: 0.887662, Accuracy: 739/1050 (70%)

Epoch: 35
Training set [0/6430 (0%)] Loss: 0.866543
Training set [3200/6430 (48%)] Loss: 0.917095
Training set [600/6430 (95%)] Loss: 1.022783
Training set: Average loss: 0.909044
Training set: Average accuracy: 62.22%
Validation set: Average loss: 0.848424, Accuracy: 755/1050 (72%)

Epoch: 36
Training set [0/6430 (0%)] Loss: 0.858282
Training set [3200/6430 (48%)] Loss: 0.933738
Training set [600/6430 (95%)] Loss: 1.018227
Training set: Average loss: 0.883300
Training set: Average accuracy: 63.14%
Validation set: Average loss: 0.914435, Accuracy: 711/1050 (68%)

Epoch: 37
Training set [0/6430 (0%)] Loss: 0.827374
Training set [3200/6430 (48%)] Loss: 0.849093
Training set [600/6430 (95%)] Loss: 0.767958
Training set: Average loss: 0.850357
Training set: Average accuracy: 63.59%
Validation set: Average loss: 1.015139, Accuracy: 692/1050 (66%)

Epoch: 38
Training set [0/6430 (0%)] Loss: 0.834929
Training set [3200/6430 (48%)] Loss: 0.842278
Training set [600/6430 (95%)] Loss: 0.828484
Training set: Average loss: 0.848844
Training set: Average accuracy: 62.83%
Validation set: Average loss: 0.765110, Accuracy: 799/1050 (76%)

Epoch: 39
Training set [0/6430 (0%)] Loss: 0.727700
Training set [3200/6430 (48%)] Loss: 0.847041
Training set [600/6430 (95%)] Loss: 0.739316
Training set: Average loss: 0.829291
Training set: Average accuracy: 64.63%
Validation set: Average loss: 0.859328, Accuracy: 753/1050 (72%)

Epoch: 40
Training set [0/6430 (0%)] Loss: 0.877654
Training set [3200/6430 (48%)] Loss: 0.768236
Training set [600/6430 (95%)] Loss: 0.770125
Training set: Average loss: 0.799014
Training set: Average accuracy: 65.16%
Validation set: Average loss: 0.828220, Accuracy: 765/1050 (73%)

Epoch: 41
Training set [0/6430 (0%)] Loss: 0.809042
Training set [3200/6430 (48%)] Loss: 0.752683
Training set [600/6430 (95%)] Loss: 0.995609
Training set: Average loss: 0.818036
Training set: Average accuracy: 65.26%
Validation set: Average loss: 0.876697, Accuracy: 745/1050 (71%)

Epoch: 42
Training set [0/6430 (0%)] Loss: 0.789119
Training set [3200/6430 (48%)] Loss: 0.816042
Training set [600/6430 (95%)] Loss: 0.857024
Training set: Average loss: 0.814970
Training set: Average accuracy: 64.57%
Validation set: Average loss: 0.742091, Accuracy: 792/1050 (75%)

Epoch: 43
Training set [0/6430 (0%)] Loss: 0.769175
Training set [3200/6430 (48%)] Loss: 0.828547
Training set [600/6430 (95%)] Loss: 0.741469
Training set: Average loss: 0.787695
Training set: Average accuracy: 65.68%
Validation set: Average loss: 0.772250, Accuracy: 792/1050 (75%)

Epoch: 44
Training set [0/6430 (0%)] Loss: 0.735216
Training set [3200/6430 (48%)] Loss: 0.748255
Training set [600/6430 (95%)] Loss: 0.758277
Training set: Average loss: 0.777132
Training set: Average accuracy: 66.87%
Validation set: Average loss: 1.194126, Accuracy: 655/1050 (62%)

Epoch: 45
Training set [0/6430 (0%)] Loss: 0.820498
Training set [3200/6430 (48%)] Loss: 0.787370
Training set [600/6430 (95%)] Loss: 0.645896
Training set: Average loss: 0.797533
Training set: Average accuracy: 65.13%
Validation set: Average loss: 0.774595, Accuracy: 785/1050 (75%)

Epoch: 46
Training set [0/6430 (0%)] Loss: 0.806329
Training set [3200/6430 (48%)] Loss: 0.859353
Training set [600/6430 (95%)] Loss: 0.901259
Training set: Average loss: 0.780063
Training set: Average accuracy: 65.91%
Validation set: Average loss: 0.780077, Accuracy: 755/1050 (72%)

Epoch: 47
Training set [0/6430 (0%)] Loss: 0.795677
Training set [3200/6430 (48%)] Loss: 0.836416
Training set [600/6430 (95%)] Loss: 0.971280
Training set: Average loss: 0.769098
Training set: Average accuracy: 67.43%
Validation set: Average loss: 0.783506, Accuracy: 789/1050 (75%)

Epoch: 48
Training set [0/6430 (0%)] Loss: 0.864983
Training set [3200/6430 (48%)] Loss: 0.819067
Training set [600/6430 (95%)] Loss: 0.884051
Training set: Average loss: 0.815387
Training set: Average accuracy: 65.04%
Validation set: Average loss: 0.743065, Accuracy: 779/1050 (74%)

Epoch: 49
Training set [0/6430 (0%)] Loss: 0.743456
Training set [3200/6430 (48%)] Loss: 0.775213
Training set [600/6430 (95%)] Loss: 0.899429
Training set: Average loss: 0.764861
Training set: Average accuracy: 66.49%
Validation set: Average loss: 0.704663, Accuracy: 790/1050 (75%)

Epoch: 50
Training set [0/6430 (0%)] Loss: 0.770406
Training set [3200/6430 (48%)] Loss: 0.726017
Training set [600/6430 (95%)] Loss: 0.981649
Training set: Average loss: 0.762269
Training set: Average accuracy: 66.77%
Validation set: Average loss: 0.903104, Accuracy: 776/1050 (74%)

Epoch: 51
Training set [0/6430 (0%)] Loss: 0.731692
Training set [3200/6430 (48%)] Loss: 0.700671
Training set [600/6430 (95%)] Loss: 0.761505
Training set: Average loss: 0.750714
Training set: Average accuracy: 67.64%
Validation set: Average loss: 0.703955, Accuracy: 810/1050 (77%)

Epoch: 52
Training set [0/6430 (0%)] Loss: 0.802167
Training set [3200/6430 (48%)] Loss: 0.736500
Training set [600/6430 (95%)] Loss: 0.972799
Training set: Average loss: 0.760331
Training set: Average accuracy: 67.70%
Validation set: Average loss: 1.419654, Accuracy: 620/1050 (59%)

Epoch: 53
Training set [0/6430 (0%)] Loss: 0.690492
Training set [3200/6430 (48%)] Loss: 0.680714
Training set [600/6430 (95%)] Loss: 0.910810
Training set: Average loss: 0.771991
Training set: Average accuracy: 66.77%
Validation set: Average loss: 0.784168, Accuracy: 783/1050 (75%)

Epoch: 54
Training set [0/6430 (0%)] Loss: 0.801839
Training set [3200/6430 (48%)] Loss: 0.689037
Training set [600/6430 (95%)] Loss: 0.932005
Training set: Average loss: 0.753334
Training set: Average accuracy: 67.43%
Validation set: Average loss: 0.845079, Accuracy: 798/1050 (76%)

Epoch: 55
Training set [0/6430 (0%)] Loss: 0.799287
Training set [3200/6430 (48%)] Loss: 0.744583
Training set [600/6430 (95%)] Loss: 0.817939
Training set: Average loss: 0.745694
Training set: Average accuracy: 67.31%
Validation set: Average loss: 0.657620, Accuracy: 804/1050 (77%)

Epoch: 56
Training set [0/6430 (0%)] Loss: 0.680458
Training set [3200/6430 (48%)] Loss: 0.734313
Training set [600/6430 (95%)] Loss: 0.643278
Training set: Average loss: 0.727133
Training set: Average accuracy: 67.39%
Validation set: Average loss: 0.744082, Accuracy: 790/1050 (75%)

Epoch: 57
Training set [0/6430 (0%)] Loss: 0.767566
Training set [3200/6430 (48%)] Loss: 0.690696
Training set [600/6430 (95%)] Loss: 0.545312
Training set: Average loss: 0.726365
Training set: Average accuracy: 67.79%
Validation set: Average loss: 0.785464, Accuracy: 792/1050 (75%)

Epoch: 58
Training set [0/6430 (0%)] Loss: 0.721678
Training set [3200/6430 (48%)] Loss: 0.681526
Training set [600/6430 (95%)] Loss: 0.796049
Training set: Average loss: 0.714077
Training set: Average accuracy: 69.38%
Validation set: Average loss: 0.762271, Accuracy: 792/1050 (75%)

Epoch: 59
Training set [0/6430 (0%)] Loss: 0.711035
Training set [3200/6430 (48%)] Loss: 0.799887
Training set [600/6430 (95%)] Loss: 0.721868
Training set: Average loss: 0.702732
Training set: Average accuracy: 69.80%
Validation set: Average loss: 1.025046, Accuracy: 758/1050 (72%)

Epoch: 60
Training set [0/6430 (0%)] Loss: 0.729697
Training set [3200/6430 (48%)] Loss: 0.705123
Training set [600/6430 (95%)] Loss: 0.863341
Training set: Average loss: 0.713632
Training set: Average accuracy: 68.12%
Validation set: Average loss: 0.812871, Accuracy: 782/1050 (74%)

Epoch: 61
Training set [0/6430 (0%)] Loss: 0.715677
Training set [3200/6430 (48%)] Loss: 0.735977
Training set [600/6430 (95%)] Loss: 0.503163
Training set: Average loss: 0.702283
Training set: Average accuracy: 68.86%
Validation set: Average loss: 0.729134, Accuracy: 803/1050 (76%)

Epoch: 62
Training set [0/6430 (0%)] Loss: 0.685912
Training set [3200/6430 (48%)] Loss: 0.731594
Training set [600/6430 (95%)] Loss: 0.706957
Training set: Average loss: 0.699588
Training set: Average accuracy: 70.05%
Validation set: Average loss: 0.798406, Accuracy: 788/1050 (75%)

Epoch: 63
Training set [0/6430 (0%)] Loss: 0.624138
Training set [3200/6430 (48%)] Loss: 0.666182
Training set [600/6430 (95%)] Loss: 1.124686
Training set: Average loss: 0.699448
Training set: Average accuracy: 69.14%
Validation set: Average loss: 0.689047, Accuracy: 805/1050 (77%)

Epoch: 64
Training set [0/6430 (0%)] Loss: 0.630836
Training set [3200/6430 (48%)] Loss: 0.881715
Training set [600/6430 (95%)] Loss: 0.460634
Training set: Average loss: 0.721713
Training set: Average accuracy: 68.12%
Validation set: Average loss: 0.964466, Accuracy: 747/1050 (71%)

Epoch: 65
Training set [0/6430 (0%)] Loss: 0.729585
Training set [3200/6430 (48%)] Loss: 0.723351
Training set [600/6430 (95%)] Loss: 1.067652
Training set: Average loss: 0.719240
Training set: Average accuracy: 69.95%
Validation set: Average loss: 0.799655, Accuracy: 762/1050 (73%)

Epoch: 66
Training set [0/6430 (0%)] Loss: 0.655642
Training set [3200/6430 (48%)] Loss: 0.788335
Training set [600/6430 (95%)] Loss: 0.733136
Training set: Average loss: 0.739622
Training set: Average accuracy: 67.40%
Validation set: Average loss: 0.765107, Accuracy: 792/1050 (75%)

Epoch: 67
Training set [0/6430 (0%)] Loss: 0.676723
Training set [3200/6430 (48%)] Loss: 0.760611
Training set [600/6430 (95%)] Loss: 0.805885
Training set: Average loss: 0.718992
Training set: Average accuracy: 68.38%
Validation set: Average loss: 0.749345, Accuracy: 799/1050 (76%)

Epoch: 68
Training set [0/6430 (0%)] Loss: 0.733743
Training set [3200/6430 (48%)] Loss: 0.668187
Training set [600/6430 (95%)] Loss: 0.492470
Training set: Average loss: 0.711978
Training set: Average accuracy: 68.65%
Validation set: Average loss: 0.745919, Accuracy: 795/1050 (76%)

Epoch: 69
Training set [0/6430 (0%)] Loss: 0.791577
Training set [3200/6430 (48%)] Loss: 0.653090
Training set [600/6430 (95%)] Loss: 0.851305
Training set: Average loss: 0.697566
Training set: Average accuracy: 69.52%
Validation set: Average loss: 0.970693, Accuracy: 716/1050 (68%)

Epoch: 70
Training set [0/6430 (0%)] Loss: 0.788046
Training set [3200/6430 (48%)] Loss: 0.730659
Training set [600/6430 (95%)] Loss: 1.016863
Training set: Average loss: 0.736863
Training set: Average accuracy: 69.24%
Validation set: Average loss: 0.725838, Accuracy: 778/1050 (74%)

Epoch: 71
Training set [0/6430 (0%)] Loss: 0.655868
Training set [3200/6430 (48%)] Loss: 0.674499
Training set [600/6430 (95%)] Loss: 0.640026
Training set: Average loss: 0.691867
Training set: Average accuracy: 68.99%
Validation set: Average loss: 0.840523, Accuracy: 772/1050 (74%)

Epoch: 72
Training set [0/6430 (0%)] Loss: 0.703594
Training set [3200/6430 (48%)] Loss: 0.582296
Training set [600/6430 (95%)] Loss: 0.678227
Training set: Average loss: 0.663740
Training set: Average accuracy: 69.83%
Validation set: Average loss: 0.681488, Accuracy: 813/1050 (77%)

Epoch: 73
Training set [0/6430 (0%)] Loss: 0.706314
Training set [3200/6430 (48%)] Loss: 0.666526
Training set [600/6430 (95%)] Loss: 0.796426
Training set: Average loss: 0.682248
Training set: Average accuracy: 70.09%
Validation set: Average loss: 0.959884, Accuracy: 762/1050 (73%)

Epoch: 74
Training set [0/6430 (0%)] Loss: 0.637864
Training set [3200/6430 (48%)] Loss: 0.682315
Training set [600/6430 (95%)] Loss: 0.771985
Training set: Average loss: 0.663208
Training set: Average accuracy: 71.14%
Validation set: Average loss: 0.741295, Accuracy: 806/1050 (77%)

Epoch: 75
Training set [0/6430 (0%)] Loss: 0.621004
Training set [3200/6430 (48%)] Loss: 0.771522
Training set [600/6430 (95%)] Loss: 0.937655
Training set: Average loss: 0.706621
Training set: Average accuracy: 69.97%
Validation set: Average loss: 0.783047, Accuracy: 782/1050 (74%)

Epoch: 76
Training set [0/6430 (0%)] Loss: 0.665228
Training set [3200/6430 (48%)] Loss: 0.792436
Training set [600/6430 (95%)] Loss: 0.850636
Training set: Average loss: 0.756268
Training set: Average accuracy: 67.71%
Validation set: Average loss: 0.738011, Accuracy: 810/1050 (77%)

Epoch: 77
Training set [0/6430 (0%)] Loss: 0.654352
Training set [3200/6430 (48%)] Loss: 0.705440
Training set [600/6430 (95%)] Loss: 0.471030
Training set: Average loss: 0.652011
Training set: Average accuracy: 70.31%
Validation set: Average loss: 0.830265, Accuracy: 782/1050 (74%)

Epoch: 78
Training set [0/6430 (0%)] Loss: 0.573833
Training set [3200/6430 (48%)] Loss: 0.623527
Training set [600/6430 (95%)] Loss: 0.626391
Training set: Average loss: 0.661153
Training set: Average accuracy: 70.64%
Validation set: Average loss: 0.792631, Accuracy: 788/1050 (75%)

Epoch: 79
Training set [0/6430 (0%)] Loss: 0.627699
Training set [3200/6430 (48%)] Loss: 0.643873
Training set [600/6430 (95%)] Loss: 0.561768
Training set: Average loss: 0.635824
Training set: Average accuracy: 71.63%
Validation set: Average loss: 0.710101, Accuracy: 815/1050 (78%)

Epoch: 80
Training set [0/6430 (0%)] Loss: 0.581370
Training set [3200/6430 (48%)] Loss: 0.620592
Training set [600/6430 (95%)] Loss: 0.693599
Training set: Average loss: 0.654949
Training set: Average accuracy: 71.46%
Validation set: Average loss: 0.892715, Accuracy: 745/1050 (71%)

Epoch: 81
Training set [0/6430 (0%)] Loss: 0.665652
Training set [3200/6430 (48%)] Loss: 0.594496
Training set [600/6430 (95%)] Loss: 0.475226
Training set: Average loss: 0.635221
Training set: Average accuracy: 72.32%
Validation set: Average loss: 1.091324, Accuracy: 719/1050 (68%)

Epoch: 82
Training set [0/6430 (0%)] Loss: 0.668226
Training set [3200/6430 (48%)] Loss: 0.591033
Training set [600/6430 (95%)] Loss: 0.690975
Training set: Average loss: 0.633820
Training set: Average accuracy: 72.02%
Validation set: Average loss: 0.697286, Accuracy: 830/1050 (79%)

Epoch: 83
Training set [0/6430 (0%)] Loss: 0.683000
Training set [3200/6430 (48%)] Loss: 0.589307
Training set [600/6430 (95%)] Loss: 0.404947
Training set: Average loss: 0.656915
Training set: Average accuracy: 69.94%
Validation set: Average loss: 0.787000, Accuracy: 796/1050 (76%)

Epoch: 84
Training set [0/6430 (0%)] Loss: 0.539968
Training set [3200/6430 (48%)] Loss: 0.678299
Training set [600/6430 (95%)] Loss: 0.821640
Training set: Average loss: 0.633539
Training set: Average accuracy: 72.19%
Validation set: Average loss: 0.749946, Accuracy: 802/1050 (76%)

Epoch: 85
Training set [0/6430 (0%)] Loss: 0.667296
Training set [3200/6430 (48%)] Loss: 0.627261
Training set [600/6430 (95%)] Loss: 0.476158
Training set: Average loss: 0.636212
Training set: Average accuracy: 71.28%
Validation set: Average loss: 0.614639, Accuracy: 825/1050 (79%)

Epoch: 86
Training set [0/6430 (0%)] Loss: 0.576236
Training set [3200/6430 (48%)] Loss: 0.640665
Training set [600/6430 (95%)] Loss: 0.862620
Training set: Average loss: 0.630621
Training set: Average accuracy: 72.49%
Validation set: Average loss: 0.722003, Accuracy: 808/1050 (77%)

Epoch: 87
Training set [0/6430 (0%)] Loss: 0.583719
Training set [3200/6430 (48%)] Loss: 0.571893
Training set [600/6430 (95%)] Loss: 0.609690
Training set: Average loss: 0.606270
Training set: Average accuracy: 73.36%
Validation set: Average loss: 0.852572, Accuracy: 772/1050 (74%)

Epoch: 88
Training set [0/6430 (0%)] Loss: 0.599063
Training set [3200/6430 (48%)] Loss: 0.632465
Training set [600/6430 (95%)] Loss: 0.979489
Training set: Average loss: 0.638497
Training set: Average accuracy: 72.47%
Validation set: Average loss: 0.648972, Accuracy: 838/1050 (80%)

Epoch: 89
Training set [0/6430 (0%)] Loss: 0.540029
Training set [3200/6430 (48%)] Loss: 0.585129
Training set [600/6430 (95%)] Loss: 0.765371
Training set: Average loss: 0.631896
Training set: Average accuracy: 72.43%
Validation set: Average loss: 0.799246, Accuracy: 809/1050 (77%)

Epoch: 90
Training set [0/6430 (0%)] Loss: 0.652673
Training set [3200/6430 (48%)] Loss: 0.639110
Training set [600/6430 (95%)] Loss: 0.671871
Training set: Average loss: 0.614861
Training set: Average accuracy: 73.27%
Validation set: Average loss: 0.860253, Accuracy: 815/1050 (78%)

Epoch: 91
Training set [0/6430 (0%)] Loss: 0.590748
Training set [3200/6430 (48%)] Loss: 0.592536
Training set [600/6430 (95%)] Loss: 0.523250
Training set: Average loss: 0.608591
Training set: Average accuracy: 72.69%
Validation set: Average loss: 0.849209, Accuracy: 781/1050 (74%)

Epoch: 92
Training set [0/6430 (0%)] Loss: 0.741309
Training set [3200/6430 (48%)] Loss: 0.612369
Training set [600/6430 (95%)] Loss: 0.823643
Training set: Average loss: 0.624447
Training set: Average accuracy: 72.61%
Validation set: Average loss: 0.903148, Accuracy: 793/1050 (76%)

Epoch: 93
Training set [0/6430 (0%)] Loss: 0.665352
Training set [3200/6430 (48%)] Loss: 0.560118
Training set [600/6430 (95%)] Loss: 0.447134
Training set: Average loss: 0.623763
Training set: Average accuracy: 71.98%
Validation set: Average loss: 0.778188, Accuracy: 796/1050 (76%)

Epoch: 94
Training set [0/6430 (0%)] Loss: 0.633212
Training set [3200/6430 (48%)] Loss: 0.646069
Training set [600/6430 (95%)] Loss: 0.734843
Training set: Average loss: 0.636610
Training set: Average accuracy: 71.37%
Validation set: Average loss: 0.715509, Accuracy: 830/1050 (79%)

Epoch: 95
Training set [0/6430 (0%)] Loss: 0.659288
Training set [3200/6430 (48%)] Loss: 0.599601
Training set [600/6430 (95%)] Loss: 0.720080
Training set: Average loss: 0.629596
Training set: Average accuracy: 72.80%
Validation set: Average loss: 0.854927, Accuracy: 798/1050 (76%)

Epoch: 96
Training set [0/6430 (0%)] Loss: 0.580664
Training set [3200/6430 (48%)] Loss: 0.745202
Training set [600/6430 (95%)] Loss: 0.461737
Training set: Average loss: 0.619164
Training set: Average accuracy: 72.61%
Validation set: Average loss: 0.680453, Accuracy: 809/1050 (77%)

Epoch: 97
Training set [0/6430 (0%)] Loss: 0.592032
Training set [3200/6430 (48%)] Loss: 0.568669
Training set [600/6430 (95%)] Loss: 0.595553
Training set: Average loss: 0.605067
Training set: Average accuracy: 72.55%
Validation set: Average loss: 0.624588, Accuracy: 847/1050 (81%)

Epoch: 98
Training set [0/6430 (0%)] Loss: 0.537427
Training set [3200/6430 (48%)] Loss: 0.605579
Training set [600/6430 (95%)] Loss: 0.589791
Training set: Average loss: 0.582795
Training set: Average accuracy: 74.23%
Validation set: Average loss: 0.665684, Accuracy: 838/1050 (80%)

Epoch: 99
Training set [0/6430 (0%)] Loss: 0.628900
Training set [3200/6430 (48%)] Loss: 0.543994
Training set [600/6430 (95%)] Loss: 0.497654
Training set: Average loss: 0.582439
Training set: Average accuracy: 74.25%
Validation set: Average loss: 0.704221, Accuracy: 830/1050 (79%)

Epoch: 100
Training set [0/6430 (0%)] Loss: 0.594831
Training set [3200/6430 (48%)] Loss: 0.519158
Training set [600/6430 (95%)] Loss: 0.751043
Training set: Average loss: 0.594415
Training set: Average accuracy: 73.92%
Validation set: Average loss: 0.759036, Accuracy: 797/1050 (76%)

Epoch: 101
Training set [0/6430 (0%)] Loss: 0.581316
Training set [3200/6430 (48%)] Loss: 0.691918
Training set [600/6430 (95%)] Loss: 1.087275
Training set: Average loss: 0.633501
Training set: Average accuracy: 73.41%
Validation set: Average loss: 0.764728, Accuracy: 796/1050 (76%)

Epoch: 102
Training set [0/6430 (0%)] Loss: 0.599171
Training set [3200/6430 (48%)] Loss: 0.609506
Training set [600/6430 (95%)] Loss: 1.161869
Training set: Average loss: 0.661235
Training set: Average accuracy: 72.27%
Validation set: Average loss: 0.668362, Accuracy: 813/1050 (77%)

Epoch: 103
Training set [0/6430 (0%)] Loss: 0.599496
Training set [3200/6430 (48%)] Loss: 0.594231
Training set [600/6430 (95%)] Loss: 0.723927
Training set: Average loss: 0.618640
Training set: Average accuracy: 72.92%
Validation set: Average loss: 0.875034, Accuracy: 802/1050 (76%)

Epoch: 104
Training set [0/6430 (0%)] Loss: 0.615727
Training set [3200/6430 (48%)] Loss: 0.694476
Training set [600/6430 (95%)] Loss: 0.474364
Training set: Average loss: 0.625612
Training set: Average accuracy: 72.64%
Validation set: Average loss: 0.756877, Accuracy: 827/1050 (79%)

Epoch: 105
Training set [0/6430 (0%)] Loss: 0.639033
Training set [3200/6430 (48%)] Loss: 0.628472
Training set [600/6430 (95%)] Loss: 0.322797
Training set: Average loss: 0.603362
Training set: Average accuracy: 72.69%
Validation set: Average loss: 0.664701, Accuracy: 844/1050 (80%)

Epoch: 106
Training set [0/6430 (0%)] Loss: 0.571239
Training set [3200/6430 (48%)] Loss: 0.530135
Training set [600/6430 (95%)] Loss: 0.370648
Training set: Average loss: 0.586680
Training set: Average accuracy: 73.14%
Validation set: Average loss: 0.596924, Accuracy: 860/1050 (82%)

Epoch: 107
Training set [0/6430 (0%)] Loss: 0.491979
Training set [3200/6430 (48%)] Loss: 0.601270
Training set [600/6430 (95%)] Loss: 0.599620
Training set: Average loss: 0.571531
Training set: Average accuracy: 74.26%
Validation set: Average loss: 0.644787, Accuracy: 820/1050 (78%)

Epoch: 108
Training set [0/6430 (0%)] Loss: 0.615808
Training set [3200/6430 (48%)] Loss: 0.529235
Training set [600/6430 (95%)] Loss: 0.395481
Training set: Average loss: 0.560340
Training set: Average accuracy: 74.93%
Validation set: Average loss: 0.662006, Accuracy: 863/1050 (82%)

Epoch: 109
Training set [0/6430 (0%)] Loss: 0.586572
Training set [3200/6430 (48%)] Loss: 0.547202
Training set [600/6430 (95%)] Loss: 0.534599
Training set: Average loss: 0.592260
Training set: Average accuracy: 73.81%
Validation set: Average loss: 0.822963, Accuracy: 793/1050 (76%)

Epoch: 110
Training set [0/6430 (0%)] Loss: 0.560995
Training set [3200/6430 (48%)] Loss: 0.624119
Training set [600/6430 (95%)] Loss: 0.519267
Training set: Average loss: 0.590577
Training set: Average accuracy: 73.86%
Validation set: Average loss: 0.664347, Accuracy: 835/1050 (80%)

Epoch: 111
Training set [0/6430 (0%)] Loss: 0.597897
Training set [3200/6430 (48%)] Loss: 0.538977
Training set [600/6430 (95%)] Loss: 0.841395
Training set: Average loss: 0.590057
Training set: Average accuracy: 74.21%
Validation set: Average loss: 0.599995, Accuracy: 843/1050 (80%)

Epoch: 112
Training set [0/6430 (0%)] Loss: 0.614304
Training set [3200/6430 (48%)] Loss: 0.588577
Training set [600/6430 (95%)] Loss: 0.404621
Training set: Average loss: 0.612029
Training set: Average accuracy: 73.16%
Validation set: Average loss: 0.600675, Accuracy: 848/1050 (81%)

Epoch: 113
Training set [0/6430 (0%)] Loss: 0.541663
Training set [3200/6430 (48%)] Loss: 0.565582
Training set [600/6430 (95%)] Loss: 0.597969
Training set: Average loss: 0.570456
Training set: Average accuracy: 74.57%
Validation set: Average loss: 0.650474, Accuracy: 845/1050 (80%)

Epoch: 114
Training set [0/6430 (0%)] Loss: 0.573747
Training set [3200/6430 (48%)] Loss: 0.521343
Training set [600/6430 (95%)] Loss: 0.436930
Training set: Average loss: 0.567955
Training set: Average accuracy: 75.10%
Validation set: Average loss: 0.749217, Accuracy: 836/1050 (80%)

Epoch: 115
Training set [0/6430 (0%)] Loss: 0.534235
Training set [3200/6430 (48%)] Loss: 0.584335
Training set [600/6430 (95%)] Loss: 0.522422
Training set: Average loss: 0.559469
Training set: Average accuracy: 74.20%
Validation set: Average loss: 0.665866, Accuracy: 860/1050 (82%)

Epoch: 116
Training set [0/6430 (0%)] Loss: 0.579829
Training set [3200/6430 (48%)] Loss: 0.581843
Training set [600/6430 (95%)] Loss: 0.843848
Training set: Average loss: 0.562124
Training set: Average accuracy: 75.32%
Validation set: Average loss: 0.921339, Accuracy: 800/1050 (76%)

Epoch: 117
Training set [0/6430 (0%)] Loss: 0.568843
Training set [3200/6430 (48%)] Loss: 0.598285
Training set [600/6430 (95%)] Loss: 0.591726
Training set: Average loss: 0.582988
Training set: Average accuracy: 74.63%
Validation set: Average loss: 0.773217, Accuracy: 829/1050 (79%)

Epoch: 118
Training set [0/6430 (0%)] Loss: 0.543979
Training set [3200/6430 (48%)] Loss: 0.497681
Training set [600/6430 (95%)] Loss: 0.524237
Training set: Average loss: 0.563429
Training set: Average accuracy: 74.49%
Validation set: Average loss: 0.697082, Accuracy: 843/1050 (80%)

Epoch: 119
Training set [0/6430 (0%)] Loss: 0.538199
Training set [3200/6430 (48%)] Loss: 0.608324
Training set [600/6430 (95%)] Loss: 0.395635
Training set: Average loss: 0.582383
Training set: Average accuracy: 73.98%
Validation set: Average loss: 0.683535, Accuracy: 835/1050 (80%)

Epoch: 120
Training set [0/6430 (0%)] Loss: 0.537499
Training set [3200/6430 (48%)] Loss: 0.600452
Training set [600/6430 (95%)] Loss: 0.488431
Training set: Average loss: 0.566113
Training set: Average accuracy: 75.24%
Validation set: Average loss: 0.768955, Accuracy: 798/1050 (76%)

Epoch: 121
Training set [0/6430 (0%)] Loss: 0.673736
Training set [3200/6430 (48%)] Loss: 0.563616
Training set [600/6430 (95%)] Loss: 0.590768
Training set: Average loss: 0.564540
Training set: Average accuracy: 74.62%
Validation set: Average loss: 0.901495, Accuracy: 806/1050 (77%)

Epoch: 122
Training set [0/6430 (0%)] Loss: 0.571316
Training set [3200/6430 (48%)] Loss: 0.549630
Training set [600/6430 (95%)] Loss: 0.517390
Training set: Average loss: 0.564051
Training set: Average accuracy: 74.82%
Validation set: Average loss: 1.016610, Accuracy: 804/1050 (77%)

Epoch: 123
Training set [0/6430 (0%)] Loss: 0.520322
Training set [3200/6430 (48%)] Loss: 0.613489
Training set [600/6430 (95%)] Loss: 0.487321
Training set: Average loss: 0.561179
Training set: Average accuracy: 75.29%
Validation set: Average loss: 0.656085, Accuracy: 834/1050 (79%)

Epoch: 124
Training set [0/6430 (0%)] Loss: 0.534774
Training set [3200/6430 (48%)] Loss: 0.601526
Training set [600/6430 (95%)] Loss: 0.686721
Training set: Average loss: 0.567003
Training set: Average accuracy: 74.51%
Validation set: Average loss: 1.024626, Accuracy: 764/1050 (73%)

Epoch: 125
Training set [0/6430 (0%)] Loss: 0.592969
Training set [3200/6430 (48%)] Loss: 0.489938
Training set [600/6430 (95%)] Loss: 0.602176
Training set: Average loss: 0.551105
Training set: Average accuracy: 75.30%
Validation set: Average loss: 0.693362, Accuracy: 828/1050 (79%)

Epoch: 126
Training set [0/6430 (0%)] Loss: 0.504993
Training set [3200/6430 (48%)] Loss: 0.544770
Training set [600/6430 (95%)] Loss: 0.482085
Training set: Average loss: 0.546428
Training set: Average accuracy: 75.21%
Validation set: Average loss: 0.618600, Accuracy: 849/1050 (81%)

Epoch: 127
Training set [0/6430 (0%)] Loss: 0.564231
Training set [3200/6430 (48%)] Loss: 0.525057
Training set [600/6430 (95%)] Loss: 0.527504
Training set: Average loss: 0.529861
Training set: Average accuracy: 76.41%
Validation set: Average loss: 0.689265, Accuracy: 833/1050 (79%)

Epoch: 128
Training set [0/6430 (0%)] Loss: 0.483627
Training set [3200/6430 (48%)] Loss: 0.523390
Training set [600/6430 (95%)] Loss: 0.329052
Training set: Average loss: 0.525215
Training set: Average accuracy: 75.86%
Validation set: Average loss: 0.755298, Accuracy: 826/1050 (79%)

Epoch: 129
Training set [0/6430 (0%)] Loss: 0.477863
Training set [3200/6430 (48%)] Loss: 0.562647
Training set [600/6430 (95%)] Loss: 0.627576
Training set: Average loss: 0.549792
Training set: Average accuracy: 75.97%
Validation set: Average loss: 0.694945, Accuracy: 840/1050 (80%)

Epoch: 130
Training set [0/6430 (0%)] Loss: 0.510919
Training set [3200/6430 (48%)] Loss: 0.619677
Training set [600/6430 (95%)] Loss: 0.427887
Training set: Average loss: 0.543005
Training set: Average accuracy: 75.52%
Validation set: Average loss: 0.721386, Accuracy: 824/1050 (78%)

Epoch: 131
Training set [0/6430 (0%)] Loss: 0.532969
Training set [3200/6430 (48%)] Loss: 0.604366
Training set [600/6430 (95%)] Loss: 0.725162
Training set: Average loss: 0.542245
Training set: Average accuracy: 76.19%
Validation set: Average loss: 0.665584, Accuracy: 854/1050 (81%)

Epoch: 132
Training set [0/6430 (0%)] Loss: 0.530874
Training set [3200/6430 (48%)] Loss: 0.543487
Training set [600/6430 (95%)] Loss: 0.408514
Training set: Average loss: 0.539502
Training set: Average accuracy: 76.10%
Validation set: Average loss: 0.711796, Accuracy: 848/1050 (81%)

Epoch: 133
Training set [0/6430 (0%)] Loss: 0.623479
Training set [3200/6430 (48%)] Loss: 0.566066
Training set [600/6430 (95%)] Loss: 0.441831
Training set: Average loss: 0.547992
Training set: Average accuracy: 75.38%
Validation set: Average loss: 0.858323, Accuracy: 799/1050 (76%)

Epoch: 134
Training set [0/6430 (0%)] Loss: 0.483212
Training set [3200/6430 (48%)] Loss: 0.496560
Training set [600/6430 (95%)] Loss: 0.400280
Training set: Average loss: 0.518204
Training set: Average accuracy: 75.97%
Validation set: Average loss: 0.746775, Accuracy: 846/1050 (81%)

Epoch: 135
Training set [0/6430 (0%)] Loss: 0.459280
Training set [3200/6430 (48%)] Loss: 0.440768
Training set [600/6430 (95%)] Loss: 0.629254
Training set: Average loss: 0.522117
Training set: Average accuracy: 77.06%
Validation set: Average loss: 0.792032, Accuracy: 796/1050 (76%)

Epoch: 136
Training set [0/6430 (0%)] Loss: 0.529986
Training set [3200/6430 (48%)] Loss: 0.553089
Training set [600/6430 (95%)] Loss: 0.563969
Training set: Average loss: 0.526146
Training set: Average accuracy: 76.50%
Validation set: Average loss: 0.708384, Accuracy: 841/1050 (80%)

Epoch: 137
Training set [0/6430 (0%)] Loss: 0.579762
Training set [3200/6430 (48%)] Loss: 0.575267
Training set [600/6430 (95%)] Loss: 0.411042
Training set: Average loss: 0.531764
Training set: Average accuracy: 75.33%
Validation set: Average loss: 0.672755, Accuracy: 851/1050 (81%)

Epoch: 138
Training set [0/6430 (0%)] Loss: 0.478407
Training set [3200/6430 (48%)] Loss: 0.481066
Training set [600/6430 (95%)] Loss: 0.321491
Training set: Average loss: 0.505940
Training set: Average accuracy: 76.69%
Validation set: Average loss: 0.668806, Accuracy: 869/1050 (83%)

Epoch: 139
Training set [0/6430 (0%)] Loss: 0.436177
Training set [3200/6430 (48%)] Loss: 0.488601
Training set [600/6430 (95%)] Loss: 0.651453
Training set: Average loss: 0.512088
Training set: Average accuracy: 76.63%
Validation set: Average loss: 0.642369, Accuracy: 857/1050 (82%)

Epoch: 140
Training set [0/6430 (0%)] Loss: 0.582064
Training set [3200/6430 (48%)] Loss: 0.606222
Training set [600/6430 (95%)] Loss: 0.490563
Training set: Average loss: 0.535416
Training set: Average accuracy: 76.10%
Validation set: Average loss: 0.752440, Accuracy: 838/1050 (80%)

Epoch: 141
Training set [0/6430 (0%)] Loss: 0.470025
Training set [3200/6430 (48%)] Loss: 0.541180
Training set [600/6430 (95%)] Loss: 0.532204
Training set: Average loss: 0.503354
Training set: Average accuracy: 78.16%
Validation set: Average loss: 0.804270, Accuracy: 812/1050 (77%)

Epoch: 142
Training set [0/6430 (0%)] Loss: 0.542649
Training set [3200/6430 (48%)] Loss: 0.530854
Training set [600/6430 (95%)] Loss: 0.528483
Training set: Average loss: 0.538562
Training set: Average accuracy: 75.27%
Validation set: Average loss: 0.731923, Accuracy: 837/1050 (80%)

Epoch: 143
Training set [0/6430 (0%)] Loss: 0.481518
Training set [3200/6430 (48%)] Loss: 0.571484
Training set [600/6430 (95%)] Loss: 0.466406
Training set: Average loss: 0.532996
Training set: Average accuracy: 76.08%
Validation set: Average loss: 0.863418, Accuracy: 800/1050 (76%)

Epoch: 144
Training set [0/6430 (0%)] Loss: 0.512166
Training set [3200/6430 (48%)] Loss: 0.588780
Training set [600/6430 (95%)] Loss: 0.665460
Training set: Average loss: 0.553696
Training set: Average accuracy: 76.47%
Validation set: Average loss: 1.106974, Accuracy: 754/1050 (72%)

Epoch: 145
Training set [0/6430 (0%)] Loss: 0.550666
Training set [3200/6430 (48%)] Loss: 0.548843
Training set [600/6430 (95%)] Loss: 0.548588
Training set: Average loss: 0.580570
Training set: Average accuracy: 74.98%
Validation set: Average loss: 0.637093, Accuracy: 841/1050 (80%)

Epoch: 146
Training set [0/6430 (0%)] Loss: 0.512456
Training set [3200/6430 (48%)] Loss: 0.591699
Training set [600/6430 (95%)] Loss: 0.439336
Training set: Average loss: 0.532205
Training set: Average accuracy: 75.49%
Validation set: Average loss: 0.696865, Accuracy: 849/1050 (81%)

Epoch: 147
Training set [0/6430 (0%)] Loss: 0.503459
Training set [3200/6430 (48%)] Loss: 0.518632
Training set [600/6430 (95%)] Loss: 0.621170
Training set: Average loss: 0.517088
Training set: Average accuracy: 76.97%
Validation set: Average loss: 0.636287, Accuracy: 855/1050 (81%)

Epoch: 148
Training set [0/6430 (0%)] Loss: 0.550240
Training set [3200/6430 (48%)] Loss: 0.506332
Training set [600/6430 (95%)] Loss: 0.550030
Training set: Average loss: 0.499088
Training set: Average accuracy: 77.51%
Validation set: Average loss: 0.674914, Accuracy: 862/1050 (82%)

Epoch: 149
Training set [0/6430 (0%)] Loss: 0.515003
Training set [3200/6430 (48%)] Loss: 0.551419
Training set [600/6430 (95%)] Loss: 0.670971
Training set: Average loss: 0.547723
Training set: Average accuracy: 75.91%
Validation set: Average loss: 0.750421, Accuracy: 822/1050 (78%)

BasicNet
training_loss -- validation_loss
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]
[2.866913006419227, 1.8786783615748088, 1.811924832207816, 1.7468025059927077, 1.6977098555791945, 1.6465739522661482, 1.5998443875994002, 1.5000363872164773, 1.4743219557262601, 1.431720222745623, 1.37196717943464, 1.3239128305798484, 1.3099735180536907, 1.256441042536781, 1.2301809106554304, 1.23154574348813, 1.176017925852821, 1.153702247710455, 1.1080389249892462, 1.095528903461638, 1.0526123217173986, 1.0456663171450298, 1.0277869020189558, 1.0233512634322757, 1.032159915992192, 0.9972766666185289, 0.9665266332172212, 0.9687062870888483, 0.934597685223534, 0.9168392930712018, 0.9143185870988029, 0.9567050933837891, 0.9079599806240627, 0.8995102785882496, 0.8618390702065968, 0.9090440131369091, 0.883299932593391, 0.8503570443107968, 0.8488441450255257, 0.8292906539780753, 0.7990139495758783, 0.8180364256813413, 0.8149704734484354, 0.7876945024444943, 0.7771319888886952, 0.7975334184510368, 0.7800629990441459, 0.7690982676687694, 0.8153871666817438, 0.7648614048957825, 0.7622688072068351, 0.7507140551294599, 0.760330889906202, 0.7719906880742028, 0.753333758740198, 0.7456937602588108, 0.7271328625224885, 0.7263652228173756, 0.7140765615871975, 0.7027320577984765, 0.7136322543734596, 0.7022826841899327, 0.6995876488231477, 0.6994484634626479, 0.7217125381742205, 0.7192403674125671, 0.7396215711321149, 0.7189924858865284, 0.711977862176441, 0.6975662481217157, 0.7368631476447696, 0.6918668264434451, 0.663739610285986, 0.6822476642472404, 0.663208354087103, 0.7066206705002558, 0.7562675163859413, 0.6520105571973891, 0.6611525331224714, 0.635824271610805, 0.6549487397784278, 0.6352212301322392, 0.6338195233117967, 0.6569145307654426, 0.6335389500572568, 0.636212075040454, 0.6306209081695193, 0.6062702309517634, 0.6384970659301394, 0.6318963822864351, 0.6148611221994672, 0.6085911194483439, 0.6244474904877799, 0.6237630517709822, 0.6366100084213984, 0.6295955692018781, 0.6191643291995639, 0.6050666769345602, 0.582795378707704, 0.5824387868245443, 0.5944147819564456, 0.6335010954311916, 0.6612353239740644, 0.6186395372663226, 0.6256124646890731, 0.6033622778597332, 0.5866803257238298, 0.5715313965366, 0.5603398254939488, 0.5922603266579765, 0.5905773980276925, 0.5900570707661765, 0.6120294956933885, 0.5704558335599446, 0.5679545147078378, 0.5594691549028669, 0.5621240635712942, 0.5829882933979943, 0.5634289653528304, 0.5823828876018524, 0.5661125594661349, 0.5645398100217184, 0.5640511768204826, 0.5611786104383922, 0.5670029364881062, 0.5511051558312916, 0.5464277764161428, 0.5298612188725245, 0.5252148878006708, 0.5497915389991942, 0.543005496263504, 0.5422447252841223, 0.5395017422380901, 0.5479921499888102, 0.5182040887219566, 0.5221174969559624, 0.5261459464118594, 0.531763915504728, 0.5059404642809004, 0.5120876757871538, 0.5354158097789401, 0.5033543407917023, 0.5385615130265554, 0.5329955064115071, 0.5536961796737853, 0.5805704253060477, 0.5322049075648898, 0.5170880627064478, 0.4990884023053305, 0.5477231400353568]
[1.9624738991260529, 1.864722579717636, 1.7718968987464905, 1.707366794347763, 1.702422946691513, 1.5825490355491638, 1.4901583194732666, 1.490320861339569, 1.4464271664619446, 1.3463135957717896, 1.2795272171497345, 1.2465009093284607, 1.2567619383335114, 1.2602814435958862, 1.1427530348300934, 1.107895627617836, 1.073701649904251, 1.0718541741371155, 1.5256726145744324, 1.0399911850690842, 1.0355011820793152, 1.096336767077446, 1.0113228559494019, 1.0304317027330399, 0.9763764888048172, 0.9138449728488922, 0.9171151369810104, 1.035956248641014, 0.8762463182210922, 0.9020224511623383, 0.7787563055753708, 0.8503728657960892, 0.8754266649484634, 0.7931201010942459, 0.8876623213291168, 0.8484235405921936, 0.9144349247217178, 1.0151391997933388, 0.7651101350784302, 0.859328418970108, 0.8282200768589973, 0.8766969442367554, 0.7420907318592072, 0.7722502946853638, 1.1941260397434235, 0.7745951116085052, 0.7800770625472069, 0.7835060209035873, 0.7430647537112236, 0.7046629041433334, 0.9031043499708176, 0.7039548009634018, 1.4196536540985107, 0.7841680645942688, 0.8450791537761688, 0.657619796693325, 0.7440822646021843, 0.7854644358158112, 0.7622713297605515, 1.0250460058450699, 0.8128707110881805, 0.7291342318058014, 0.7984062135219574, 0.6890474110841751, 0.9644659608602524, 0.7996554374694824, 0.7651065140962601, 0.7493450790643692, 0.7459191679954529, 0.9706929549574852, 0.7258383929729462, 0.8405233025550842, 0.681487612426281, 0.9598835706710815, 0.7412946224212646, 0.7830465063452721, 0.7380112856626511, 0.8302646726369858, 0.7926312386989594, 0.7101012319326401, 0.8927153125405312, 1.0913239866495132, 0.6972855627536774, 0.7870004773139954, 0.7499463781714439, 0.6146391406655312, 0.722003236413002, 0.8525723963975906, 0.6489720866084099, 0.7992458641529083, 0.8602527678012848, 0.8492087423801422, 0.9031481593847275, 0.7781884372234344, 0.7155091166496277, 0.8549274057149887, 0.6804526373744011, 0.6245879009366035, 0.6656842157244682, 0.7042214125394821, 0.7590364441275597, 0.7647277191281319, 0.6683615520596504, 0.8750335425138474, 0.7568767219781876, 0.6647007018327713, 0.5969242453575134, 0.6447866037487984, 0.6620062738656998, 0.8229631260037422, 0.6643471568822861, 0.599994532763958, 0.6006750613451004, 0.6504737138748169, 0.7492171972990036, 0.6658660843968391, 0.9213387966156006, 0.7732167616486549, 0.6970821171998978, 0.6835352778434753, 0.7689552083611488, 0.901494637131691, 1.0166102647781372, 0.656085304915905, 1.0246257558465004, 0.693361721932888, 0.6186002567410469, 0.6892645470798016, 0.7552976831793785, 0.6949448883533478, 0.7213861793279648, 0.6655841022729874, 0.7117958664894104, 0.8583226501941681, 0.7467752248048782, 0.7920322641730309, 0.7083839476108551, 0.6727550402283669, 0.6688063740730286, 0.6423692032694817, 0.7524404004216194, 0.8042703792452812, 0.7319230139255524, 0.8634184971451759, 1.1069738417863846, 0.6370934695005417, 0.6968653574585915, 0.6362873688340187, 0.6749144122004509, 0.7504206746816635]
BasicNet
training_accuracy -- validation_accuracy
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]
[17.620528771384137, 21.57076205287714, 25.349922239502334, 28.973561430793158, 31.119751166407465, 35.3343701399689, 36.50077760497667, 39.93779160186625, 41.91290824261275, 43.219284603421464, 45.14774494556765, 46.98289269051322, 47.371695178849144, 48.66251944012442, 50.80870917573873, 50.77760497667185, 52.19284603421462, 52.98600311041991, 55.00777604976672, 55.31881804043546, 56.780715396578536, 56.15863141524106, 57.69828926905132, 56.81181959564541, 57.153965785381025, 58.18040435458787, 59.95334370139969, 58.973561430793154, 60.497667185069986, 60.63763608087092, 60.88646967340591, 60.24883359253499, 61.27527216174183, 61.80404354587869, 62.55054432348367, 62.22395023328149, 63.14152410575428, 63.59253499222395, 62.83048211508554, 64.63452566096423, 65.16329704510109, 65.25660964230171, 64.57231726283048, 65.67651632970451, 66.87402799377917, 65.13219284603421, 65.90979782270607, 67.4339035769829, 65.03888024883359, 66.48522550544324, 66.7651632970451, 67.63608087091757, 67.69828926905132, 66.7651632970451, 67.4339035769829, 67.3094867807154, 67.38724727838259, 67.79160186625194, 69.37791601866252, 69.79782270606532, 68.11819595645412, 68.8646967340591, 70.04665629860031, 69.14463452566096, 68.11819595645412, 69.95334370139969, 67.40279937791603, 68.38258164852255, 68.64696734059098, 69.51788491446345, 69.23794712286158, 68.98911353032659, 69.82892690513219, 70.09331259720062, 71.1353032659409, 69.96889580093313, 67.71384136858475, 70.31104199066874, 70.63763608087092, 71.63297045101089, 71.46189735614308, 72.31726283048212, 72.02177293934682, 69.93779160186625, 72.19284603421463, 71.27527216174184, 72.48833592534993, 73.35925349922239, 72.47278382581649, 72.42612752721618, 73.26594090202177, 72.6905132192846, 72.61275272161741, 71.9751166407465, 71.36858475894246, 72.79937791601866, 72.61275272161741, 72.55054432348366, 74.23017107309487, 74.2457231726283, 73.91912908242612, 73.4059097978227, 72.27060653188181, 72.92379471228615, 72.64385692068429, 72.6905132192846, 73.14152410575427, 74.26127527216174, 74.93001555209953, 73.81026438569207, 73.85692068429238, 74.21461897356143, 73.15707620528771, 74.57231726283048, 75.10108864696734, 74.19906687402799, 75.31881804043546, 74.63452566096423, 74.4945567651633, 73.98133748055987, 75.24105754276827, 74.61897356143079, 74.82115085536547, 75.28771384136859, 74.51010886469673, 75.30326594090202, 75.2099533437014, 76.40746500777605, 75.86314152410576, 75.97200622083982, 75.52099533437014, 76.18973561430793, 76.09642301710731, 75.38102643856921, 75.97200622083982, 77.06065318818041, 76.50077760497668, 75.3343701399689, 76.68740279937792, 76.62519440124417, 76.09642301710731, 78.16485225505443, 75.27216174183515, 76.08087091757388, 76.4696734059098, 74.97667185069984, 75.48989113530327, 76.96734059097979, 77.51166407465007, 75.90979782270607]
[14.285714285714286, 23.61904761904762, 33.333333333333336, 35.61904761904762, 34.57142857142857, 42.0, 49.142857142857146, 43.142857142857146, 44.38095238095238, 49.142857142857146, 51.904761904761905, 52.857142857142854, 55.904761904761905, 59.523809523809526, 54.285714285714285, 61.23809523809524, 62.476190476190474, 63.42857142857143, 49.333333333333336, 63.23809523809524, 62.285714285714285, 57.714285714285715, 62.76190476190476, 64.28571428571429, 65.80952380952381, 68.19047619047619, 66.38095238095238, 63.904761904761905, 69.52380952380952, 70.95238095238095, 70.57142857142857, 68.19047619047619, 71.71428571428571, 70.85714285714286, 70.38095238095238, 71.9047619047619, 67.71428571428571, 65.9047619047619, 76.0952380952381, 71.71428571428571, 72.85714285714286, 70.95238095238095, 75.42857142857143, 75.42857142857143, 62.38095238095238, 74.76190476190476, 71.9047619047619, 75.14285714285714, 74.19047619047619, 75.23809523809524, 73.9047619047619, 77.14285714285714, 59.04761904761905, 74.57142857142857, 76.0, 76.57142857142857, 75.23809523809524, 75.42857142857143, 75.42857142857143, 72.19047619047619, 74.47619047619048, 76.47619047619048, 75.04761904761905, 76.66666666666667, 71.14285714285714, 72.57142857142857, 75.42857142857143, 76.0952380952381, 75.71428571428571, 68.19047619047619, 74.0952380952381, 73.52380952380952, 77.42857142857143, 72.57142857142857, 76.76190476190476, 74.47619047619048, 77.14285714285714, 74.47619047619048, 75.04761904761905, 77.61904761904762, 70.95238095238095, 68.47619047619048, 79.04761904761905, 75.80952380952381, 76.38095238095238, 78.57142857142857, 76.95238095238095, 73.52380952380952, 79.80952380952381, 77.04761904761905, 77.61904761904762, 74.38095238095238, 75.52380952380952, 75.80952380952381, 79.04761904761905, 76.0, 77.04761904761905, 80.66666666666667, 79.80952380952381, 79.04761904761905, 75.9047619047619, 75.80952380952381, 77.42857142857143, 76.38095238095238, 78.76190476190476, 80.38095238095238, 81.9047619047619, 78.0952380952381, 82.19047619047619, 75.52380952380952, 79.52380952380952, 80.28571428571429, 80.76190476190476, 80.47619047619048, 79.61904761904762, 81.9047619047619, 76.19047619047619, 78.95238095238095, 80.28571428571429, 79.52380952380952, 76.0, 76.76190476190476, 76.57142857142857, 79.42857142857143, 72.76190476190476, 78.85714285714286, 80.85714285714286, 79.33333333333333, 78.66666666666667, 80.0, 78.47619047619048, 81.33333333333333, 80.76190476190476, 76.0952380952381, 80.57142857142857, 75.80952380952381, 80.0952380952381, 81.04761904761905, 82.76190476190476, 81.61904761904762, 79.80952380952381, 77.33333333333333, 79.71428571428571, 76.19047619047619, 71.80952380952381, 80.0952380952381, 80.85714285714286, 81.42857142857143, 82.0952380952381, 78.28571428571429]
model saved as model_store_320/cnn_car_BasicNet.pt
Getting predictions from test set...
BasicNet
[[112  13   0   8   5   9   3]
 [  3 119   0   0   9   2  17]
 [  2  14 117   1   5   6   5]
 [ 21   5   1 102   4   6  11]
 [  1   4   0   0 135   0  10]
 [  1  19   5   3   5 116   1]
 [  1  22   2   0   4   0 121]]
=============================
ImprovedNet
=============================
Epoch: 0
Training set [0/6430 (0%)] Loss: 1.949116
Training set [3200/6430 (48%)] Loss: 1.938088
Training set [600/6430 (95%)] Loss: 1.901839
Training set: Average loss: 1.998070
Training set: Average accuracy: 16.95%
Validation set: Average loss: 1.909984, Accuracy: 213/1050 (20%)

Epoch: 1
Training set [0/6430 (0%)] Loss: 1.884207
Training set [3200/6430 (48%)] Loss: 1.779771
Training set [600/6430 (95%)] Loss: 1.778849
Training set: Average loss: 1.802728
Training set: Average accuracy: 28.72%
Validation set: Average loss: 1.776776, Accuracy: 344/1050 (33%)

Epoch: 2
Training set [0/6430 (0%)] Loss: 1.731187
Training set [3200/6430 (48%)] Loss: 1.694586
Training set [600/6430 (95%)] Loss: 1.599479
Training set: Average loss: 1.677314
Training set: Average accuracy: 35.19%
Validation set: Average loss: 1.719256, Accuracy: 389/1050 (37%)

Epoch: 3
Training set [0/6430 (0%)] Loss: 1.645090
Training set [3200/6430 (48%)] Loss: 1.548668
Training set [600/6430 (95%)] Loss: 1.338525
Training set: Average loss: 1.536920
Training set: Average accuracy: 41.59%
Validation set: Average loss: 1.579462, Accuracy: 426/1050 (41%)

Epoch: 4
Training set [0/6430 (0%)] Loss: 1.456325
Training set [3200/6430 (48%)] Loss: 1.370034
Training set [600/6430 (95%)] Loss: 1.412083
Training set: Average loss: 1.397168
Training set: Average accuracy: 48.09%
Validation set: Average loss: 1.516883, Accuracy: 481/1050 (46%)

Epoch: 5
Training set [0/6430 (0%)] Loss: 1.311768
Training set [3200/6430 (48%)] Loss: 1.281693
Training set [600/6430 (95%)] Loss: 1.282306
Training set: Average loss: 1.252434
Training set: Average accuracy: 55.02%
Validation set: Average loss: 1.325215, Accuracy: 556/1050 (53%)

Epoch: 6
Training set [0/6430 (0%)] Loss: 1.105743
Training set [3200/6430 (48%)] Loss: 1.120762
Training set [600/6430 (95%)] Loss: 1.127583
Training set: Average loss: 1.069397
Training set: Average accuracy: 62.27%
Validation set: Average loss: 1.300392, Accuracy: 554/1050 (53%)

Epoch: 7
Training set [0/6430 (0%)] Loss: 1.014744
Training set [3200/6430 (48%)] Loss: 0.940055
Training set [600/6430 (95%)] Loss: 0.699976
Training set: Average loss: 0.897019
Training set: Average accuracy: 68.26%
Validation set: Average loss: 1.286220, Accuracy: 568/1050 (54%)

Epoch: 8
Training set [0/6430 (0%)] Loss: 0.832615
Training set [3200/6430 (48%)] Loss: 0.718185
Training set [600/6430 (95%)] Loss: 0.456859
Training set: Average loss: 0.738451
Training set: Average accuracy: 74.34%
Validation set: Average loss: 1.118609, Accuracy: 622/1050 (59%)

Epoch: 9
Training set [0/6430 (0%)] Loss: 0.657405
Training set [3200/6430 (48%)] Loss: 0.582498
Training set [600/6430 (95%)] Loss: 0.676003
Training set: Average loss: 0.612541
Training set: Average accuracy: 78.93%
Validation set: Average loss: 1.131668, Accuracy: 649/1050 (62%)

Epoch: 10
Training set [0/6430 (0%)] Loss: 0.459175
Training set [3200/6430 (48%)] Loss: 0.459449
Training set [600/6430 (95%)] Loss: 0.638805
Training set: Average loss: 0.496774
Training set: Average accuracy: 83.56%
Validation set: Average loss: 1.103790, Accuracy: 667/1050 (64%)

Epoch: 11
Training set [0/6430 (0%)] Loss: 0.368604
Training set [3200/6430 (48%)] Loss: 0.405286
Training set [600/6430 (95%)] Loss: 0.667198
Training set: Average loss: 0.410705
Training set: Average accuracy: 86.38%
Validation set: Average loss: 1.089719, Accuracy: 678/1050 (65%)

Epoch: 12
Training set [0/6430 (0%)] Loss: 0.368918
Training set [3200/6430 (48%)] Loss: 0.318736
Training set [600/6430 (95%)] Loss: 0.357581
Training set: Average loss: 0.320053
Training set: Average accuracy: 89.36%
Validation set: Average loss: 1.197577, Accuracy: 673/1050 (64%)

Epoch: 13
Training set [0/6430 (0%)] Loss: 0.290996
Training set [3200/6430 (48%)] Loss: 0.235047
Training set [600/6430 (95%)] Loss: 0.313750
Training set: Average loss: 0.259388
Training set: Average accuracy: 91.80%
Validation set: Average loss: 1.148101, Accuracy: 694/1050 (66%)

Epoch: 14
Training set [0/6430 (0%)] Loss: 0.185787
Training set [3200/6430 (48%)] Loss: 0.248114
Training set [600/6430 (95%)] Loss: 0.257800
Training set: Average loss: 0.212529
Training set: Average accuracy: 93.08%
Validation set: Average loss: 1.230556, Accuracy: 700/1050 (67%)

Epoch: 15
Training set [0/6430 (0%)] Loss: 0.149409
Training set [3200/6430 (48%)] Loss: 0.194280
Training set [600/6430 (95%)] Loss: 0.134027
Training set: Average loss: 0.178208
Training set: Average accuracy: 93.58%
Validation set: Average loss: 1.163140, Accuracy: 675/1050 (64%)

Epoch: 16
Training set [0/6430 (0%)] Loss: 0.194262
Training set [3200/6430 (48%)] Loss: 0.135426
Training set [600/6430 (95%)] Loss: 0.064427
Training set: Average loss: 0.144016
Training set: Average accuracy: 95.32%
Validation set: Average loss: 1.234687, Accuracy: 705/1050 (67%)

Epoch: 17
Training set [0/6430 (0%)] Loss: 0.162155
Training set [3200/6430 (48%)] Loss: 0.155269
Training set [600/6430 (95%)] Loss: 0.103708
Training set: Average loss: 0.131304
Training set: Average accuracy: 95.91%
Validation set: Average loss: 1.204003, Accuracy: 714/1050 (68%)

Epoch: 18
Training set [0/6430 (0%)] Loss: 0.104318
Training set [3200/6430 (48%)] Loss: 0.109905
Training set [600/6430 (95%)] Loss: 0.024977
Training set: Average loss: 0.099700
Training set: Average accuracy: 96.70%
Validation set: Average loss: 1.254576, Accuracy: 716/1050 (68%)

Epoch: 19
Training set [0/6430 (0%)] Loss: 0.064339
Training set [3200/6430 (48%)] Loss: 0.100559
Training set [600/6430 (95%)] Loss: 0.241503
Training set: Average loss: 0.093142
Training set: Average accuracy: 97.48%
Validation set: Average loss: 1.398233, Accuracy: 692/1050 (66%)

Epoch: 20
Training set [0/6430 (0%)] Loss: 0.081548
Training set [3200/6430 (48%)] Loss: 0.087655
Training set [600/6430 (95%)] Loss: 0.036093
Training set: Average loss: 0.094436
Training set: Average accuracy: 96.84%
Validation set: Average loss: 1.190396, Accuracy: 711/1050 (68%)

Epoch: 21
Training set [0/6430 (0%)] Loss: 0.101419
Training set [3200/6430 (48%)] Loss: 0.050585
Training set [600/6430 (95%)] Loss: 0.029099
Training set: Average loss: 0.069171
Training set: Average accuracy: 98.02%
Validation set: Average loss: 1.314562, Accuracy: 722/1050 (69%)

Epoch: 22
Training set [0/6430 (0%)] Loss: 0.079412
Training set [3200/6430 (48%)] Loss: 0.077684
Training set [600/6430 (95%)] Loss: 0.011728
Training set: Average loss: 0.066643
Training set: Average accuracy: 97.79%
Validation set: Average loss: 1.412304, Accuracy: 708/1050 (67%)

Epoch: 23
Training set [0/6430 (0%)] Loss: 0.069900
Training set [3200/6430 (48%)] Loss: 0.053128
Training set [600/6430 (95%)] Loss: 0.030394
Training set: Average loss: 0.052654
Training set: Average accuracy: 98.26%
Validation set: Average loss: 1.406198, Accuracy: 698/1050 (66%)

Epoch: 24
Training set [0/6430 (0%)] Loss: 0.061980
Training set [3200/6430 (48%)] Loss: 0.025596
Training set [600/6430 (95%)] Loss: 0.063819
Training set: Average loss: 0.065826
Training set: Average accuracy: 97.96%
Validation set: Average loss: 1.355406, Accuracy: 699/1050 (67%)

Epoch: 25
Training set [0/6430 (0%)] Loss: 0.079915
Training set [3200/6430 (48%)] Loss: 0.070953
Training set [600/6430 (95%)] Loss: 0.035167
Training set: Average loss: 0.059120
Training set: Average accuracy: 98.37%
Validation set: Average loss: 1.506522, Accuracy: 710/1050 (68%)

Epoch: 26
Training set [0/6430 (0%)] Loss: 0.038595
Training set [3200/6430 (48%)] Loss: 0.021395
Training set [600/6430 (95%)] Loss: 0.042741
Training set: Average loss: 0.053974
Training set: Average accuracy: 98.15%
Validation set: Average loss: 1.400436, Accuracy: 712/1050 (68%)

Epoch: 27
Training set [0/6430 (0%)] Loss: 0.034442
Training set [3200/6430 (48%)] Loss: 0.050376
Training set [600/6430 (95%)] Loss: 0.026946
Training set: Average loss: 0.048105
Training set: Average accuracy: 98.55%
Validation set: Average loss: 1.546670, Accuracy: 698/1050 (66%)

Epoch: 28
Training set [0/6430 (0%)] Loss: 0.026903
Training set [3200/6430 (48%)] Loss: 0.064882
Training set [600/6430 (95%)] Loss: 0.023297
Training set: Average loss: 0.043592
Training set: Average accuracy: 98.54%
Validation set: Average loss: 1.441940, Accuracy: 724/1050 (69%)

Epoch: 29
Training set [0/6430 (0%)] Loss: 0.030424
Training set [3200/6430 (48%)] Loss: 0.071253
Training set [600/6430 (95%)] Loss: 0.050637
Training set: Average loss: 0.048813
Training set: Average accuracy: 98.13%
Validation set: Average loss: 1.452809, Accuracy: 714/1050 (68%)

Epoch: 30
Training set [0/6430 (0%)] Loss: 0.042527
Training set [3200/6430 (48%)] Loss: 0.029321
Training set [600/6430 (95%)] Loss: 0.087428
Training set: Average loss: 0.048141
Training set: Average accuracy: 98.58%
Validation set: Average loss: 1.460915, Accuracy: 696/1050 (66%)

Epoch: 31
Training set [0/6430 (0%)] Loss: 0.080519
Training set [3200/6430 (48%)] Loss: 0.043280
Training set [600/6430 (95%)] Loss: 0.026322
Training set: Average loss: 0.044762
Training set: Average accuracy: 98.46%
Validation set: Average loss: 1.500425, Accuracy: 700/1050 (67%)

Epoch: 32
Training set [0/6430 (0%)] Loss: 0.029459
Training set [3200/6430 (48%)] Loss: 0.019373
Training set [600/6430 (95%)] Loss: 0.033734
Training set: Average loss: 0.033349
Training set: Average accuracy: 98.97%
Validation set: Average loss: 1.589770, Accuracy: 710/1050 (68%)

Epoch: 33
Training set [0/6430 (0%)] Loss: 0.019253
Training set [3200/6430 (48%)] Loss: 0.060430
Training set [600/6430 (95%)] Loss: 0.005335
Training set: Average loss: 0.036386
Training set: Average accuracy: 98.86%
Validation set: Average loss: 1.467131, Accuracy: 723/1050 (69%)

Epoch: 34
Training set [0/6430 (0%)] Loss: 0.028875
Training set [3200/6430 (48%)] Loss: 0.053224
Training set [600/6430 (95%)] Loss: 0.029899
Training set: Average loss: 0.038045
Training set: Average accuracy: 98.66%
Validation set: Average loss: 1.488251, Accuracy: 704/1050 (67%)

Epoch: 35
Training set [0/6430 (0%)] Loss: 0.022784
Training set [3200/6430 (48%)] Loss: 0.015602
Training set [600/6430 (95%)] Loss: 0.001916
Training set: Average loss: 0.031973
Training set: Average accuracy: 98.91%
Validation set: Average loss: 1.614055, Accuracy: 716/1050 (68%)

Epoch: 36
Training set [0/6430 (0%)] Loss: 0.033158
Training set [3200/6430 (48%)] Loss: 0.026830
Training set [600/6430 (95%)] Loss: 0.066717
Training set: Average loss: 0.032647
Training set: Average accuracy: 99.13%
Validation set: Average loss: 1.590581, Accuracy: 710/1050 (68%)

Epoch: 37
Training set [0/6430 (0%)] Loss: 0.051992
Training set [3200/6430 (48%)] Loss: 0.035212
Training set [600/6430 (95%)] Loss: 0.004693
Training set: Average loss: 0.042176
Training set: Average accuracy: 98.80%
Validation set: Average loss: 1.730806, Accuracy: 698/1050 (66%)

Epoch: 38
Training set [0/6430 (0%)] Loss: 0.021360
Training set [3200/6430 (48%)] Loss: 0.042196
Training set [600/6430 (95%)] Loss: 0.006143
Training set: Average loss: 0.038330
Training set: Average accuracy: 98.82%
Validation set: Average loss: 1.503573, Accuracy: 722/1050 (69%)

Epoch: 39
Training set [0/6430 (0%)] Loss: 0.019619
Training set [3200/6430 (48%)] Loss: 0.025278
Training set [600/6430 (95%)] Loss: 0.023060
Training set: Average loss: 0.027031
Training set: Average accuracy: 99.10%
Validation set: Average loss: 1.575006, Accuracy: 715/1050 (68%)

Epoch: 40
Training set [0/6430 (0%)] Loss: 0.029593
Training set [3200/6430 (48%)] Loss: 0.016445
Training set [600/6430 (95%)] Loss: 0.002417
Training set: Average loss: 0.035405
Training set: Average accuracy: 98.88%
Validation set: Average loss: 1.682018, Accuracy: 715/1050 (68%)

Epoch: 41
Training set [0/6430 (0%)] Loss: 0.016822
Training set [3200/6430 (48%)] Loss: 0.013819
Training set [600/6430 (95%)] Loss: 0.017942
Training set: Average loss: 0.031054
Training set: Average accuracy: 99.08%
Validation set: Average loss: 1.543824, Accuracy: 709/1050 (68%)

Epoch: 42
Training set [0/6430 (0%)] Loss: 0.044429
Training set [3200/6430 (48%)] Loss: 0.027734
Training set [600/6430 (95%)] Loss: 0.001232
Training set: Average loss: 0.019692
Training set: Average accuracy: 99.41%
Validation set: Average loss: 1.757248, Accuracy: 712/1050 (68%)

Epoch: 43
Training set [0/6430 (0%)] Loss: 0.043168
Training set [3200/6430 (48%)] Loss: 0.015099
Training set [600/6430 (95%)] Loss: 0.003343
Training set: Average loss: 0.028396
Training set: Average accuracy: 98.99%
Validation set: Average loss: 1.707359, Accuracy: 707/1050 (67%)

Epoch: 44
Training set [0/6430 (0%)] Loss: 0.013933
Training set [3200/6430 (48%)] Loss: 0.023168
Training set [600/6430 (95%)] Loss: 0.021999
Training set: Average loss: 0.025682
Training set: Average accuracy: 99.10%
Validation set: Average loss: 1.700125, Accuracy: 705/1050 (67%)

Epoch: 45
Training set [0/6430 (0%)] Loss: 0.040664
Training set [3200/6430 (48%)] Loss: 0.021150
Training set [600/6430 (95%)] Loss: 0.030313
Training set: Average loss: 0.028163
Training set: Average accuracy: 99.05%
Validation set: Average loss: 1.720187, Accuracy: 706/1050 (67%)

Epoch: 46
Training set [0/6430 (0%)] Loss: 0.025818
Training set [3200/6430 (48%)] Loss: 0.049496
Training set [600/6430 (95%)] Loss: 0.003192
Training set: Average loss: 0.027299
Training set: Average accuracy: 99.02%
Validation set: Average loss: 1.677973, Accuracy: 711/1050 (68%)

Epoch: 47
Training set [0/6430 (0%)] Loss: 0.025517
Training set [3200/6430 (48%)] Loss: 0.040666
Training set [600/6430 (95%)] Loss: 0.002156
Training set: Average loss: 0.027200
Training set: Average accuracy: 99.13%
Validation set: Average loss: 1.763623, Accuracy: 709/1050 (68%)

Epoch: 48
Training set [0/6430 (0%)] Loss: 0.039625
Training set [3200/6430 (48%)] Loss: 0.021523
Training set [600/6430 (95%)] Loss: 0.019399
Training set: Average loss: 0.030041
Training set: Average accuracy: 99.08%
Validation set: Average loss: 1.529253, Accuracy: 708/1050 (67%)

Epoch: 49
Training set [0/6430 (0%)] Loss: 0.034310
Training set [3200/6430 (48%)] Loss: 0.036489
Training set [600/6430 (95%)] Loss: 0.006590
Training set: Average loss: 0.026314
Training set: Average accuracy: 99.16%
Validation set: Average loss: 1.665711, Accuracy: 707/1050 (67%)

Epoch: 50
Training set [0/6430 (0%)] Loss: 0.034782
Training set [3200/6430 (48%)] Loss: 0.017240
Training set [600/6430 (95%)] Loss: 0.001642
Training set: Average loss: 0.019430
Training set: Average accuracy: 99.39%
Validation set: Average loss: 1.734145, Accuracy: 707/1050 (67%)

Epoch: 51
Training set [0/6430 (0%)] Loss: 0.009576
Training set [3200/6430 (48%)] Loss: 0.018910
Training set [600/6430 (95%)] Loss: 0.005547
Training set: Average loss: 0.020967
Training set: Average accuracy: 99.35%
Validation set: Average loss: 1.698024, Accuracy: 711/1050 (68%)

Epoch: 52
Training set [0/6430 (0%)] Loss: 0.024434
Training set [3200/6430 (48%)] Loss: 0.010558
Training set [600/6430 (95%)] Loss: 0.005217
Training set: Average loss: 0.021419
Training set: Average accuracy: 99.30%
Validation set: Average loss: 1.844536, Accuracy: 706/1050 (67%)

Epoch: 53
Training set [0/6430 (0%)] Loss: 0.013374
Training set [3200/6430 (48%)] Loss: 0.011147
Training set [600/6430 (95%)] Loss: 0.003195
Training set: Average loss: 0.022466
Training set: Average accuracy: 99.27%
Validation set: Average loss: 1.830153, Accuracy: 704/1050 (67%)

Epoch: 54
Training set [0/6430 (0%)] Loss: 0.015964
Training set [3200/6430 (48%)] Loss: 0.025037
Training set [600/6430 (95%)] Loss: 0.002018
Training set: Average loss: 0.019099
Training set: Average accuracy: 99.35%
Validation set: Average loss: 1.900602, Accuracy: 710/1050 (68%)

Epoch: 55
Training set [0/6430 (0%)] Loss: 0.028017
Training set [3200/6430 (48%)] Loss: 0.031866
Training set [600/6430 (95%)] Loss: 0.001171
Training set: Average loss: 0.023430
Training set: Average accuracy: 99.27%
Validation set: Average loss: 1.774192, Accuracy: 707/1050 (67%)

Epoch: 56
Training set [0/6430 (0%)] Loss: 0.018388
Training set [3200/6430 (48%)] Loss: 0.030674
Training set [600/6430 (95%)] Loss: 0.014834
Training set: Average loss: 0.022198
Training set: Average accuracy: 99.38%
Validation set: Average loss: 1.671469, Accuracy: 709/1050 (68%)

Epoch: 57
Training set [0/6430 (0%)] Loss: 0.008163
Training set [3200/6430 (48%)] Loss: 0.009498
Training set [600/6430 (95%)] Loss: 0.019871
Training set: Average loss: 0.020449
Training set: Average accuracy: 99.41%
Validation set: Average loss: 1.793133, Accuracy: 698/1050 (66%)

Epoch: 58
Training set [0/6430 (0%)] Loss: 0.006032
Training set [3200/6430 (48%)] Loss: 0.023443
Training set [600/6430 (95%)] Loss: 0.006306
Training set: Average loss: 0.024300
Training set: Average accuracy: 99.18%
Validation set: Average loss: 1.714537, Accuracy: 721/1050 (69%)

Epoch: 59
Training set [0/6430 (0%)] Loss: 0.024840
Training set [3200/6430 (48%)] Loss: 0.010445
Training set [600/6430 (95%)] Loss: 0.017123
Training set: Average loss: 0.018286
Training set: Average accuracy: 99.39%
Validation set: Average loss: 1.939555, Accuracy: 694/1050 (66%)

Epoch: 60
Training set [0/6430 (0%)] Loss: 0.009452
Training set [3200/6430 (48%)] Loss: 0.013857
Training set [600/6430 (95%)] Loss: 0.015262
Training set: Average loss: 0.026243
Training set: Average accuracy: 99.19%
Validation set: Average loss: 1.817233, Accuracy: 710/1050 (68%)

Epoch: 61
Training set [0/6430 (0%)] Loss: 0.015948
Training set [3200/6430 (48%)] Loss: 0.014623
Training set [600/6430 (95%)] Loss: 0.022948
Training set: Average loss: 0.022422
Training set: Average accuracy: 99.32%
Validation set: Average loss: 1.653421, Accuracy: 692/1050 (66%)

Epoch: 62
Training set [0/6430 (0%)] Loss: 0.044011
Training set [3200/6430 (48%)] Loss: 0.017336
Training set [600/6430 (95%)] Loss: 0.000969
Training set: Average loss: 0.023318
Training set: Average accuracy: 99.19%
Validation set: Average loss: 1.824584, Accuracy: 697/1050 (66%)

Epoch: 63
Training set [0/6430 (0%)] Loss: 0.030836
Training set [3200/6430 (48%)] Loss: 0.017681
Training set [600/6430 (95%)] Loss: 0.000998
Training set: Average loss: 0.023469
Training set: Average accuracy: 99.14%
Validation set: Average loss: 1.841781, Accuracy: 703/1050 (67%)

Epoch: 64
Training set [0/6430 (0%)] Loss: 0.050642
Training set [3200/6430 (48%)] Loss: 0.033417
Training set [600/6430 (95%)] Loss: 0.008951
Training set: Average loss: 0.024424
Training set: Average accuracy: 99.27%
Validation set: Average loss: 1.606257, Accuracy: 714/1050 (68%)

Epoch: 65
Training set [0/6430 (0%)] Loss: 0.012679
Training set [3200/6430 (48%)] Loss: 0.027975
Training set [600/6430 (95%)] Loss: 0.014025
Training set: Average loss: 0.020157
Training set: Average accuracy: 99.36%
Validation set: Average loss: 1.736743, Accuracy: 724/1050 (69%)

Epoch: 66
Training set [0/6430 (0%)] Loss: 0.011550
Training set [3200/6430 (48%)] Loss: 0.016749
Training set [600/6430 (95%)] Loss: 0.005177
Training set: Average loss: 0.019288
Training set: Average accuracy: 99.24%
Validation set: Average loss: 1.772397, Accuracy: 720/1050 (69%)

Epoch: 67
Training set [0/6430 (0%)] Loss: 0.016076
Training set [3200/6430 (48%)] Loss: 0.015850
Training set [600/6430 (95%)] Loss: 0.001366
Training set: Average loss: 0.013045
Training set: Average accuracy: 99.55%
Validation set: Average loss: 1.846228, Accuracy: 719/1050 (68%)

Epoch: 68
Training set [0/6430 (0%)] Loss: 0.009275
Training set [3200/6430 (48%)] Loss: 0.012290
Training set [600/6430 (95%)] Loss: 0.001365
Training set: Average loss: 0.020547
Training set: Average accuracy: 99.18%
Validation set: Average loss: 1.911153, Accuracy: 694/1050 (66%)

Epoch: 69
Training set [0/6430 (0%)] Loss: 0.005543
Training set [3200/6430 (48%)] Loss: 0.040982
Training set [600/6430 (95%)] Loss: 0.002178
Training set: Average loss: 0.018666
Training set: Average accuracy: 99.44%
Validation set: Average loss: 2.002839, Accuracy: 710/1050 (68%)

Epoch: 70
Training set [0/6430 (0%)] Loss: 0.027320
Training set [3200/6430 (48%)] Loss: 0.017836
Training set [600/6430 (95%)] Loss: 0.003380
Training set: Average loss: 0.018988
Training set: Average accuracy: 99.41%
Validation set: Average loss: 1.810450, Accuracy: 725/1050 (69%)

Epoch: 71
Training set [0/6430 (0%)] Loss: 0.012255
Training set [3200/6430 (48%)] Loss: 0.015203
Training set [600/6430 (95%)] Loss: 0.003972
Training set: Average loss: 0.022724
Training set: Average accuracy: 99.28%
Validation set: Average loss: 1.746380, Accuracy: 732/1050 (70%)

Epoch: 72
Training set [0/6430 (0%)] Loss: 0.038401
Training set [3200/6430 (48%)] Loss: 0.026724
Training set [600/6430 (95%)] Loss: 0.025824
Training set: Average loss: 0.025908
Training set: Average accuracy: 99.13%
Validation set: Average loss: 1.892190, Accuracy: 708/1050 (67%)

Epoch: 73
Training set [0/6430 (0%)] Loss: 0.023528
Training set [3200/6430 (48%)] Loss: 0.010366
Training set [600/6430 (95%)] Loss: 0.004470
Training set: Average loss: 0.025289
Training set: Average accuracy: 99.13%
Validation set: Average loss: 1.707951, Accuracy: 707/1050 (67%)

Epoch: 74
Training set [0/6430 (0%)] Loss: 0.016004
Training set [3200/6430 (48%)] Loss: 0.018606
Training set [600/6430 (95%)] Loss: 0.009012
Training set: Average loss: 0.022018
Training set: Average accuracy: 99.27%
Validation set: Average loss: 1.707371, Accuracy: 715/1050 (68%)

Epoch: 75
Training set [0/6430 (0%)] Loss: 0.010306
Training set [3200/6430 (48%)] Loss: 0.027833
Training set [600/6430 (95%)] Loss: 0.028249
Training set: Average loss: 0.025774
Training set: Average accuracy: 99.19%
Validation set: Average loss: 1.761294, Accuracy: 718/1050 (68%)

Epoch: 76
Training set [0/6430 (0%)] Loss: 0.005639
Training set [3200/6430 (48%)] Loss: 0.036456
Training set [600/6430 (95%)] Loss: 0.014368
Training set: Average loss: 0.022719
Training set: Average accuracy: 99.16%
Validation set: Average loss: 1.659010, Accuracy: 708/1050 (67%)

Epoch: 77
Training set [0/6430 (0%)] Loss: 0.031336
Training set [3200/6430 (48%)] Loss: 0.014350
Training set [600/6430 (95%)] Loss: 0.034454
Training set: Average loss: 0.022003
Training set: Average accuracy: 99.22%
Validation set: Average loss: 1.766017, Accuracy: 702/1050 (67%)

Early stopping: no improvement for 10 epochs
ImprovedNet
training_loss -- validation_loss
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77]
[1.9980704954692297, 1.8027278866086687, 1.6773140487216769, 1.536920388539632, 1.3971684603464036, 1.252433833621797, 1.0693967938423157, 0.8970186795507159, 0.7384508975914547, 0.612541119257609, 0.49677389292489915, 0.41070489230610074, 0.32005314174152555, 0.2593878564380464, 0.2125288255157925, 0.1782078579777763, 0.1440159689102854, 0.13130400755575725, 0.09970040929814179, 0.0931424464853037, 0.09443554974028043, 0.06917071076376098, 0.06664266707819133, 0.05265373940623942, 0.0658262169786862, 0.059120382758833114, 0.05397359858311358, 0.04810498903195063, 0.043592240572685285, 0.04881312875520615, 0.04814137615973041, 0.04476204310499486, 0.03334926432442097, 0.03638634427140156, 0.038044728338718414, 0.03197277057915926, 0.0326465628154221, 0.042175610549747944, 0.0383303488959514, 0.027031385162401767, 0.03540505736046249, 0.031053609791256133, 0.019691719335415178, 0.028396023481729486, 0.025681898352645692, 0.02816321390370528, 0.027298739246491874, 0.027199718591180585, 0.030041468595819815, 0.026313700291904666, 0.019430125326228637, 0.02096674041379066, 0.021419046291460592, 0.022466341975987666, 0.019098894160595677, 0.0234304871188388, 0.022197556504536243, 0.02044855501680147, 0.024299897031769865, 0.018286485358008316, 0.02624345158359834, 0.02242235444663536, 0.023318134439510425, 0.023468559352858437, 0.024423610241640182, 0.020157359895252046, 0.019288442252824705, 0.013045450655876525, 0.020546712419239894, 0.01866550394333899, 0.018987633842265324, 0.02272442304750993, 0.025907775143250114, 0.025289225281171855, 0.022017682902514935, 0.025774357352583183, 0.022718914451875856, 0.022002734665182374]
[1.9099840223789215, 1.7767756283283234, 1.7192555665969849, 1.5794620513916016, 1.5168834328651428, 1.3252149522304535, 1.300391674041748, 1.2862198054790497, 1.1186088174581528, 1.1316678076982498, 1.1037901490926743, 1.089718535542488, 1.1975774466991425, 1.1481008380651474, 1.2305562198162079, 1.163139745593071, 1.2346865832805634, 1.204003483057022, 1.2545758336782455, 1.3982331454753876, 1.1903958469629288, 1.3145617544651031, 1.4123040735721588, 1.4061976373195648, 1.355406492948532, 1.5065216720104218, 1.400435522198677, 1.5466700792312622, 1.441940426826477, 1.4528092741966248, 1.4609145373106003, 1.500424861907959, 1.5897699147462845, 1.4671309739351273, 1.4882514625787735, 1.6140554994344711, 1.590580552816391, 1.7308058738708496, 1.5035727620124817, 1.575005754828453, 1.6820176839828491, 1.5438237637281418, 1.7572480738162994, 1.7073586285114288, 1.7001253217458725, 1.7201872915029526, 1.677972599864006, 1.7636231631040573, 1.5292534977197647, 1.665711134672165, 1.7341452687978745, 1.6980239301919937, 1.8445364385843277, 1.8301526010036469, 1.900602176785469, 1.7741921991109848, 1.6714686155319214, 1.793132796883583, 1.714536964893341, 1.9395549893379211, 1.81723290681839, 1.6534213423728943, 1.8245835602283478, 1.8417807221412659, 1.6062567085027695, 1.7367425709962845, 1.7723972499370575, 1.8462278693914413, 1.9111528843641281, 2.002839356660843, 1.8104503005743027, 1.7463798075914383, 1.8921900689601898, 1.7079509645700455, 1.7073712944984436, 1.761293649673462, 1.6590103060007095, 1.7660167962312698]
ImprovedNet
training_accuracy -- validation_accuracy
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77]
[16.951788491446344, 28.724727838258165, 35.19440124416796, 41.58631415241057, 48.08709175738725, 55.023328149300156, 62.2706065318818, 68.25816485225505, 74.33903576982893, 78.92690513219284, 83.56143079315707, 86.37636080870918, 89.36236391912908, 91.8040435458787, 93.07931570762052, 93.57698289269051, 95.31881804043546, 95.90979782270607, 96.70295489891136, 97.48055987558321, 96.84292379471229, 98.0248833592535, 97.79160186625194, 98.25816485225505, 97.96267496111975, 98.36702954898911, 98.14930015552099, 98.55365474339035, 98.53810264385692, 98.13374805598755, 98.58475894245723, 98.46034214618973, 98.97356143079315, 98.8646967340591, 98.66251944012441, 98.9113530326594, 99.12908242612752, 98.80248833592535, 98.81804043545878, 99.09797822706065, 98.88024883359253, 99.08242612752721, 99.40902021772939, 98.98911353032659, 99.09797822706065, 99.05132192846034, 99.02021772939347, 99.12908242612752, 99.08242612752721, 99.1601866251944, 99.39346811819595, 99.34681181959564, 99.30015552099533, 99.26905132192846, 99.34681181959564, 99.26905132192846, 99.37791601866252, 99.40902021772939, 99.17573872472784, 99.39346811819595, 99.19129082426127, 99.31570762052877, 99.19129082426127, 99.14463452566096, 99.26905132192846, 99.36236391912908, 99.23794712286158, 99.54898911353033, 99.17573872472784, 99.44012441679627, 99.40902021772939, 99.2846034214619, 99.12908242612752, 99.12908242612752, 99.26905132192846, 99.19129082426127, 99.1601866251944, 99.22239502332815]
[20.285714285714285, 32.76190476190476, 37.04761904761905, 40.57142857142857, 45.80952380952381, 52.95238095238095, 52.76190476190476, 54.095238095238095, 59.23809523809524, 61.80952380952381, 63.523809523809526, 64.57142857142857, 64.0952380952381, 66.0952380952381, 66.66666666666667, 64.28571428571429, 67.14285714285714, 68.0, 68.19047619047619, 65.9047619047619, 67.71428571428571, 68.76190476190476, 67.42857142857143, 66.47619047619048, 66.57142857142857, 67.61904761904762, 67.80952380952381, 66.47619047619048, 68.95238095238095, 68.0, 66.28571428571429, 66.66666666666667, 67.61904761904762, 68.85714285714286, 67.04761904761905, 68.19047619047619, 67.61904761904762, 66.47619047619048, 68.76190476190476, 68.0952380952381, 68.0952380952381, 67.52380952380952, 67.80952380952381, 67.33333333333333, 67.14285714285714, 67.23809523809524, 67.71428571428571, 67.52380952380952, 67.42857142857143, 67.33333333333333, 67.33333333333333, 67.71428571428571, 67.23809523809524, 67.04761904761905, 67.61904761904762, 67.33333333333333, 67.52380952380952, 66.47619047619048, 68.66666666666667, 66.0952380952381, 67.61904761904762, 65.9047619047619, 66.38095238095238, 66.95238095238095, 68.0, 68.95238095238095, 68.57142857142857, 68.47619047619048, 66.0952380952381, 67.61904761904762, 69.04761904761905, 69.71428571428571, 67.42857142857143, 67.33333333333333, 68.0952380952381, 68.38095238095238, 67.42857142857143, 66.85714285714286]
model saved as model_store_320/cnn_car_ImprovedNet.pt
Getting predictions from test set...
ImprovedNet
[[ 94   8   1  11  19  11   6]
 [ 12  89   2   2  20   2  23]
 [ 16  10  88   5   4  10  17]
 [ 35   3   4  68  17  13  10]
 [  5   0   0   1 126   4  14]
 [  6   7   2   3   2 120  10]
 [  3   7   7   2   4  10 117]]
=============================
ImprovedNetLite
=============================
Epoch: 0
Training set [0/6430 (0%)] Loss: 2.085093
Training set [3200/6430 (48%)] Loss: 1.971746
Training set [600/6430 (95%)] Loss: 1.964203
Training set: Average loss: 2.665968
Training set: Average accuracy: 18.20%
Validation set: Average loss: 1.930640, Accuracy: 213/1050 (20%)

Epoch: 1
Training set [0/6430 (0%)] Loss: 1.901576
Training set [3200/6430 (48%)] Loss: 1.853385
Training set [600/6430 (95%)] Loss: 1.649161
Training set: Average loss: 1.837184
Training set: Average accuracy: 25.04%
Validation set: Average loss: 1.862529, Accuracy: 279/1050 (27%)

Epoch: 2
Training set [0/6430 (0%)] Loss: 1.796136
Training set [3200/6430 (48%)] Loss: 1.657620
Training set [600/6430 (95%)] Loss: 1.892534
Training set: Average loss: 1.743817
Training set: Average accuracy: 30.92%
Validation set: Average loss: 1.755874, Accuracy: 386/1050 (37%)

Epoch: 3
Training set [0/6430 (0%)] Loss: 1.681769
Training set [3200/6430 (48%)] Loss: 1.738282
Training set [600/6430 (95%)] Loss: 1.732269
Training set: Average loss: 1.677499
Training set: Average accuracy: 33.59%
Validation set: Average loss: 1.636523, Accuracy: 425/1050 (40%)

Epoch: 4
Training set [0/6430 (0%)] Loss: 1.608737
Training set [3200/6430 (48%)] Loss: 1.611132
Training set [600/6430 (95%)] Loss: 1.514293
Training set: Average loss: 1.600876
Training set: Average accuracy: 37.20%
Validation set: Average loss: 1.557151, Accuracy: 482/1050 (46%)

Epoch: 5
Training set [0/6430 (0%)] Loss: 1.534708
Training set [3200/6430 (48%)] Loss: 1.594338
Training set [600/6430 (95%)] Loss: 1.564604
Training set: Average loss: 1.547401
Training set: Average accuracy: 39.67%
Validation set: Average loss: 1.597332, Accuracy: 442/1050 (42%)

Epoch: 6
Training set [0/6430 (0%)] Loss: 1.532470
Training set [3200/6430 (48%)] Loss: 1.449798
Training set [600/6430 (95%)] Loss: 1.340715
Training set: Average loss: 1.482563
Training set: Average accuracy: 42.18%
Validation set: Average loss: 1.460227, Accuracy: 510/1050 (49%)

Epoch: 7
Training set [0/6430 (0%)] Loss: 1.369638
Training set [3200/6430 (48%)] Loss: 1.481043
Training set [600/6430 (95%)] Loss: 1.519629
Training set: Average loss: 1.439627
Training set: Average accuracy: 44.35%
Validation set: Average loss: 1.317312, Accuracy: 560/1050 (53%)

Epoch: 8
Training set [0/6430 (0%)] Loss: 1.341280
Training set [3200/6430 (48%)] Loss: 1.408391
Training set [600/6430 (95%)] Loss: 1.213880
Training set: Average loss: 1.398917
Training set: Average accuracy: 44.93%
Validation set: Average loss: 1.296823, Accuracy: 563/1050 (54%)

Epoch: 9
Training set [0/6430 (0%)] Loss: 1.291469
Training set [3200/6430 (48%)] Loss: 1.390228
Training set [600/6430 (95%)] Loss: 1.182279
Training set: Average loss: 1.331627
Training set: Average accuracy: 47.42%
Validation set: Average loss: 1.274827, Accuracy: 591/1050 (56%)

Epoch: 10
Training set [0/6430 (0%)] Loss: 1.417155
Training set [3200/6430 (48%)] Loss: 1.269823
Training set [600/6430 (95%)] Loss: 1.258149
Training set: Average loss: 1.292563
Training set: Average accuracy: 50.09%
Validation set: Average loss: 1.171781, Accuracy: 619/1050 (59%)

Epoch: 11
Training set [0/6430 (0%)] Loss: 1.289378
Training set [3200/6430 (48%)] Loss: 1.232035
Training set [600/6430 (95%)] Loss: 1.213527
Training set: Average loss: 1.245502
Training set: Average accuracy: 51.68%
Validation set: Average loss: 1.170315, Accuracy: 617/1050 (59%)

Epoch: 12
Training set [0/6430 (0%)] Loss: 1.191778
Training set [3200/6430 (48%)] Loss: 1.199608
Training set [600/6430 (95%)] Loss: 0.894986
Training set: Average loss: 1.191572
Training set: Average accuracy: 52.38%
Validation set: Average loss: 1.105456, Accuracy: 623/1050 (59%)

Epoch: 13
Training set [0/6430 (0%)] Loss: 1.048737
Training set [3200/6430 (48%)] Loss: 1.087248
Training set [600/6430 (95%)] Loss: 1.303333
Training set: Average loss: 1.159619
Training set: Average accuracy: 54.70%
Validation set: Average loss: 1.092463, Accuracy: 615/1050 (59%)

Epoch: 14
Training set [0/6430 (0%)] Loss: 1.177438
Training set [3200/6430 (48%)] Loss: 1.064339
Training set [600/6430 (95%)] Loss: 1.031441
Training set: Average loss: 1.117534
Training set: Average accuracy: 55.46%
Validation set: Average loss: 1.031449, Accuracy: 663/1050 (63%)

Epoch: 15
Training set [0/6430 (0%)] Loss: 1.097780
Training set [3200/6430 (48%)] Loss: 1.053976
Training set [600/6430 (95%)] Loss: 1.094609
Training set: Average loss: 1.126524
Training set: Average accuracy: 54.70%
Validation set: Average loss: 0.994353, Accuracy: 677/1050 (64%)

Epoch: 16
Training set [0/6430 (0%)] Loss: 1.076030
Training set [3200/6430 (48%)] Loss: 1.088671
Training set [600/6430 (95%)] Loss: 1.128263
Training set: Average loss: 1.060234
Training set: Average accuracy: 57.87%
Validation set: Average loss: 1.085046, Accuracy: 626/1050 (60%)

Epoch: 17
Training set [0/6430 (0%)] Loss: 1.115540
Training set [3200/6430 (48%)] Loss: 1.011654
Training set [600/6430 (95%)] Loss: 0.676878
Training set: Average loss: 1.039339
Training set: Average accuracy: 58.21%
Validation set: Average loss: 1.044764, Accuracy: 667/1050 (64%)

Epoch: 18
Training set [0/6430 (0%)] Loss: 1.087078
Training set [3200/6430 (48%)] Loss: 1.053280
Training set [600/6430 (95%)] Loss: 0.839006
Training set: Average loss: 1.010592
Training set: Average accuracy: 59.02%
Validation set: Average loss: 1.022524, Accuracy: 679/1050 (65%)

Epoch: 19
Training set [0/6430 (0%)] Loss: 0.907166
Training set [3200/6430 (48%)] Loss: 0.947571
Training set [600/6430 (95%)] Loss: 1.226411
Training set: Average loss: 1.001178
Training set: Average accuracy: 60.17%
Validation set: Average loss: 1.354640, Accuracy: 639/1050 (61%)

Epoch: 20
Training set [0/6430 (0%)] Loss: 0.968195
Training set [3200/6430 (48%)] Loss: 0.943230
Training set [600/6430 (95%)] Loss: 1.214919
Training set: Average loss: 0.969934
Training set: Average accuracy: 61.68%
Validation set: Average loss: 1.182180, Accuracy: 668/1050 (64%)

Epoch: 21
Training set [0/6430 (0%)] Loss: 0.832375
Training set [3200/6430 (48%)] Loss: 0.871393
Training set [600/6430 (95%)] Loss: 1.037241
Training set: Average loss: 0.929091
Training set: Average accuracy: 63.25%
Validation set: Average loss: 0.937383, Accuracy: 735/1050 (70%)

Epoch: 22
Training set [0/6430 (0%)] Loss: 0.889734
Training set [3200/6430 (48%)] Loss: 0.986157
Training set [600/6430 (95%)] Loss: 0.883160
Training set: Average loss: 0.915102
Training set: Average accuracy: 63.25%
Validation set: Average loss: 1.136870, Accuracy: 634/1050 (60%)

Epoch: 23
Training set [0/6430 (0%)] Loss: 0.867848
Training set [3200/6430 (48%)] Loss: 0.834487
Training set [600/6430 (95%)] Loss: 0.857248
Training set: Average loss: 0.873604
Training set: Average accuracy: 64.32%
Validation set: Average loss: 1.172936, Accuracy: 666/1050 (63%)

Epoch: 24
Training set [0/6430 (0%)] Loss: 0.896053
Training set [3200/6430 (48%)] Loss: 0.806544
Training set [600/6430 (95%)] Loss: 0.844108
Training set: Average loss: 0.860486
Training set: Average accuracy: 64.26%
Validation set: Average loss: 0.840104, Accuracy: 743/1050 (71%)

Epoch: 25
Training set [0/6430 (0%)] Loss: 0.799478
Training set [3200/6430 (48%)] Loss: 0.922746
Training set [600/6430 (95%)] Loss: 0.820721
Training set: Average loss: 0.856518
Training set: Average accuracy: 64.99%
Validation set: Average loss: 0.861896, Accuracy: 719/1050 (68%)

Epoch: 26
Training set [0/6430 (0%)] Loss: 0.900253
Training set [3200/6430 (48%)] Loss: 0.881922
Training set [600/6430 (95%)] Loss: 0.614272
Training set: Average loss: 0.818841
Training set: Average accuracy: 66.52%
Validation set: Average loss: 0.868133, Accuracy: 751/1050 (72%)

Epoch: 27
Training set [0/6430 (0%)] Loss: 0.793418
Training set [3200/6430 (48%)] Loss: 0.818879
Training set [600/6430 (95%)] Loss: 0.682556
Training set: Average loss: 0.796732
Training set: Average accuracy: 67.45%
Validation set: Average loss: 0.995509, Accuracy: 711/1050 (68%)

Epoch: 28
Training set [0/6430 (0%)] Loss: 0.787152
Training set [3200/6430 (48%)] Loss: 0.910035
Training set [600/6430 (95%)] Loss: 0.751542
Training set: Average loss: 0.827015
Training set: Average accuracy: 65.99%
Validation set: Average loss: 0.885998, Accuracy: 721/1050 (69%)

Epoch: 29
Training set [0/6430 (0%)] Loss: 0.736814
Training set [3200/6430 (48%)] Loss: 0.759216
Training set [600/6430 (95%)] Loss: 0.725079
Training set: Average loss: 0.787524
Training set: Average accuracy: 67.95%
Validation set: Average loss: 0.836914, Accuracy: 749/1050 (71%)

Epoch: 30
Training set [0/6430 (0%)] Loss: 0.763380
Training set [3200/6430 (48%)] Loss: 0.775678
Training set [600/6430 (95%)] Loss: 0.664770
Training set: Average loss: 0.769155
Training set: Average accuracy: 67.93%
Validation set: Average loss: 0.831232, Accuracy: 757/1050 (72%)

Epoch: 31
Training set [0/6430 (0%)] Loss: 0.908328
Training set [3200/6430 (48%)] Loss: 0.802231
Training set [600/6430 (95%)] Loss: 0.742677
Training set: Average loss: 0.774115
Training set: Average accuracy: 68.26%
Validation set: Average loss: 0.777079, Accuracy: 770/1050 (73%)

Epoch: 32
Training set [0/6430 (0%)] Loss: 0.731753
Training set [3200/6430 (48%)] Loss: 0.822194
Training set [600/6430 (95%)] Loss: 0.716688
Training set: Average loss: 0.764259
Training set: Average accuracy: 68.24%
Validation set: Average loss: 0.726570, Accuracy: 784/1050 (75%)

Epoch: 33
Training set [0/6430 (0%)] Loss: 0.737193
Training set [3200/6430 (48%)] Loss: 0.777932
Training set [600/6430 (95%)] Loss: 0.676468
Training set: Average loss: 0.734676
Training set: Average accuracy: 70.08%
Validation set: Average loss: 0.776978, Accuracy: 783/1050 (75%)

Epoch: 34
Training set [0/6430 (0%)] Loss: 0.786201
Training set [3200/6430 (48%)] Loss: 0.760464
Training set [600/6430 (95%)] Loss: 0.585242
Training set: Average loss: 0.717050
Training set: Average accuracy: 70.20%
Validation set: Average loss: 0.794412, Accuracy: 753/1050 (72%)

Epoch: 35
Training set [0/6430 (0%)] Loss: 0.768940
Training set [3200/6430 (48%)] Loss: 0.760526
Training set [600/6430 (95%)] Loss: 0.556493
Training set: Average loss: 0.757854
Training set: Average accuracy: 69.05%
Validation set: Average loss: 0.903003, Accuracy: 722/1050 (69%)

Epoch: 36
Training set [0/6430 (0%)] Loss: 0.811758
Training set [3200/6430 (48%)] Loss: 0.729276
Training set [600/6430 (95%)] Loss: 0.403357
Training set: Average loss: 0.699962
Training set: Average accuracy: 70.75%
Validation set: Average loss: 0.754673, Accuracy: 790/1050 (75%)

Epoch: 37
Training set [0/6430 (0%)] Loss: 0.638977
Training set [3200/6430 (48%)] Loss: 0.586206
Training set [600/6430 (95%)] Loss: 0.971554
Training set: Average loss: 0.708555
Training set: Average accuracy: 71.42%
Validation set: Average loss: 0.870973, Accuracy: 742/1050 (71%)

Epoch: 38
Training set [0/6430 (0%)] Loss: 0.724520
Training set [3200/6430 (48%)] Loss: 0.708407
Training set [600/6430 (95%)] Loss: 0.516009
Training set: Average loss: 0.693953
Training set: Average accuracy: 71.49%
Validation set: Average loss: 0.749118, Accuracy: 769/1050 (73%)

Epoch: 39
Training set [0/6430 (0%)] Loss: 0.652086
Training set [3200/6430 (48%)] Loss: 0.623364
Training set [600/6430 (95%)] Loss: 0.604833
Training set: Average loss: 0.665698
Training set: Average accuracy: 72.91%
Validation set: Average loss: 0.858314, Accuracy: 749/1050 (71%)

Epoch: 40
Training set [0/6430 (0%)] Loss: 0.671297
Training set [3200/6430 (48%)] Loss: 0.748130
Training set [600/6430 (95%)] Loss: 0.644028
Training set: Average loss: 0.695379
Training set: Average accuracy: 71.51%
Validation set: Average loss: 0.691992, Accuracy: 801/1050 (76%)

Epoch: 41
Training set [0/6430 (0%)] Loss: 0.564076
Training set [3200/6430 (48%)] Loss: 0.676916
Training set [600/6430 (95%)] Loss: 0.723620
Training set: Average loss: 0.680188
Training set: Average accuracy: 72.58%
Validation set: Average loss: 0.726588, Accuracy: 784/1050 (75%)

Epoch: 42
Training set [0/6430 (0%)] Loss: 0.742783
Training set [3200/6430 (48%)] Loss: 0.610404
Training set [600/6430 (95%)] Loss: 0.586517
Training set: Average loss: 0.673295
Training set: Average accuracy: 72.43%
Validation set: Average loss: 1.128564, Accuracy: 738/1050 (70%)

Epoch: 43
Training set [0/6430 (0%)] Loss: 0.676560
Training set [3200/6430 (48%)] Loss: 0.750636
Training set [600/6430 (95%)] Loss: 0.680403
Training set: Average loss: 0.660112
Training set: Average accuracy: 73.16%
Validation set: Average loss: 0.955333, Accuracy: 738/1050 (70%)

Epoch: 44
Training set [0/6430 (0%)] Loss: 0.616423
Training set [3200/6430 (48%)] Loss: 0.724801
Training set [600/6430 (95%)] Loss: 0.990668
Training set: Average loss: 0.662241
Training set: Average accuracy: 73.08%
Validation set: Average loss: 0.913747, Accuracy: 737/1050 (70%)

Epoch: 45
Training set [0/6430 (0%)] Loss: 0.606008
Training set [3200/6430 (48%)] Loss: 0.655405
Training set [600/6430 (95%)] Loss: 0.700082
Training set: Average loss: 0.659575
Training set: Average accuracy: 73.53%
Validation set: Average loss: 0.812893, Accuracy: 766/1050 (73%)

Epoch: 46
Training set [0/6430 (0%)] Loss: 0.581470
Training set [3200/6430 (48%)] Loss: 0.652535
Training set [600/6430 (95%)] Loss: 0.442893
Training set: Average loss: 0.637623
Training set: Average accuracy: 73.37%
Validation set: Average loss: 0.776922, Accuracy: 769/1050 (73%)

Epoch: 47
Training set [0/6430 (0%)] Loss: 0.608288
Training set [3200/6430 (48%)] Loss: 0.637451
Training set [600/6430 (95%)] Loss: 0.599827
Training set: Average loss: 0.625504
Training set: Average accuracy: 74.04%
Validation set: Average loss: 0.677001, Accuracy: 791/1050 (75%)

Epoch: 48
Training set [0/6430 (0%)] Loss: 0.489549
Training set [3200/6430 (48%)] Loss: 0.638565
Training set [600/6430 (95%)] Loss: 0.447512
Training set: Average loss: 0.572131
Training set: Average accuracy: 76.81%
Validation set: Average loss: 0.650764, Accuracy: 822/1050 (78%)

Epoch: 49
Training set [0/6430 (0%)] Loss: 0.551682
Training set [3200/6430 (48%)] Loss: 0.620955
Training set [600/6430 (95%)] Loss: 0.580651
Training set: Average loss: 0.603094
Training set: Average accuracy: 75.38%
Validation set: Average loss: 1.140968, Accuracy: 719/1050 (68%)

Epoch: 50
Training set [0/6430 (0%)] Loss: 0.520877
Training set [3200/6430 (48%)] Loss: 0.649280
Training set [600/6430 (95%)] Loss: 0.650831
Training set: Average loss: 0.589994
Training set: Average accuracy: 76.39%
Validation set: Average loss: 0.670896, Accuracy: 818/1050 (78%)

Epoch: 51
Training set [0/6430 (0%)] Loss: 0.542749
Training set [3200/6430 (48%)] Loss: 0.635358
Training set [600/6430 (95%)] Loss: 0.454304
Training set: Average loss: 0.603892
Training set: Average accuracy: 75.05%
Validation set: Average loss: 0.772997, Accuracy: 774/1050 (74%)

Epoch: 52
Training set [0/6430 (0%)] Loss: 0.597447
Training set [3200/6430 (48%)] Loss: 0.577877
Training set [600/6430 (95%)] Loss: 0.443990
Training set: Average loss: 0.585838
Training set: Average accuracy: 75.61%
Validation set: Average loss: 0.921940, Accuracy: 749/1050 (71%)

Epoch: 53
Training set [0/6430 (0%)] Loss: 0.514785
Training set [3200/6430 (48%)] Loss: 0.514961
Training set [600/6430 (95%)] Loss: 0.631852
Training set: Average loss: 0.557017
Training set: Average accuracy: 76.70%
Validation set: Average loss: 0.739448, Accuracy: 804/1050 (77%)

Epoch: 54
Training set [0/6430 (0%)] Loss: 0.555106
Training set [3200/6430 (48%)] Loss: 0.535931
Training set [600/6430 (95%)] Loss: 0.383747
Training set: Average loss: 0.548901
Training set: Average accuracy: 77.22%
Validation set: Average loss: 0.810083, Accuracy: 792/1050 (75%)

Epoch: 55
Training set [0/6430 (0%)] Loss: 0.621422
Training set [3200/6430 (48%)] Loss: 0.593017
Training set [600/6430 (95%)] Loss: 0.372603
Training set: Average loss: 0.563463
Training set: Average accuracy: 76.58%
Validation set: Average loss: 1.427434, Accuracy: 690/1050 (66%)

Epoch: 56
Training set [0/6430 (0%)] Loss: 0.631453
Training set [3200/6430 (48%)] Loss: 0.534619
Training set [600/6430 (95%)] Loss: 0.591350
Training set: Average loss: 0.568556
Training set: Average accuracy: 76.50%
Validation set: Average loss: 0.713231, Accuracy: 788/1050 (75%)

Epoch: 57
Training set [0/6430 (0%)] Loss: 0.560224
Training set [3200/6430 (48%)] Loss: 0.557501
Training set [600/6430 (95%)] Loss: 0.628036
Training set: Average loss: 0.569883
Training set: Average accuracy: 77.31%
Validation set: Average loss: 0.928631, Accuracy: 763/1050 (73%)

Epoch: 58
Training set [0/6430 (0%)] Loss: 0.518391
Training set [3200/6430 (48%)] Loss: 0.538456
Training set [600/6430 (95%)] Loss: 0.527368
Training set: Average loss: 0.554561
Training set: Average accuracy: 77.48%
Validation set: Average loss: 0.779947, Accuracy: 806/1050 (77%)

Epoch: 59
Training set [0/6430 (0%)] Loss: 0.605883
Training set [3200/6430 (48%)] Loss: 0.555305
Training set [600/6430 (95%)] Loss: 0.736034
Training set: Average loss: 0.582597
Training set: Average accuracy: 76.42%
Validation set: Average loss: 0.956180, Accuracy: 756/1050 (72%)

Epoch: 60
Training set [0/6430 (0%)] Loss: 0.527060
Training set [3200/6430 (48%)] Loss: 0.698587
Training set [600/6430 (95%)] Loss: 0.650793
Training set: Average loss: 0.563810
Training set: Average accuracy: 77.01%
Validation set: Average loss: 0.770050, Accuracy: 802/1050 (76%)

Epoch: 61
Training set [0/6430 (0%)] Loss: 0.555968
Training set [3200/6430 (48%)] Loss: 0.567302
Training set [600/6430 (95%)] Loss: 0.606686
Training set: Average loss: 0.565085
Training set: Average accuracy: 76.77%
Validation set: Average loss: 0.736063, Accuracy: 804/1050 (77%)

Epoch: 62
Training set [0/6430 (0%)] Loss: 0.518276
Training set [3200/6430 (48%)] Loss: 0.583341
Training set [600/6430 (95%)] Loss: 0.479984
Training set: Average loss: 0.534282
Training set: Average accuracy: 77.53%
Validation set: Average loss: 0.741066, Accuracy: 809/1050 (77%)

Epoch: 63
Training set [0/6430 (0%)] Loss: 0.509613
Training set [3200/6430 (48%)] Loss: 0.570854
Training set [600/6430 (95%)] Loss: 0.414443
Training set: Average loss: 0.529628
Training set: Average accuracy: 78.10%
Validation set: Average loss: 0.687310, Accuracy: 801/1050 (76%)

Epoch: 64
Training set [0/6430 (0%)] Loss: 0.544440
Training set [3200/6430 (48%)] Loss: 0.428105
Training set [600/6430 (95%)] Loss: 0.562046
Training set: Average loss: 0.531232
Training set: Average accuracy: 78.40%
Validation set: Average loss: 0.738034, Accuracy: 818/1050 (78%)

Epoch: 65
Training set [0/6430 (0%)] Loss: 0.552572
Training set [3200/6430 (48%)] Loss: 0.542943
Training set [600/6430 (95%)] Loss: 0.506476
Training set: Average loss: 0.545983
Training set: Average accuracy: 77.40%
Validation set: Average loss: 0.754047, Accuracy: 807/1050 (77%)

Epoch: 66
Training set [0/6430 (0%)] Loss: 0.567515
Training set [3200/6430 (48%)] Loss: 0.455148
Training set [600/6430 (95%)] Loss: 0.735411
Training set: Average loss: 0.537208
Training set: Average accuracy: 78.32%
Validation set: Average loss: 1.036773, Accuracy: 738/1050 (70%)

Epoch: 67
Training set [0/6430 (0%)] Loss: 0.525728
Training set [3200/6430 (48%)] Loss: 0.468812
Training set [600/6430 (95%)] Loss: 0.322084
Training set: Average loss: 0.505781
Training set: Average accuracy: 78.43%
Validation set: Average loss: 0.722693, Accuracy: 812/1050 (77%)

Epoch: 68
Training set [0/6430 (0%)] Loss: 0.453678
Training set [3200/6430 (48%)] Loss: 0.546516
Training set [600/6430 (95%)] Loss: 0.430312
Training set: Average loss: 0.485200
Training set: Average accuracy: 79.64%
Validation set: Average loss: 0.807667, Accuracy: 788/1050 (75%)

Epoch: 69
Training set [0/6430 (0%)] Loss: 0.498907
Training set [3200/6430 (48%)] Loss: 0.578116
Training set [600/6430 (95%)] Loss: 0.544297
Training set: Average loss: 0.535582
Training set: Average accuracy: 77.71%
Validation set: Average loss: 1.394385, Accuracy: 679/1050 (65%)

Epoch: 70
Training set [0/6430 (0%)] Loss: 0.510958
Training set [3200/6430 (48%)] Loss: 0.555491
Training set [600/6430 (95%)] Loss: 0.643697
Training set: Average loss: 0.529403
Training set: Average accuracy: 78.55%
Validation set: Average loss: 0.735230, Accuracy: 789/1050 (75%)

Epoch: 71
Training set [0/6430 (0%)] Loss: 0.539303
Training set [3200/6430 (48%)] Loss: 0.580016
Training set [600/6430 (95%)] Loss: 0.591661
Training set: Average loss: 0.505691
Training set: Average accuracy: 80.11%
Validation set: Average loss: 0.905314, Accuracy: 765/1050 (73%)

Epoch: 72
Training set [0/6430 (0%)] Loss: 0.592856
Training set [3200/6430 (48%)] Loss: 0.656978
Training set [600/6430 (95%)] Loss: 0.356340
Training set: Average loss: 0.525338
Training set: Average accuracy: 78.18%
Validation set: Average loss: 0.713598, Accuracy: 799/1050 (76%)

Epoch: 73
Training set [0/6430 (0%)] Loss: 0.514849
Training set [3200/6430 (48%)] Loss: 0.473129
Training set [600/6430 (95%)] Loss: 0.607196
Training set: Average loss: 0.521758
Training set: Average accuracy: 78.27%
Validation set: Average loss: 0.711518, Accuracy: 811/1050 (77%)

Epoch: 74
Training set [0/6430 (0%)] Loss: 0.509270
Training set [3200/6430 (48%)] Loss: 0.542219
Training set [600/6430 (95%)] Loss: 0.367686
Training set: Average loss: 0.495959
Training set: Average accuracy: 79.70%
Validation set: Average loss: 0.639261, Accuracy: 835/1050 (80%)

Epoch: 75
Training set [0/6430 (0%)] Loss: 0.359637
Training set [3200/6430 (48%)] Loss: 0.486012
Training set [600/6430 (95%)] Loss: 0.434149
Training set: Average loss: 0.498651
Training set: Average accuracy: 79.83%
Validation set: Average loss: 0.760941, Accuracy: 802/1050 (76%)

Epoch: 76
Training set [0/6430 (0%)] Loss: 0.515286
Training set [3200/6430 (48%)] Loss: 0.490304
Training set [600/6430 (95%)] Loss: 0.823057
Training set: Average loss: 0.501016
Training set: Average accuracy: 80.53%
Validation set: Average loss: 0.658146, Accuracy: 809/1050 (77%)

Epoch: 77
Training set [0/6430 (0%)] Loss: 0.483334
Training set [3200/6430 (48%)] Loss: 0.466116
Training set [600/6430 (95%)] Loss: 0.464131
Training set: Average loss: 0.503360
Training set: Average accuracy: 79.35%
Validation set: Average loss: 0.810313, Accuracy: 766/1050 (73%)

Epoch: 78
Training set [0/6430 (0%)] Loss: 0.510962
Training set [3200/6430 (48%)] Loss: 0.527673
Training set [600/6430 (95%)] Loss: 0.561458
Training set: Average loss: 0.516043
Training set: Average accuracy: 79.14%
Validation set: Average loss: 0.751270, Accuracy: 824/1050 (78%)

Early stopping: no improvement for 10 epochs
ImprovedNetLite
training_loss -- validation_loss
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]
[2.66596824214572, 1.8371842021033877, 1.7438167844499861, 1.677499356723967, 1.6008762802396501, 1.5474008605593728, 1.4825625873747326, 1.4396271365029472, 1.3989173230670748, 1.3316268410001482, 1.2925626153037661, 1.24550195535024, 1.1915721070198786, 1.1596187296367826, 1.117534109524318, 1.1265237274624051, 1.0602341833568754, 1.0393388583546592, 1.0105919071606226, 1.0011784746533348, 0.9699343414533705, 0.9290912577084133, 0.91510199932825, 0.8736040535427275, 0.8604861554645357, 0.8565184303692409, 0.8188413012595404, 0.796731826804933, 0.8270152324721927, 0.787524143854777, 0.7691548636981419, 0.7741152757690066, 0.7642589041164943, 0.7346762844494411, 0.7170497008732387, 0.7578541522934323, 0.6999621334530058, 0.7085548582531157, 0.6939528981844584, 0.6656976427350726, 0.6953792770703634, 0.6801879093760536, 0.6732953758466811, 0.6601122305506751, 0.662241206282661, 0.6595748180434817, 0.6376230588981083, 0.6255037443978446, 0.5721305920964196, 0.6030943365324111, 0.5899942290215265, 0.6038921560559954, 0.5858377388545445, 0.5570165656861805, 0.5489011917795453, 0.5634625128337315, 0.5685561498006185, 0.5698827590261187, 0.5545605534598941, 0.5825974529697782, 0.5638101881458646, 0.5650846702711922, 0.5342821720100585, 0.5296277176766169, 0.5312315750689733, 0.5459834805556706, 0.53720841947056, 0.5057812219574338, 0.48520047465960187, 0.5355816966011411, 0.5294034438473838, 0.5056913991769155, 0.5253375115848723, 0.5217576041108086, 0.4959587837968554, 0.4986508261589777, 0.5010160548346383, 0.5033596527008783, 0.5160430201462337]
[1.930640459060669, 1.862529307603836, 1.7558744549751282, 1.63652303814888, 1.557151436805725, 1.5973321199417114, 1.4602266550064087, 1.317312479019165, 1.2968233823776245, 1.2748267352581024, 1.171781301498413, 1.1703149676322937, 1.1054564118385315, 1.0924629420042038, 1.031449168920517, 0.994352862238884, 1.0850457102060318, 1.0447635799646378, 1.0225236415863037, 1.3546396344900131, 1.182179719209671, 0.9373833984136581, 1.136870414018631, 1.1729363948106766, 0.840104267001152, 0.8618960827589035, 0.8681328445672989, 0.9955087751150131, 0.8859978690743446, 0.8369140923023224, 0.8312319666147232, 0.777078777551651, 0.7265704497694969, 0.7769779860973358, 0.7944123893976212, 0.9030028879642487, 0.7546732276678085, 0.8709734156727791, 0.7491181418299675, 0.8583142161369324, 0.6919922530651093, 0.7265876457095146, 1.1285640895366669, 0.9553325027227402, 0.9137466996908188, 0.812892958521843, 0.7769217789173126, 0.6770010627806187, 0.6507641449570656, 1.1409680098295212, 0.6708959937095642, 0.7729969397187233, 0.9219400584697723, 0.7394481599330902, 0.8100828677415848, 1.4274342358112335, 0.7132313475012779, 0.9286305606365204, 0.7799469232559204, 0.9561795741319656, 0.7700496912002563, 0.7360629439353943, 0.7410656213760376, 0.6873104646801949, 0.7380336225032806, 0.7540467083454132, 1.036773219704628, 0.7226929813623428, 0.8076668754220009, 1.3943845182657242, 0.7352303713560104, 0.9053142368793488, 0.71359833329916, 0.7115177810192108, 0.6392605379223824, 0.7609407380223274, 0.6581456921994686, 0.8103126063942909, 0.7512699067592621]
ImprovedNetLite
training_accuracy -- validation_accuracy
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]
[18.195956454121305, 25.038880248833593, 30.917573872472783, 33.59253499222395, 37.20062208398134, 39.67340590979782, 42.17729393468118, 44.35458786936236, 44.93001555209953, 47.418351477449455, 50.09331259720062, 51.679626749611195, 52.37947122861586, 54.69673405909798, 55.45878693623639, 54.69673405909798, 57.86936236391913, 58.211508553654745, 59.020217729393465, 60.17107309486781, 61.679626749611195, 63.25038880248834, 63.25038880248834, 64.32348367029549, 64.26127527216174, 64.99222395023328, 66.51632970451011, 67.44945567651634, 65.98755832037325, 67.94712286158631, 67.93157076205287, 68.25816485225505, 68.24261275272161, 70.07776049766719, 70.20217729393468, 69.05132192846034, 70.74650077760498, 71.41524105754277, 71.49300155520996, 72.90824261275272, 71.5085536547434, 72.58164852255054, 72.42612752721618, 73.15707620528771, 73.07931570762052, 73.5303265940902, 73.37480559875583, 74.04354587869362, 76.81181959564542, 75.38102643856921, 76.39191290824262, 75.05443234836703, 75.61430793157076, 76.70295489891136, 77.21617418351478, 76.57853810264386, 76.50077760497668, 77.3094867807154, 77.48055987558321, 76.42301710730949, 77.0139968895801, 76.7651632970451, 77.52721617418351, 78.10264385692068, 78.39813374805598, 77.40279937791603, 78.3203732503888, 78.42923794712286, 79.64230171073095, 77.71384136858475, 78.55365474339035, 80.10886469673406, 78.18040435458786, 78.27371695178849, 79.7045101088647, 79.82892690513219, 80.52877138413686, 79.34681181959564, 79.14463452566096]
[20.285714285714285, 26.571428571428573, 36.76190476190476, 40.476190476190474, 45.904761904761905, 42.095238095238095, 48.57142857142857, 53.333333333333336, 53.61904761904762, 56.285714285714285, 58.95238095238095, 58.76190476190476, 59.333333333333336, 58.57142857142857, 63.142857142857146, 64.47619047619048, 59.61904761904762, 63.523809523809526, 64.66666666666667, 60.857142857142854, 63.61904761904762, 70.0, 60.38095238095238, 63.42857142857143, 70.76190476190476, 68.47619047619048, 71.52380952380952, 67.71428571428571, 68.66666666666667, 71.33333333333333, 72.0952380952381, 73.33333333333333, 74.66666666666667, 74.57142857142857, 71.71428571428571, 68.76190476190476, 75.23809523809524, 70.66666666666667, 73.23809523809524, 71.33333333333333, 76.28571428571429, 74.66666666666667, 70.28571428571429, 70.28571428571429, 70.19047619047619, 72.95238095238095, 73.23809523809524, 75.33333333333333, 78.28571428571429, 68.47619047619048, 77.9047619047619, 73.71428571428571, 71.33333333333333, 76.57142857142857, 75.42857142857143, 65.71428571428571, 75.04761904761905, 72.66666666666667, 76.76190476190476, 72.0, 76.38095238095238, 76.57142857142857, 77.04761904761905, 76.28571428571429, 77.9047619047619, 76.85714285714286, 70.28571428571429, 77.33333333333333, 75.04761904761905, 64.66666666666667, 75.14285714285714, 72.85714285714286, 76.0952380952381, 77.23809523809524, 79.52380952380952, 76.38095238095238, 77.04761904761905, 72.95238095238095, 78.47619047619048]
model saved as model_store_320/cnn_car_ImprovedNetLite.pt
Getting predictions from test set...
ImprovedNetLite
[[ 97   4   3  39   5   2   0]
 [  7 107   1   3   6   3  23]
 [  2   3 132   7   1   1   4]
 [ 14   0   6 122   3   2   3]
 [  0   1  10   1 131   0   7]
 [  4   8  14   6   3 112   3]
 [  0   6  14   3   4   0 123]]
Data loaders ready
=============================
BasicNet
=============================
Epoch: 0
Training set [0/6430 (0%)] Loss: 2.012618
Training set [2560/6430 (38%)] Loss: 1.912966
Training set [5120/6430 (77%)] Loss: 1.856632
Training set: Average loss: 2.461281
Training set: Average accuracy: 19.56%
Validation set: Average loss: 1.872985, Accuracy: 224/1050 (21%)

Epoch: 1
Training set [0/6430 (0%)] Loss: 1.850831
Training set [2560/6430 (38%)] Loss: 1.828246
Training set [5120/6430 (77%)] Loss: 1.716729
Training set: Average loss: 1.799036
Training set: Average accuracy: 25.41%
Validation set: Average loss: 1.788143, Accuracy: 323/1050 (31%)

Epoch: 2
Training set [0/6430 (0%)] Loss: 1.735345
Training set [2560/6430 (38%)] Loss: 1.762764
Training set [5120/6430 (77%)] Loss: 1.731612
Training set: Average loss: 1.742088
Training set: Average accuracy: 29.13%
Validation set: Average loss: 1.726440, Accuracy: 390/1050 (37%)

Epoch: 3
Training set [0/6430 (0%)] Loss: 1.745864
Training set [2560/6430 (38%)] Loss: 1.595234
Training set [5120/6430 (77%)] Loss: 1.562543
Training set: Average loss: 1.639473
Training set: Average accuracy: 33.79%
Validation set: Average loss: 1.631280, Accuracy: 371/1050 (35%)

Epoch: 4
Training set [0/6430 (0%)] Loss: 1.555426
Training set [2560/6430 (38%)] Loss: 1.592093
Training set [5120/6430 (77%)] Loss: 1.573653
Training set: Average loss: 1.573850
Training set: Average accuracy: 38.10%
Validation set: Average loss: 1.501271, Accuracy: 468/1050 (45%)

Epoch: 5
Training set [0/6430 (0%)] Loss: 1.576955
Training set [2560/6430 (38%)] Loss: 1.489547
Training set [5120/6430 (77%)] Loss: 1.438318
Training set: Average loss: 1.479514
Training set: Average accuracy: 42.58%
Validation set: Average loss: 1.462467, Accuracy: 500/1050 (48%)

Epoch: 6
Training set [0/6430 (0%)] Loss: 1.384779
Training set [2560/6430 (38%)] Loss: 1.436205
Training set [5120/6430 (77%)] Loss: 1.363285
Training set: Average loss: 1.402496
Training set: Average accuracy: 45.19%
Validation set: Average loss: 1.382165, Accuracy: 529/1050 (50%)

Epoch: 7
Training set [0/6430 (0%)] Loss: 1.332187
Training set [2560/6430 (38%)] Loss: 1.255662
Training set [5120/6430 (77%)] Loss: 1.215332
Training set: Average loss: 1.329146
Training set: Average accuracy: 48.35%
Validation set: Average loss: 1.272725, Accuracy: 554/1050 (53%)

Epoch: 8
Training set [0/6430 (0%)] Loss: 1.242575
Training set [2560/6430 (38%)] Loss: 1.247712
Training set [5120/6430 (77%)] Loss: 1.250897
Training set: Average loss: 1.269744
Training set: Average accuracy: 51.23%
Validation set: Average loss: 1.205857, Accuracy: 609/1050 (58%)

Epoch: 9
Training set [0/6430 (0%)] Loss: 1.252754
Training set [2560/6430 (38%)] Loss: 1.300022
Training set [5120/6430 (77%)] Loss: 1.171547
Training set: Average loss: 1.207466
Training set: Average accuracy: 53.48%
Validation set: Average loss: 1.639822, Accuracy: 474/1050 (45%)

Epoch: 10
Training set [0/6430 (0%)] Loss: 1.197192
Training set [2560/6430 (38%)] Loss: 1.033022
Training set [5120/6430 (77%)] Loss: 1.102750
Training set: Average loss: 1.146226
Training set: Average accuracy: 55.29%
Validation set: Average loss: 3.874488, Accuracy: 305/1050 (29%)

Epoch: 11
Training set [0/6430 (0%)] Loss: 1.181294
Training set [2560/6430 (38%)] Loss: 1.130641
Training set [5120/6430 (77%)] Loss: 1.110781
Training set: Average loss: 1.109402
Training set: Average accuracy: 56.11%
Validation set: Average loss: 1.168442, Accuracy: 601/1050 (57%)

Epoch: 12
Training set [0/6430 (0%)] Loss: 1.041712
Training set [2560/6430 (38%)] Loss: 1.051486
Training set [5120/6430 (77%)] Loss: 1.031535
Training set: Average loss: 1.039014
Training set: Average accuracy: 59.64%
Validation set: Average loss: 1.068395, Accuracy: 671/1050 (64%)

Epoch: 13
Training set [0/6430 (0%)] Loss: 1.115836
Training set [2560/6430 (38%)] Loss: 1.015043
Training set [5120/6430 (77%)] Loss: 1.043916
Training set: Average loss: 1.001433
Training set: Average accuracy: 60.16%
Validation set: Average loss: 1.476456, Accuracy: 569/1050 (54%)

Epoch: 14
Training set [0/6430 (0%)] Loss: 0.971368
Training set [2560/6430 (38%)] Loss: 0.882905
Training set [5120/6430 (77%)] Loss: 0.884930
Training set: Average loss: 0.958281
Training set: Average accuracy: 62.74%
Validation set: Average loss: 0.956839, Accuracy: 672/1050 (64%)

Epoch: 15
Training set [0/6430 (0%)] Loss: 0.927714
Training set [2560/6430 (38%)] Loss: 0.963423
Training set [5120/6430 (77%)] Loss: 0.912837
Training set: Average loss: 0.945173
Training set: Average accuracy: 62.85%
Validation set: Average loss: 2.746888, Accuracy: 393/1050 (37%)

Epoch: 16
Training set [0/6430 (0%)] Loss: 0.997255
Training set [2560/6430 (38%)] Loss: 1.004539
Training set [5120/6430 (77%)] Loss: 0.939968
Training set: Average loss: 0.928951
Training set: Average accuracy: 64.17%
Validation set: Average loss: 0.946105, Accuracy: 711/1050 (68%)

Epoch: 17
Training set [0/6430 (0%)] Loss: 0.795059
Training set [2560/6430 (38%)] Loss: 0.860078
Training set [5120/6430 (77%)] Loss: 0.796831
Training set: Average loss: 0.870436
Training set: Average accuracy: 66.91%
Validation set: Average loss: 0.893808, Accuracy: 713/1050 (68%)

Epoch: 18
Training set [0/6430 (0%)] Loss: 0.820722
Training set [2560/6430 (38%)] Loss: 0.910102
Training set [5120/6430 (77%)] Loss: 0.767455
Training set: Average loss: 0.874008
Training set: Average accuracy: 66.31%
Validation set: Average loss: 0.972324, Accuracy: 747/1050 (71%)

Epoch: 19
Training set [0/6430 (0%)] Loss: 0.864682
Training set [2560/6430 (38%)] Loss: 0.840892
Training set [5120/6430 (77%)] Loss: 0.799268
Training set: Average loss: 0.826282
Training set: Average accuracy: 67.57%
Validation set: Average loss: 0.917229, Accuracy: 710/1050 (68%)

Epoch: 20
Training set [0/6430 (0%)] Loss: 0.724552
Training set [2560/6430 (38%)] Loss: 0.818854
Training set [5120/6430 (77%)] Loss: 0.686733
Training set: Average loss: 0.776456
Training set: Average accuracy: 70.23%
Validation set: Average loss: 1.068469, Accuracy: 692/1050 (66%)

Epoch: 21
Training set [0/6430 (0%)] Loss: 0.808563
Training set [2560/6430 (38%)] Loss: 0.817807
Training set [5120/6430 (77%)] Loss: 0.700717
Training set: Average loss: 0.745699
Training set: Average accuracy: 70.61%
Validation set: Average loss: 1.025033, Accuracy: 646/1050 (62%)

Epoch: 22
Training set [0/6430 (0%)] Loss: 0.811304
Training set [2560/6430 (38%)] Loss: 0.711379
Training set [5120/6430 (77%)] Loss: 0.692448
Training set: Average loss: 0.739733
Training set: Average accuracy: 70.72%
Validation set: Average loss: 1.496306, Accuracy: 653/1050 (62%)

Epoch: 23
Training set [0/6430 (0%)] Loss: 0.757710
Training set [2560/6430 (38%)] Loss: 0.807927
Training set [5120/6430 (77%)] Loss: 0.719339
Training set: Average loss: 0.728640
Training set: Average accuracy: 72.40%
Validation set: Average loss: 2.349597, Accuracy: 531/1050 (51%)

Epoch: 24
Training set [0/6430 (0%)] Loss: 0.748028
Training set [2560/6430 (38%)] Loss: 0.687378
Training set [5120/6430 (77%)] Loss: 0.667138
Training set: Average loss: 0.721938
Training set: Average accuracy: 71.57%
Validation set: Average loss: 0.831353, Accuracy: 761/1050 (72%)

Epoch: 25
Training set [0/6430 (0%)] Loss: 0.724721
Training set [2560/6430 (38%)] Loss: 0.621701
Training set [5120/6430 (77%)] Loss: 0.678896
Training set: Average loss: 0.710491
Training set: Average accuracy: 72.10%
Validation set: Average loss: 0.821748, Accuracy: 770/1050 (73%)

Epoch: 26
Training set [0/6430 (0%)] Loss: 0.592717
Training set [2560/6430 (38%)] Loss: 0.638997
Training set [5120/6430 (77%)] Loss: 0.687299
Training set: Average loss: 0.650199
Training set: Average accuracy: 73.95%
Validation set: Average loss: 0.765630, Accuracy: 774/1050 (74%)

Epoch: 27
Training set [0/6430 (0%)] Loss: 0.596069
Training set [2560/6430 (38%)] Loss: 0.634581
Training set [5120/6430 (77%)] Loss: 0.761650
Training set: Average loss: 0.642135
Training set: Average accuracy: 74.56%
Validation set: Average loss: 0.809284, Accuracy: 773/1050 (74%)

Epoch: 28
Training set [0/6430 (0%)] Loss: 0.557983
Training set [2560/6430 (38%)] Loss: 0.712220
Training set [5120/6430 (77%)] Loss: 0.578794
Training set: Average loss: 0.637466
Training set: Average accuracy: 75.01%
Validation set: Average loss: 0.842058, Accuracy: 779/1050 (74%)

Epoch: 29
Training set [0/6430 (0%)] Loss: 0.649572
Training set [2560/6430 (38%)] Loss: 0.609099
Training set [5120/6430 (77%)] Loss: 0.590912
Training set: Average loss: 0.631180
Training set: Average accuracy: 75.41%
Validation set: Average loss: 0.751738, Accuracy: 789/1050 (75%)

Epoch: 30
Training set [0/6430 (0%)] Loss: 0.621297
Training set [2560/6430 (38%)] Loss: 0.584600
Training set [5120/6430 (77%)] Loss: 0.515822
Training set: Average loss: 0.620589
Training set: Average accuracy: 75.51%
Validation set: Average loss: 0.929905, Accuracy: 761/1050 (72%)

Epoch: 31
Training set [0/6430 (0%)] Loss: 0.580612
Training set [2560/6430 (38%)] Loss: 0.570599
Training set [5120/6430 (77%)] Loss: 0.585560
Training set: Average loss: 0.584638
Training set: Average accuracy: 77.60%
Validation set: Average loss: 0.782396, Accuracy: 766/1050 (73%)

Epoch: 32
Training set [0/6430 (0%)] Loss: 0.566998
Training set [2560/6430 (38%)] Loss: 0.633292
Training set [5120/6430 (77%)] Loss: 0.586653
Training set: Average loss: 0.576118
Training set: Average accuracy: 77.87%
Validation set: Average loss: 0.763518, Accuracy: 777/1050 (74%)

Epoch: 33
Training set [0/6430 (0%)] Loss: 0.557884
Training set [2560/6430 (38%)] Loss: 0.532391
Training set [5120/6430 (77%)] Loss: 0.610464
Training set: Average loss: 0.545634
Training set: Average accuracy: 78.55%
Validation set: Average loss: 1.006423, Accuracy: 714/1050 (68%)

Epoch: 34
Training set [0/6430 (0%)] Loss: 0.484715
Training set [2560/6430 (38%)] Loss: 0.538555
Training set [5120/6430 (77%)] Loss: 0.622138
Training set: Average loss: 0.540462
Training set: Average accuracy: 78.60%
Validation set: Average loss: 0.788985, Accuracy: 801/1050 (76%)

Epoch: 35
Training set [0/6430 (0%)] Loss: 0.466996
Training set [2560/6430 (38%)] Loss: 0.561218
Training set [5120/6430 (77%)] Loss: 0.440712
Training set: Average loss: 0.532106
Training set: Average accuracy: 79.64%
Validation set: Average loss: 0.786476, Accuracy: 788/1050 (75%)

Epoch: 36
Training set [0/6430 (0%)] Loss: 0.534337
Training set [2560/6430 (38%)] Loss: 0.608749
Training set [5120/6430 (77%)] Loss: 0.475119
Training set: Average loss: 0.535259
Training set: Average accuracy: 79.11%
Validation set: Average loss: 0.722972, Accuracy: 803/1050 (76%)

Epoch: 37
Training set [0/6430 (0%)] Loss: 0.535205
Training set [2560/6430 (38%)] Loss: 0.448292
Training set [5120/6430 (77%)] Loss: 0.465077
Training set: Average loss: 0.504050
Training set: Average accuracy: 80.34%
Validation set: Average loss: 0.856553, Accuracy: 798/1050 (76%)

Epoch: 38
Training set [0/6430 (0%)] Loss: 0.451979
Training set [2560/6430 (38%)] Loss: 0.515516
Training set [5120/6430 (77%)] Loss: 0.517979
Training set: Average loss: 0.525330
Training set: Average accuracy: 79.11%
Validation set: Average loss: 0.844795, Accuracy: 758/1050 (72%)

Epoch: 39
Training set [0/6430 (0%)] Loss: 0.467495
Training set [2560/6430 (38%)] Loss: 0.521430
Training set [5120/6430 (77%)] Loss: 0.485622
Training set: Average loss: 0.514589
Training set: Average accuracy: 79.39%
Validation set: Average loss: 0.995190, Accuracy: 746/1050 (71%)

Epoch: 40
Training set [0/6430 (0%)] Loss: 0.442103
Training set [2560/6430 (38%)] Loss: 0.495821
Training set [5120/6430 (77%)] Loss: 0.508889
Training set: Average loss: 0.464140
Training set: Average accuracy: 81.93%
Validation set: Average loss: 0.748646, Accuracy: 811/1050 (77%)

Epoch: 41
Training set [0/6430 (0%)] Loss: 0.544363
Training set [2560/6430 (38%)] Loss: 0.591242
Training set [5120/6430 (77%)] Loss: 0.414052
Training set: Average loss: 0.479154
Training set: Average accuracy: 81.32%
Validation set: Average loss: 0.835127, Accuracy: 796/1050 (76%)

Epoch: 42
Training set [0/6430 (0%)] Loss: 0.561052
Training set [2560/6430 (38%)] Loss: 0.484016
Training set [5120/6430 (77%)] Loss: 0.521097
Training set: Average loss: 0.505116
Training set: Average accuracy: 80.81%
Validation set: Average loss: 1.535897, Accuracy: 697/1050 (66%)

Epoch: 43
Training set [0/6430 (0%)] Loss: 0.427927
Training set [2560/6430 (38%)] Loss: 0.479778
Training set [5120/6430 (77%)] Loss: 0.460566
Training set: Average loss: 0.468327
Training set: Average accuracy: 81.85%
Validation set: Average loss: 1.009595, Accuracy: 746/1050 (71%)

Epoch: 44
Training set [0/6430 (0%)] Loss: 0.476577
Training set [2560/6430 (38%)] Loss: 0.477822
Training set [5120/6430 (77%)] Loss: 0.426832
Training set: Average loss: 0.460481
Training set: Average accuracy: 82.29%
Validation set: Average loss: 0.891178, Accuracy: 779/1050 (74%)

Epoch: 45
Training set [0/6430 (0%)] Loss: 0.499354
Training set [2560/6430 (38%)] Loss: 0.377901
Training set [5120/6430 (77%)] Loss: 0.416419
Training set: Average loss: 0.429997
Training set: Average accuracy: 83.22%
Validation set: Average loss: 0.874303, Accuracy: 775/1050 (74%)

Epoch: 46
Training set [0/6430 (0%)] Loss: 0.352942
Training set [2560/6430 (38%)] Loss: 0.390874
Training set [5120/6430 (77%)] Loss: 0.472751
Training set: Average loss: 0.402579
Training set: Average accuracy: 84.20%
Validation set: Average loss: 0.758135, Accuracy: 814/1050 (78%)

Epoch: 47
Training set [0/6430 (0%)] Loss: 0.419882
Training set [2560/6430 (38%)] Loss: 0.468711
Training set [5120/6430 (77%)] Loss: 0.427501
Training set: Average loss: 0.432796
Training set: Average accuracy: 83.00%
Validation set: Average loss: 0.796921, Accuracy: 810/1050 (77%)

Epoch: 48
Training set [0/6430 (0%)] Loss: 0.372827
Training set [2560/6430 (38%)] Loss: 0.405911
Training set [5120/6430 (77%)] Loss: 0.381744
Training set: Average loss: 0.412733
Training set: Average accuracy: 84.03%
Validation set: Average loss: 0.738569, Accuracy: 833/1050 (79%)

Epoch: 49
Training set [0/6430 (0%)] Loss: 0.414463
Training set [2560/6430 (38%)] Loss: 0.467247
Training set [5120/6430 (77%)] Loss: 0.373170
Training set: Average loss: 0.432200
Training set: Average accuracy: 82.99%
Validation set: Average loss: 0.807056, Accuracy: 815/1050 (78%)

Epoch: 50
Training set [0/6430 (0%)] Loss: 0.388276
Training set [2560/6430 (38%)] Loss: 0.324245
Training set [5120/6430 (77%)] Loss: 0.348818
Training set: Average loss: 0.416758
Training set: Average accuracy: 84.12%
Validation set: Average loss: 1.163682, Accuracy: 747/1050 (71%)

Epoch: 51
Training set [0/6430 (0%)] Loss: 0.477690
Training set [2560/6430 (38%)] Loss: 0.458528
Training set [5120/6430 (77%)] Loss: 0.293506
Training set: Average loss: 0.422050
Training set: Average accuracy: 83.95%
Validation set: Average loss: 0.788396, Accuracy: 819/1050 (78%)

Epoch: 52
Training set [0/6430 (0%)] Loss: 0.508921
Training set [2560/6430 (38%)] Loss: 0.466016
Training set [5120/6430 (77%)] Loss: 0.459720
Training set: Average loss: 0.405456
Training set: Average accuracy: 83.83%
Validation set: Average loss: 0.693475, Accuracy: 837/1050 (80%)

Epoch: 53
Training set [0/6430 (0%)] Loss: 0.379372
Training set [2560/6430 (38%)] Loss: 0.385806
Training set [5120/6430 (77%)] Loss: 0.315585
Training set: Average loss: 0.412401
Training set: Average accuracy: 84.07%
Validation set: Average loss: 0.803800, Accuracy: 824/1050 (78%)

Epoch: 54
Training set [0/6430 (0%)] Loss: 0.453605
Training set [2560/6430 (38%)] Loss: 0.337650
Training set [5120/6430 (77%)] Loss: 0.351645
Training set: Average loss: 0.372095
Training set: Average accuracy: 85.43%
Validation set: Average loss: 0.919999, Accuracy: 786/1050 (75%)

Epoch: 55
Training set [0/6430 (0%)] Loss: 0.384503
Training set [2560/6430 (38%)] Loss: 0.339797
Training set [5120/6430 (77%)] Loss: 0.360578
Training set: Average loss: 0.365316
Training set: Average accuracy: 85.41%
Validation set: Average loss: 0.903168, Accuracy: 771/1050 (73%)

Epoch: 56
Training set [0/6430 (0%)] Loss: 0.292122
Training set [2560/6430 (38%)] Loss: 0.370331
Training set [5120/6430 (77%)] Loss: 0.327041
Training set: Average loss: 0.355135
Training set: Average accuracy: 85.55%
Validation set: Average loss: 0.896262, Accuracy: 810/1050 (77%)

Epoch: 57
Training set [0/6430 (0%)] Loss: 0.367000
Training set [2560/6430 (38%)] Loss: 0.367043
Training set [5120/6430 (77%)] Loss: 0.332446
Training set: Average loss: 0.369532
Training set: Average accuracy: 85.57%
Validation set: Average loss: 0.783824, Accuracy: 822/1050 (78%)

Epoch: 58
Training set [0/6430 (0%)] Loss: 0.336187
Training set [2560/6430 (38%)] Loss: 0.368233
Training set [5120/6430 (77%)] Loss: 0.328238
Training set: Average loss: 0.382006
Training set: Average accuracy: 84.98%
Validation set: Average loss: 0.826758, Accuracy: 824/1050 (78%)

Epoch: 59
Training set [0/6430 (0%)] Loss: 0.324836
Training set [2560/6430 (38%)] Loss: 0.365708
Training set [5120/6430 (77%)] Loss: 0.424861
Training set: Average loss: 0.358434
Training set: Average accuracy: 86.35%
Validation set: Average loss: 0.849287, Accuracy: 808/1050 (77%)

Epoch: 60
Training set [0/6430 (0%)] Loss: 0.308772
Training set [2560/6430 (38%)] Loss: 0.415495
Training set [5120/6430 (77%)] Loss: 0.316794
Training set: Average loss: 0.395727
Training set: Average accuracy: 84.65%
Validation set: Average loss: 0.812812, Accuracy: 823/1050 (78%)

Epoch: 61
Training set [0/6430 (0%)] Loss: 0.285699
Training set [2560/6430 (38%)] Loss: 0.366334
Training set [5120/6430 (77%)] Loss: 0.307976
Training set: Average loss: 0.361400
Training set: Average accuracy: 85.58%
Validation set: Average loss: 0.733641, Accuracy: 825/1050 (79%)

Epoch: 62
Training set [0/6430 (0%)] Loss: 0.325273
Training set [2560/6430 (38%)] Loss: 0.244387
Training set [5120/6430 (77%)] Loss: 0.290564
Training set: Average loss: 0.351595
Training set: Average accuracy: 86.66%
Validation set: Average loss: 0.835133, Accuracy: 811/1050 (77%)

Epoch: 63
Training set [0/6430 (0%)] Loss: 0.314623
Training set [2560/6430 (38%)] Loss: 0.374332
Training set [5120/6430 (77%)] Loss: 0.412478
Training set: Average loss: 0.365737
Training set: Average accuracy: 86.11%
Validation set: Average loss: 0.699658, Accuracy: 818/1050 (78%)

Epoch: 64
Training set [0/6430 (0%)] Loss: 0.236958
Training set [2560/6430 (38%)] Loss: 0.385388
Training set [5120/6430 (77%)] Loss: 0.299600
Training set: Average loss: 0.353793
Training set: Average accuracy: 86.33%
Validation set: Average loss: 0.719664, Accuracy: 830/1050 (79%)

Epoch: 65
Training set [0/6430 (0%)] Loss: 0.380390
Training set [2560/6430 (38%)] Loss: 0.309912
Training set [5120/6430 (77%)] Loss: 0.296623
Training set: Average loss: 0.329983
Training set: Average accuracy: 87.06%
Validation set: Average loss: 0.753448, Accuracy: 830/1050 (79%)

Epoch: 66
Training set [0/6430 (0%)] Loss: 0.292717
Training set [2560/6430 (38%)] Loss: 0.285933
Training set [5120/6430 (77%)] Loss: 0.308231
Training set: Average loss: 0.316588
Training set: Average accuracy: 87.56%
Validation set: Average loss: 0.796232, Accuracy: 815/1050 (78%)

Epoch: 67
Training set [0/6430 (0%)] Loss: 0.318189
Training set [2560/6430 (38%)] Loss: 0.295749
Training set [5120/6430 (77%)] Loss: 0.281244
Training set: Average loss: 0.305881
Training set: Average accuracy: 88.12%
Validation set: Average loss: 0.809294, Accuracy: 833/1050 (79%)

Epoch: 68
Training set [0/6430 (0%)] Loss: 0.273497
Training set [2560/6430 (38%)] Loss: 0.381184
Training set [5120/6430 (77%)] Loss: 0.408596
Training set: Average loss: 0.341057
Training set: Average accuracy: 86.28%
Validation set: Average loss: 0.796539, Accuracy: 802/1050 (76%)

Epoch: 69
Training set [0/6430 (0%)] Loss: 0.321606
Training set [2560/6430 (38%)] Loss: 0.390560
Training set [5120/6430 (77%)] Loss: 0.298280
Training set: Average loss: 0.331901
Training set: Average accuracy: 87.64%
Validation set: Average loss: 0.719304, Accuracy: 840/1050 (80%)

Epoch: 70
Training set [0/6430 (0%)] Loss: 0.341399
Training set [2560/6430 (38%)] Loss: 0.300050
Training set [5120/6430 (77%)] Loss: 0.365101
Training set: Average loss: 0.356349
Training set: Average accuracy: 86.19%
Validation set: Average loss: 0.773533, Accuracy: 850/1050 (81%)

Epoch: 71
Training set [0/6430 (0%)] Loss: 0.325875
Training set [2560/6430 (38%)] Loss: 0.268566
Training set [5120/6430 (77%)] Loss: 0.318919
Training set: Average loss: 0.315036
Training set: Average accuracy: 87.56%
Validation set: Average loss: 0.863431, Accuracy: 814/1050 (78%)

Epoch: 72
Training set [0/6430 (0%)] Loss: 0.240260
Training set [2560/6430 (38%)] Loss: 0.432661
Training set [5120/6430 (77%)] Loss: 0.323860
Training set: Average loss: 0.300507
Training set: Average accuracy: 88.30%
Validation set: Average loss: 0.800617, Accuracy: 829/1050 (79%)

Epoch: 73
Training set [0/6430 (0%)] Loss: 0.272640
Training set [2560/6430 (38%)] Loss: 0.349248
Training set [5120/6430 (77%)] Loss: 0.363089
Training set: Average loss: 0.305602
Training set: Average accuracy: 88.24%
Validation set: Average loss: 0.743499, Accuracy: 823/1050 (78%)

Epoch: 74
Training set [0/6430 (0%)] Loss: 0.288312
Training set [2560/6430 (38%)] Loss: 0.321726
Training set [5120/6430 (77%)] Loss: 0.317605
Training set: Average loss: 0.293659
Training set: Average accuracy: 87.93%
Validation set: Average loss: 0.811801, Accuracy: 816/1050 (78%)

Epoch: 75
Training set [0/6430 (0%)] Loss: 0.271312
Training set [2560/6430 (38%)] Loss: 0.262763
Training set [5120/6430 (77%)] Loss: 0.232294
Training set: Average loss: 0.297982
Training set: Average accuracy: 88.13%
Validation set: Average loss: 0.810646, Accuracy: 809/1050 (77%)

Epoch: 76
Training set [0/6430 (0%)] Loss: 0.368688
Training set [2560/6430 (38%)] Loss: 0.357391
Training set [5120/6430 (77%)] Loss: 0.296230
Training set: Average loss: 0.305611
Training set: Average accuracy: 87.73%
Validation set: Average loss: 0.751858, Accuracy: 845/1050 (80%)

Epoch: 77
Training set [0/6430 (0%)] Loss: 0.307051
Training set [2560/6430 (38%)] Loss: 0.270326
Training set [5120/6430 (77%)] Loss: 0.253895
Training set: Average loss: 0.288302
Training set: Average accuracy: 88.66%
Validation set: Average loss: 0.725240, Accuracy: 853/1050 (81%)

Epoch: 78
Training set [0/6430 (0%)] Loss: 0.288304
Training set [2560/6430 (38%)] Loss: 0.273077
Training set [5120/6430 (77%)] Loss: 0.300609
Training set: Average loss: 0.267939
Training set: Average accuracy: 89.39%
Validation set: Average loss: 0.953836, Accuracy: 834/1050 (79%)

Epoch: 79
Training set [0/6430 (0%)] Loss: 0.245782
Training set [2560/6430 (38%)] Loss: 0.275653
Training set [5120/6430 (77%)] Loss: 0.260337
Training set: Average loss: 0.267960
Training set: Average accuracy: 89.11%
Validation set: Average loss: 0.882046, Accuracy: 813/1050 (77%)

Epoch: 80
Training set [0/6430 (0%)] Loss: 0.302839
Training set [2560/6430 (38%)] Loss: 0.305239
Training set [5120/6430 (77%)] Loss: 0.202566
Training set: Average loss: 0.249063
Training set: Average accuracy: 90.17%
Validation set: Average loss: 0.817466, Accuracy: 851/1050 (81%)

Epoch: 81
Training set [0/6430 (0%)] Loss: 0.207632
Training set [2560/6430 (38%)] Loss: 0.229728
Training set [5120/6430 (77%)] Loss: 0.248061
Training set: Average loss: 0.259806
Training set: Average accuracy: 89.66%
Validation set: Average loss: 0.795626, Accuracy: 826/1050 (79%)

Epoch: 82
Training set [0/6430 (0%)] Loss: 0.270677
Training set [2560/6430 (38%)] Loss: 0.244161
Training set [5120/6430 (77%)] Loss: 0.228522
Training set: Average loss: 0.254716
Training set: Average accuracy: 89.36%
Validation set: Average loss: 0.848188, Accuracy: 840/1050 (80%)

Epoch: 83
Training set [0/6430 (0%)] Loss: 0.269223
Training set [2560/6430 (38%)] Loss: 0.243289
Training set [5120/6430 (77%)] Loss: 0.278116
Training set: Average loss: 0.258154
Training set: Average accuracy: 89.28%
Validation set: Average loss: 0.746987, Accuracy: 864/1050 (82%)

Epoch: 84
Training set [0/6430 (0%)] Loss: 0.241899
Training set [2560/6430 (38%)] Loss: 0.232222
Training set [5120/6430 (77%)] Loss: 0.236323
Training set: Average loss: 0.256908
Training set: Average accuracy: 89.60%
Validation set: Average loss: 0.750046, Accuracy: 855/1050 (81%)

Epoch: 85
Training set [0/6430 (0%)] Loss: 0.189313
Training set [2560/6430 (38%)] Loss: 0.303868
Training set [5120/6430 (77%)] Loss: 0.239772
Training set: Average loss: 0.274837
Training set: Average accuracy: 89.18%
Validation set: Average loss: 0.790884, Accuracy: 836/1050 (80%)

Epoch: 86
Training set [0/6430 (0%)] Loss: 0.195421
Training set [2560/6430 (38%)] Loss: 0.285717
Training set [5120/6430 (77%)] Loss: 0.303206
Training set: Average loss: 0.257814
Training set: Average accuracy: 89.56%
Validation set: Average loss: 0.819519, Accuracy: 856/1050 (82%)

Epoch: 87
Training set [0/6430 (0%)] Loss: 0.288241
Training set [2560/6430 (38%)] Loss: 0.178175
Training set [5120/6430 (77%)] Loss: 0.240262
Training set: Average loss: 0.241838
Training set: Average accuracy: 90.22%
Validation set: Average loss: 1.002589, Accuracy: 834/1050 (79%)

Epoch: 88
Training set [0/6430 (0%)] Loss: 0.193152
Training set [2560/6430 (38%)] Loss: 0.205954
Training set [5120/6430 (77%)] Loss: 0.191628
Training set: Average loss: 0.250325
Training set: Average accuracy: 90.37%
Validation set: Average loss: 0.901318, Accuracy: 819/1050 (78%)

Epoch: 89
Training set [0/6430 (0%)] Loss: 0.291813
Training set [2560/6430 (38%)] Loss: 0.198728
Training set [5120/6430 (77%)] Loss: 0.259476
Training set: Average loss: 0.248511
Training set: Average accuracy: 90.47%
Validation set: Average loss: 1.077083, Accuracy: 828/1050 (79%)

Epoch: 90
Training set [0/6430 (0%)] Loss: 0.247150
Training set [2560/6430 (38%)] Loss: 0.302844
Training set [5120/6430 (77%)] Loss: 0.264597
Training set: Average loss: 0.278212
Training set: Average accuracy: 89.18%
Validation set: Average loss: 0.819757, Accuracy: 839/1050 (80%)

Epoch: 91
Training set [0/6430 (0%)] Loss: 0.299748
Training set [2560/6430 (38%)] Loss: 0.300803
Training set [5120/6430 (77%)] Loss: 0.217641
Training set: Average loss: 0.273409
Training set: Average accuracy: 89.63%
Validation set: Average loss: 0.865370, Accuracy: 837/1050 (80%)

Epoch: 92
Training set [0/6430 (0%)] Loss: 0.244775
Training set [2560/6430 (38%)] Loss: 0.184912
Training set [5120/6430 (77%)] Loss: 0.264767
Training set: Average loss: 0.275642
Training set: Average accuracy: 89.91%
Validation set: Average loss: 0.761812, Accuracy: 850/1050 (81%)

Epoch: 93
Training set [0/6430 (0%)] Loss: 0.265788
Training set [2560/6430 (38%)] Loss: 0.318798
Training set [5120/6430 (77%)] Loss: 0.287394
Training set: Average loss: 0.300388
Training set: Average accuracy: 88.51%
Validation set: Average loss: 0.891325, Accuracy: 817/1050 (78%)

Epoch: 94
Training set [0/6430 (0%)] Loss: 0.307416
Training set [2560/6430 (38%)] Loss: 0.324101
Training set [5120/6430 (77%)] Loss: 0.405293
Training set: Average loss: 0.343125
Training set: Average accuracy: 87.22%
Validation set: Average loss: 0.966012, Accuracy: 804/1050 (77%)

Epoch: 95
Training set [0/6430 (0%)] Loss: 0.313937
Training set [2560/6430 (38%)] Loss: 0.366389
Training set [5120/6430 (77%)] Loss: 0.372704
Training set: Average loss: 0.295132
Training set: Average accuracy: 88.57%
Validation set: Average loss: 0.726529, Accuracy: 836/1050 (80%)

Epoch: 96
Training set [0/6430 (0%)] Loss: 0.251997
Training set [2560/6430 (38%)] Loss: 0.191177
Training set [5120/6430 (77%)] Loss: 0.179151
Training set: Average loss: 0.264143
Training set: Average accuracy: 89.91%
Validation set: Average loss: 0.761600, Accuracy: 837/1050 (80%)

Epoch: 97
Training set [0/6430 (0%)] Loss: 0.197413
Training set [2560/6430 (38%)] Loss: 0.219769
Training set [5120/6430 (77%)] Loss: 0.238308
Training set: Average loss: 0.238091
Training set: Average accuracy: 90.42%
Validation set: Average loss: 1.293464, Accuracy: 775/1050 (74%)

Epoch: 98
Training set [0/6430 (0%)] Loss: 0.219608
Training set [2560/6430 (38%)] Loss: 0.165355
Training set [5120/6430 (77%)] Loss: 0.244006
Training set: Average loss: 0.231396
Training set: Average accuracy: 90.96%
Validation set: Average loss: 0.926250, Accuracy: 816/1050 (78%)

Epoch: 99
Training set [0/6430 (0%)] Loss: 0.215993
Training set [2560/6430 (38%)] Loss: 0.296306
Training set [5120/6430 (77%)] Loss: 0.297433
Training set: Average loss: 0.249299
Training set: Average accuracy: 90.48%
Validation set: Average loss: 0.790185, Accuracy: 842/1050 (80%)

Epoch: 100
Training set [0/6430 (0%)] Loss: 0.223518
Training set [2560/6430 (38%)] Loss: 0.283814
Training set [5120/6430 (77%)] Loss: 0.216493
Training set: Average loss: 0.253859
Training set: Average accuracy: 89.69%
Validation set: Average loss: 3.725994, Accuracy: 571/1050 (54%)

Epoch: 101
Training set [0/6430 (0%)] Loss: 0.229148
Training set [2560/6430 (38%)] Loss: 0.210111
Training set [5120/6430 (77%)] Loss: 0.255228
Training set: Average loss: 0.223811
Training set: Average accuracy: 91.79%
Validation set: Average loss: 0.821535, Accuracy: 848/1050 (81%)

Epoch: 102
Training set [0/6430 (0%)] Loss: 0.241551
Training set [2560/6430 (38%)] Loss: 0.235667
Training set [5120/6430 (77%)] Loss: 0.176353
Training set: Average loss: 0.246014
Training set: Average accuracy: 89.98%
Validation set: Average loss: 1.089569, Accuracy: 798/1050 (76%)

Epoch: 103
Training set [0/6430 (0%)] Loss: 0.241238
Training set [2560/6430 (38%)] Loss: 0.230262
Training set [5120/6430 (77%)] Loss: 0.255662
Training set: Average loss: 0.217109
Training set: Average accuracy: 91.20%
Validation set: Average loss: 0.837655, Accuracy: 835/1050 (80%)

Epoch: 104
Training set [0/6430 (0%)] Loss: 0.232489
Training set [2560/6430 (38%)] Loss: 0.177992
Training set [5120/6430 (77%)] Loss: 0.215911
Training set: Average loss: 0.235834
Training set: Average accuracy: 90.67%
Validation set: Average loss: 0.823105, Accuracy: 833/1050 (79%)

Epoch: 105
Training set [0/6430 (0%)] Loss: 0.229516
Training set [2560/6430 (38%)] Loss: 0.256877
Training set [5120/6430 (77%)] Loss: 0.223816
Training set: Average loss: 0.230013
Training set: Average accuracy: 90.92%
Validation set: Average loss: 0.716643, Accuracy: 848/1050 (81%)

Epoch: 106
Training set [0/6430 (0%)] Loss: 0.207749
Training set [2560/6430 (38%)] Loss: 0.208199
Training set [5120/6430 (77%)] Loss: 0.246785
Training set: Average loss: 0.231849
Training set: Average accuracy: 91.04%
Validation set: Average loss: 1.243726, Accuracy: 811/1050 (77%)

Epoch: 107
Training set [0/6430 (0%)] Loss: 0.201548
Training set [2560/6430 (38%)] Loss: 0.235521
Training set [5120/6430 (77%)] Loss: 0.259506
Training set: Average loss: 0.224978
Training set: Average accuracy: 90.82%
Validation set: Average loss: 0.841407, Accuracy: 840/1050 (80%)

Epoch: 108
Training set [0/6430 (0%)] Loss: 0.221820
Training set [2560/6430 (38%)] Loss: 0.251546
Training set [5120/6430 (77%)] Loss: 0.243070
Training set: Average loss: 0.240585
Training set: Average accuracy: 90.37%
Validation set: Average loss: 0.942820, Accuracy: 828/1050 (79%)

Epoch: 109
Training set [0/6430 (0%)] Loss: 0.190455
Training set [2560/6430 (38%)] Loss: 0.235776
Training set [5120/6430 (77%)] Loss: 0.202411
Training set: Average loss: 0.221537
Training set: Average accuracy: 91.29%
Validation set: Average loss: 0.769397, Accuracy: 842/1050 (80%)

Epoch: 110
Training set [0/6430 (0%)] Loss: 0.174884
Training set [2560/6430 (38%)] Loss: 0.270909
Training set [5120/6430 (77%)] Loss: 0.250817
Training set: Average loss: 0.217059
Training set: Average accuracy: 91.38%
Validation set: Average loss: 0.843482, Accuracy: 858/1050 (82%)

Epoch: 111
Training set [0/6430 (0%)] Loss: 0.182749
Training set [2560/6430 (38%)] Loss: 0.177271
Training set [5120/6430 (77%)] Loss: 0.199437
Training set: Average loss: 0.213784
Training set: Average accuracy: 91.37%
Validation set: Average loss: 0.802676, Accuracy: 848/1050 (81%)

Epoch: 112
Training set [0/6430 (0%)] Loss: 0.190019
Training set [2560/6430 (38%)] Loss: 0.248412
Training set [5120/6430 (77%)] Loss: 0.178769
Training set: Average loss: 0.218578
Training set: Average accuracy: 91.31%
Validation set: Average loss: 1.459634, Accuracy: 775/1050 (74%)

Epoch: 113
Training set [0/6430 (0%)] Loss: 0.268147
Training set [2560/6430 (38%)] Loss: 0.196274
Training set [5120/6430 (77%)] Loss: 0.194462
Training set: Average loss: 0.212079
Training set: Average accuracy: 91.84%
Validation set: Average loss: 0.777747, Accuracy: 858/1050 (82%)

Epoch: 114
Training set [0/6430 (0%)] Loss: 0.258985
Training set [2560/6430 (38%)] Loss: 0.233692
Training set [5120/6430 (77%)] Loss: 0.222340
Training set: Average loss: 0.212702
Training set: Average accuracy: 91.54%
Validation set: Average loss: 0.875690, Accuracy: 848/1050 (81%)

Epoch: 115
Training set [0/6430 (0%)] Loss: 0.194331
Training set [2560/6430 (38%)] Loss: 0.182998
Training set [5120/6430 (77%)] Loss: 0.256217
Training set: Average loss: 0.220605
Training set: Average accuracy: 90.93%
Validation set: Average loss: 0.922564, Accuracy: 836/1050 (80%)

Epoch: 116
Training set [0/6430 (0%)] Loss: 0.163855
Training set [2560/6430 (38%)] Loss: 0.214277
Training set [5120/6430 (77%)] Loss: 0.181074
Training set: Average loss: 0.216323
Training set: Average accuracy: 92.10%
Validation set: Average loss: 0.934767, Accuracy: 846/1050 (81%)

Epoch: 117
Training set [0/6430 (0%)] Loss: 0.153499
Training set [2560/6430 (38%)] Loss: 0.281592
Training set [5120/6430 (77%)] Loss: 0.299357
Training set: Average loss: 0.299968
Training set: Average accuracy: 89.16%
Validation set: Average loss: 0.876485, Accuracy: 845/1050 (80%)

Epoch: 118
Training set [0/6430 (0%)] Loss: 0.288837
Training set [2560/6430 (38%)] Loss: 0.214264
Training set [5120/6430 (77%)] Loss: 0.221394
Training set: Average loss: 0.251844
Training set: Average accuracy: 90.36%
Validation set: Average loss: 0.770794, Accuracy: 881/1050 (84%)

Epoch: 119
Training set [0/6430 (0%)] Loss: 0.248399
Training set [2560/6430 (38%)] Loss: 0.224863
Training set [5120/6430 (77%)] Loss: 0.174152
Training set: Average loss: 0.218656
Training set: Average accuracy: 91.34%
Validation set: Average loss: 1.419992, Accuracy: 779/1050 (74%)

Epoch: 120
Training set [0/6430 (0%)] Loss: 0.135582
Training set [2560/6430 (38%)] Loss: 0.236045
Training set [5120/6430 (77%)] Loss: 0.206616
Training set: Average loss: 0.213608
Training set: Average accuracy: 91.54%
Validation set: Average loss: 0.972424, Accuracy: 816/1050 (78%)

Epoch: 121
Training set [0/6430 (0%)] Loss: 0.104496
Training set [2560/6430 (38%)] Loss: 0.236474
Training set [5120/6430 (77%)] Loss: 0.207759
Training set: Average loss: 0.222659
Training set: Average accuracy: 91.09%
Validation set: Average loss: 0.718807, Accuracy: 863/1050 (82%)

Epoch: 122
Training set [0/6430 (0%)] Loss: 0.147174
Training set [2560/6430 (38%)] Loss: 0.218259
Training set [5120/6430 (77%)] Loss: 0.232194
Training set: Average loss: 0.212547
Training set: Average accuracy: 91.66%
Validation set: Average loss: 0.915726, Accuracy: 851/1050 (81%)

Epoch: 123
Training set [0/6430 (0%)] Loss: 0.176391
Training set [2560/6430 (38%)] Loss: 0.213394
Training set [5120/6430 (77%)] Loss: 0.261303
Training set: Average loss: 0.225488
Training set: Average accuracy: 91.88%
Validation set: Average loss: 0.791525, Accuracy: 849/1050 (81%)

Early stopping: no improvement for 10 epochs
BasicNet
training_loss -- validation_loss
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123]
[2.4612807631492615, 1.7990360168310313, 1.7420877630894, 1.6394731860894423, 1.573849760569059, 1.4795136451721191, 1.4024962920408983, 1.3291459037707403, 1.2697435388198266, 1.2074663776617784, 1.1462256083121667, 1.1094017441456134, 1.0390135324918306, 1.0014328956604004, 0.9582811227211585, 0.9451734102689303, 0.9289511488034174, 0.8704355175678546, 0.8740077775258285, 0.8262821435928345, 0.7764562024519994, 0.7456994985158627, 0.739733113692357, 0.7286404692209684, 0.7219383670733526, 0.7104909832660968, 0.6501989227074844, 0.6421346526879531, 0.6374661372258112, 0.6311799253408725, 0.6205893754959106, 0.5846382448306451, 0.5761181528751667, 0.5456342995166779, 0.5404622497466894, 0.5321064511170754, 0.5352592663123057, 0.5040497619372147, 0.5253304690122604, 0.5145893566883527, 0.4641396999359131, 0.47915391394725215, 0.5051155124719326, 0.4683274936217528, 0.4604808734013484, 0.42999668648609746, 0.4025788043554013, 0.43279565985386187, 0.4127331582399515, 0.4322002816658754, 0.4167581189137239, 0.4220504267857625, 0.40545568099388707, 0.41240096436097073, 0.37209458076036894, 0.3653164987380688, 0.3551348184163754, 0.3695322573184967, 0.3820064446100822, 0.3584344054643924, 0.39572679881866163, 0.3613995640323712, 0.35159481546053517, 0.3657366495866042, 0.35379327088594437, 0.329982653260231, 0.31658759541236436, 0.3058806789609102, 0.341056873018925, 0.33190073187534624, 0.3563488996945895, 0.3150359455209512, 0.30050661300237363, 0.3056020811200142, 0.2936587224786098, 0.29798209094084227, 0.3056114533772835, 0.2883024737238884, 0.2679393102343266, 0.2679601007929215, 0.2490626573562622, 0.2598055944992946, 0.2547157464119104, 0.25815414981200147, 0.2569078132510185, 0.2748370268023931, 0.2578142164991452, 0.24183751700016168, 0.25032541442375916, 0.24851115907614046, 0.2782118824812082, 0.27340866052187407, 0.275642125079265, 0.3003880576445506, 0.34312538917248064, 0.29513176530599594, 0.2641425041052011, 0.2380910120331324, 0.23139591343127763, 0.24929938809229776, 0.2538594271127994, 0.22381149347011858, 0.24601370554703933, 0.2171088233590126, 0.2358336580487398, 0.23001277504058984, 0.23184886058935752, 0.2249784260415114, 0.24058475918494737, 0.2215368810754556, 0.21705858638653389, 0.21378400406012169, 0.21857844866239107, 0.21207897995526975, 0.21270220153606856, 0.22060541006234977, 0.21632306277751923, 0.299968442091575, 0.25184421241283417, 0.21865610950268233, 0.21360828440922958, 0.222658656250972, 0.21254656406549308, 0.22548796293827203]
[1.8729854106903077, 1.7881426572799684, 1.7264395713806153, 1.6312802314758301, 1.5012712478637695, 1.4624666690826416, 1.3821646451950074, 1.2727248907089233, 1.2058573007583617, 1.6398216962814331, 3.8744879722595216, 1.1684417247772216, 1.0683954358100891, 1.4764555454254151, 0.95683913230896, 2.746888017654419, 0.9461054325103759, 0.8938082337379456, 0.9723244905471802, 0.917228615283966, 1.068469262123108, 1.0250330328941346, 1.4963057041168213, 2.3495967864990233, 0.831353235244751, 0.8217479109764099, 0.7656298160552979, 0.8092836201190948, 0.8420575022697449, 0.7517384141683578, 0.9299046635627747, 0.7823956251144409, 0.7635176777839661, 1.0064231157302856, 0.7889851570129395, 0.7864755868911744, 0.7229720950126648, 0.8565525323152542, 0.8447946608066559, 0.9951903998851777, 0.7486462235450745, 0.8351274609565735, 1.5358970165252686, 1.0095950603485107, 0.8911776006221771, 0.874303363263607, 0.7581351310014725, 0.7969206213951111, 0.7385685324668885, 0.807056474685669, 1.1636824011802673, 0.7883963942527771, 0.6934752404689789, 0.8037999987602233, 0.9199987769126892, 0.9031676948070526, 0.8962623834609985, 0.783824372291565, 0.8267583101987839, 0.8492873728275299, 0.8128117620944977, 0.733640730381012, 0.835133159160614, 0.6996583878993988, 0.7196643114089966, 0.7534481465816498, 0.7962315082550049, 0.8092940270900726, 0.7965385347604752, 0.7193039298057556, 0.773533046245575, 0.8634313821792603, 0.8006174564361572, 0.7434994786977768, 0.8118011474609375, 0.8106461763381958, 0.7518579483032226, 0.7252400517463684, 0.9538363814353943, 0.8820456981658935, 0.8174656152725219, 0.7956257224082947, 0.8481876850128174, 0.7469871759414672, 0.7500464797019959, 0.7908843219280243, 0.8195187389850617, 1.0025889217853545, 0.9013179421424866, 1.0770826518535614, 0.8197566628456116, 0.865369999408722, 0.761812387406826, 0.8913252949714661, 0.966012316942215, 0.7265294522047043, 0.7616002917289734, 1.293463808298111, 0.9262495100498199, 0.7901852846145629, 3.7259937524795532, 0.8215345680713654, 1.0895694613456726, 0.8376552268862725, 0.8231047749519348, 0.7166425734758377, 1.2437255024909972, 0.8414072960615158, 0.942820143699646, 0.7693974077701569, 0.8434823155403137, 0.802675998210907, 1.4596340894699096, 0.7777471542358398, 0.8756903529167175, 0.9225638210773468, 0.9347672939300538, 0.8764852106571197, 0.7707935214042664, 1.4199922204017639, 0.9724242106080055, 0.7188069477677346, 0.9157258749008179, 0.7915252327919007]
BasicNet
training_accuracy -- validation_accuracy
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123]
[19.564541213063762, 25.412130637636082, 29.12908242612753, 33.79471228615863, 38.102643856920686, 42.581648522550545, 45.19440124416796, 48.35147744945568, 51.22861586314153, 53.483670295489894, 55.287713841368586, 56.11197511664075, 59.64230171073095, 60.15552099533437, 62.737169517884915, 62.846034214618975, 64.16796267496112, 66.90513219284604, 66.31415241057543, 67.57387247278382, 70.23328149300156, 70.60653188180405, 70.7153965785381, 72.3950233281493, 71.57076205287714, 72.099533437014, 73.950233281493, 74.55676516329704, 75.00777604976672, 75.41213063763608, 75.5054432348367, 77.6049766718507, 77.86936236391912, 78.55365474339035, 78.60031104199066, 79.64230171073095, 79.11353032659409, 80.34214618973562, 79.11353032659409, 79.39346811819595, 81.9284603421462, 81.32192846034215, 80.80870917573873, 81.85069984447901, 82.28615863141525, 83.21928460342146, 84.19906687402799, 83.00155520995334, 84.02799377916018, 82.9860031104199, 84.1213063763608, 83.950233281493, 83.8258164852255, 84.0746500777605, 85.42768273716952, 85.41213063763608, 85.55209953343702, 85.56765163297045, 84.97667185069984, 86.3452566096423, 84.65007776049767, 85.58320373250389, 86.65629860031105, 86.11197511664075, 86.32970451010887, 87.06065318818041, 87.55832037325038, 88.11819595645412, 86.28304821150856, 87.63608087091757, 86.18973561430793, 87.55832037325038, 88.30482115085536, 88.24261275272161, 87.93157076205287, 88.13374805598755, 87.72939346811819, 88.66251944012441, 89.39346811819595, 89.11353032659409, 90.17107309486781, 89.65785381026438, 89.36236391912908, 89.2846034214619, 89.59564541213064, 89.17573872472784, 89.56454121306376, 90.21772939346812, 90.37325038880249, 90.46656298600311, 89.17573872472784, 89.62674961119751, 89.90668740279938, 88.50699844479004, 87.21617418351478, 88.56920684292379, 89.90668740279938, 90.4199066874028, 90.9642301710731, 90.48211508553655, 89.68895800933126, 91.78849144634526, 89.98444790046656, 91.19751166407465, 90.6687402799378, 90.91757387247279, 91.04199066874028, 90.82426127527216, 90.37325038880249, 91.29082426127528, 91.3841368584759, 91.36858475894246, 91.30637636080871, 91.83514774494557, 91.53965785381027, 90.93312597200622, 92.099533437014, 89.1601866251944, 90.35769828926905, 91.33748055987559, 91.53965785381027, 91.0886469673406, 91.66407465007777, 91.88180404354588]
[21.333333333333332, 30.761904761904763, 37.142857142857146, 35.333333333333336, 44.57142857142857, 47.61904761904762, 50.38095238095238, 52.76190476190476, 58.0, 45.142857142857146, 29.047619047619047, 57.23809523809524, 63.904761904761905, 54.19047619047619, 64.0, 37.42857142857143, 67.71428571428571, 67.9047619047619, 71.14285714285714, 67.61904761904762, 65.9047619047619, 61.523809523809526, 62.19047619047619, 50.57142857142857, 72.47619047619048, 73.33333333333333, 73.71428571428571, 73.61904761904762, 74.19047619047619, 75.14285714285714, 72.47619047619048, 72.95238095238095, 74.0, 68.0, 76.28571428571429, 75.04761904761905, 76.47619047619048, 76.0, 72.19047619047619, 71.04761904761905, 77.23809523809524, 75.80952380952381, 66.38095238095238, 71.04761904761905, 74.19047619047619, 73.80952380952381, 77.52380952380952, 77.14285714285714, 79.33333333333333, 77.61904761904762, 71.14285714285714, 78.0, 79.71428571428571, 78.47619047619048, 74.85714285714286, 73.42857142857143, 77.14285714285714, 78.28571428571429, 78.47619047619048, 76.95238095238095, 78.38095238095238, 78.57142857142857, 77.23809523809524, 77.9047619047619, 79.04761904761905, 79.04761904761905, 77.61904761904762, 79.33333333333333, 76.38095238095238, 80.0, 80.95238095238095, 77.52380952380952, 78.95238095238095, 78.38095238095238, 77.71428571428571, 77.04761904761905, 80.47619047619048, 81.23809523809524, 79.42857142857143, 77.42857142857143, 81.04761904761905, 78.66666666666667, 80.0, 82.28571428571429, 81.42857142857143, 79.61904761904762, 81.52380952380952, 79.42857142857143, 78.0, 78.85714285714286, 79.9047619047619, 79.71428571428571, 80.95238095238095, 77.80952380952381, 76.57142857142857, 79.61904761904762, 79.71428571428571, 73.80952380952381, 77.71428571428571, 80.19047619047619, 54.38095238095238, 80.76190476190476, 76.0, 79.52380952380952, 79.33333333333333, 80.76190476190476, 77.23809523809524, 80.0, 78.85714285714286, 80.19047619047619, 81.71428571428571, 80.76190476190476, 73.80952380952381, 81.71428571428571, 80.76190476190476, 79.61904761904762, 80.57142857142857, 80.47619047619048, 83.9047619047619, 74.19047619047619, 77.71428571428571, 82.19047619047619, 81.04761904761905, 80.85714285714286]
model saved as model_store_256/cnn_car_BasicNet.pt
Getting predictions from test set...
BasicNet
[[105   5   0  26  11   2   1]
 [  1 115   2   5   9   9   9]
 [  3   5 125   3   6   5   3]
 [  8   0   2 129   3   4   4]
 [  3  10   2   0 125   0  10]
 [  2   7   4   6   0 125   6]
 [  2   9   6   4   1   3 125]]
=============================
ImprovedNet
=============================
Epoch: 0
Training set [0/6430 (0%)] Loss: 1.945186
Training set [2560/6430 (38%)] Loss: 1.919480
Training set [5120/6430 (77%)] Loss: 1.891747
Training set: Average loss: 1.935624
Training set: Average accuracy: 20.25%
Validation set: Average loss: 1.825670, Accuracy: 326/1050 (31%)

Epoch: 1
Training set [0/6430 (0%)] Loss: 1.775541
Training set [2560/6430 (38%)] Loss: 1.731507
Training set [5120/6430 (77%)] Loss: 1.728886
Training set: Average loss: 1.710393
Training set: Average accuracy: 34.17%
Validation set: Average loss: 1.690276, Accuracy: 411/1050 (39%)

Epoch: 2
Training set [0/6430 (0%)] Loss: 1.554592
Training set [2560/6430 (38%)] Loss: 1.644106
Training set [5120/6430 (77%)] Loss: 1.605116
Training set: Average loss: 1.546137
Training set: Average accuracy: 41.80%
Validation set: Average loss: 1.511311, Accuracy: 450/1050 (43%)

Epoch: 3
Training set [0/6430 (0%)] Loss: 1.374661
Training set [2560/6430 (38%)] Loss: 1.485137
Training set [5120/6430 (77%)] Loss: 1.289693
Training set: Average loss: 1.385001
Training set: Average accuracy: 49.81%
Validation set: Average loss: 1.408787, Accuracy: 524/1050 (50%)

Epoch: 4
Training set [0/6430 (0%)] Loss: 1.183937
Training set [2560/6430 (38%)] Loss: 1.185741
Training set [5120/6430 (77%)] Loss: 1.121988
Training set: Average loss: 1.185081
Training set: Average accuracy: 56.86%
Validation set: Average loss: 1.413478, Accuracy: 542/1050 (52%)

Epoch: 5
Training set [0/6430 (0%)] Loss: 1.094041
Training set [2560/6430 (38%)] Loss: 1.179166
Training set [5120/6430 (77%)] Loss: 1.013481
Training set: Average loss: 0.986740
Training set: Average accuracy: 64.98%
Validation set: Average loss: 1.226195, Accuracy: 603/1050 (57%)

Epoch: 6
Training set [0/6430 (0%)] Loss: 0.747753
Training set [2560/6430 (38%)] Loss: 0.720243
Training set [5120/6430 (77%)] Loss: 0.791209
Training set: Average loss: 0.813817
Training set: Average accuracy: 71.84%
Validation set: Average loss: 1.181826, Accuracy: 634/1050 (60%)

Epoch: 7
Training set [0/6430 (0%)] Loss: 0.715072
Training set [2560/6430 (38%)] Loss: 0.717930
Training set [5120/6430 (77%)] Loss: 0.619129
Training set: Average loss: 0.634919
Training set: Average accuracy: 78.80%
Validation set: Average loss: 1.099091, Accuracy: 663/1050 (63%)

Epoch: 8
Training set [0/6430 (0%)] Loss: 0.591761
Training set [2560/6430 (38%)] Loss: 0.510330
Training set [5120/6430 (77%)] Loss: 0.535057
Training set: Average loss: 0.525311
Training set: Average accuracy: 81.82%
Validation set: Average loss: 1.287614, Accuracy: 609/1050 (58%)

Epoch: 9
Training set [0/6430 (0%)] Loss: 0.549662
Training set [2560/6430 (38%)] Loss: 0.403667
Training set [5120/6430 (77%)] Loss: 0.446677
Training set: Average loss: 0.430748
Training set: Average accuracy: 85.43%
Validation set: Average loss: 1.074904, Accuracy: 672/1050 (64%)

Epoch: 10
Training set [0/6430 (0%)] Loss: 0.321912
Training set [2560/6430 (38%)] Loss: 0.321886
Training set [5120/6430 (77%)] Loss: 0.279774
Training set: Average loss: 0.329980
Training set: Average accuracy: 89.42%
Validation set: Average loss: 1.093061, Accuracy: 662/1050 (63%)

Epoch: 11
Training set [0/6430 (0%)] Loss: 0.306045
Training set [2560/6430 (38%)] Loss: 0.300245
Training set [5120/6430 (77%)] Loss: 0.246536
Training set: Average loss: 0.278968
Training set: Average accuracy: 90.82%
Validation set: Average loss: 1.110888, Accuracy: 686/1050 (65%)

Epoch: 12
Training set [0/6430 (0%)] Loss: 0.233752
Training set [2560/6430 (38%)] Loss: 0.200824
Training set [5120/6430 (77%)] Loss: 0.217210
Training set: Average loss: 0.209850
Training set: Average accuracy: 93.06%
Validation set: Average loss: 1.254588, Accuracy: 692/1050 (66%)

Epoch: 13
Training set [0/6430 (0%)] Loss: 0.170295
Training set [2560/6430 (38%)] Loss: 0.163986
Training set [5120/6430 (77%)] Loss: 0.130653
Training set: Average loss: 0.168167
Training set: Average accuracy: 94.42%
Validation set: Average loss: 1.283722, Accuracy: 687/1050 (65%)

Epoch: 14
Training set [0/6430 (0%)] Loss: 0.182650
Training set [2560/6430 (38%)] Loss: 0.141230
Training set [5120/6430 (77%)] Loss: 0.178285
Training set: Average loss: 0.147579
Training set: Average accuracy: 95.32%
Validation set: Average loss: 1.287136, Accuracy: 701/1050 (67%)

Epoch: 15
Training set [0/6430 (0%)] Loss: 0.158812
Training set [2560/6430 (38%)] Loss: 0.145739
Training set [5120/6430 (77%)] Loss: 0.111270
Training set: Average loss: 0.124288
Training set: Average accuracy: 96.16%
Validation set: Average loss: 1.233925, Accuracy: 704/1050 (67%)

Epoch: 16
Training set [0/6430 (0%)] Loss: 0.081996
Training set [2560/6430 (38%)] Loss: 0.141466
Training set [5120/6430 (77%)] Loss: 0.139927
Training set: Average loss: 0.118793
Training set: Average accuracy: 95.97%
Validation set: Average loss: 1.324093, Accuracy: 698/1050 (66%)

Epoch: 17
Training set [0/6430 (0%)] Loss: 0.093503
Training set [2560/6430 (38%)] Loss: 0.106419
Training set [5120/6430 (77%)] Loss: 0.082357
Training set: Average loss: 0.090823
Training set: Average accuracy: 96.95%
Validation set: Average loss: 1.348021, Accuracy: 692/1050 (66%)

Epoch: 18
Training set [0/6430 (0%)] Loss: 0.085042
Training set [2560/6430 (38%)] Loss: 0.118066
Training set [5120/6430 (77%)] Loss: 0.143215
Training set: Average loss: 0.079377
Training set: Average accuracy: 97.45%
Validation set: Average loss: 1.359680, Accuracy: 699/1050 (67%)

Epoch: 19
Training set [0/6430 (0%)] Loss: 0.119417
Training set [2560/6430 (38%)] Loss: 0.052241
Training set [5120/6430 (77%)] Loss: 0.082744
Training set: Average loss: 0.086325
Training set: Average accuracy: 97.42%
Validation set: Average loss: 1.432994, Accuracy: 695/1050 (66%)

Epoch: 20
Training set [0/6430 (0%)] Loss: 0.054524
Training set [2560/6430 (38%)] Loss: 0.105505
Training set [5120/6430 (77%)] Loss: 0.038208
Training set: Average loss: 0.071605
Training set: Average accuracy: 97.54%
Validation set: Average loss: 1.468537, Accuracy: 696/1050 (66%)

Epoch: 21
Training set [0/6430 (0%)] Loss: 0.040057
Training set [2560/6430 (38%)] Loss: 0.054703
Training set [5120/6430 (77%)] Loss: 0.055320
Training set: Average loss: 0.064081
Training set: Average accuracy: 97.88%
Validation set: Average loss: 1.405743, Accuracy: 700/1050 (67%)

Epoch: 22
Training set [0/6430 (0%)] Loss: 0.069834
Training set [2560/6430 (38%)] Loss: 0.053575
Training set [5120/6430 (77%)] Loss: 0.055590
Training set: Average loss: 0.062816
Training set: Average accuracy: 97.96%
Validation set: Average loss: 1.514758, Accuracy: 688/1050 (66%)

Epoch: 23
Training set [0/6430 (0%)] Loss: 0.034605
Training set [2560/6430 (38%)] Loss: 0.067280
Training set [5120/6430 (77%)] Loss: 0.097099
Training set: Average loss: 0.054422
Training set: Average accuracy: 98.26%
Validation set: Average loss: 1.448330, Accuracy: 687/1050 (65%)

Epoch: 24
Training set [0/6430 (0%)] Loss: 0.029768
Training set [2560/6430 (38%)] Loss: 0.020825
Training set [5120/6430 (77%)] Loss: 0.050014
Training set: Average loss: 0.041671
Training set: Average accuracy: 98.77%
Validation set: Average loss: 1.603378, Accuracy: 688/1050 (66%)

Epoch: 25
Training set [0/6430 (0%)] Loss: 0.017852
Training set [2560/6430 (38%)] Loss: 0.084304
Training set [5120/6430 (77%)] Loss: 0.041113
Training set: Average loss: 0.047777
Training set: Average accuracy: 98.46%
Validation set: Average loss: 1.593631, Accuracy: 685/1050 (65%)

Epoch: 26
Training set [0/6430 (0%)] Loss: 0.033973
Training set [2560/6430 (38%)] Loss: 0.062757
Training set [5120/6430 (77%)] Loss: 0.036451
Training set: Average loss: 0.041558
Training set: Average accuracy: 98.63%
Validation set: Average loss: 1.592313, Accuracy: 694/1050 (66%)

Epoch: 27
Training set [0/6430 (0%)] Loss: 0.055766
Training set [2560/6430 (38%)] Loss: 0.022990
Training set [5120/6430 (77%)] Loss: 0.053743
Training set: Average loss: 0.043837
Training set: Average accuracy: 98.77%
Validation set: Average loss: 1.499628, Accuracy: 694/1050 (66%)

Epoch: 28
Training set [0/6430 (0%)] Loss: 0.074010
Training set [2560/6430 (38%)] Loss: 0.064007
Training set [5120/6430 (77%)] Loss: 0.064788
Training set: Average loss: 0.044837
Training set: Average accuracy: 98.55%
Validation set: Average loss: 1.453084, Accuracy: 698/1050 (66%)

Epoch: 29
Training set [0/6430 (0%)] Loss: 0.045287
Training set [2560/6430 (38%)] Loss: 0.088281
Training set [5120/6430 (77%)] Loss: 0.066737
Training set: Average loss: 0.048378
Training set: Average accuracy: 98.63%
Validation set: Average loss: 1.489128, Accuracy: 691/1050 (66%)

Epoch: 30
Training set [0/6430 (0%)] Loss: 0.018778
Training set [2560/6430 (38%)] Loss: 0.035068
Training set [5120/6430 (77%)] Loss: 0.065613
Training set: Average loss: 0.040059
Training set: Average accuracy: 98.77%
Validation set: Average loss: 1.511757, Accuracy: 692/1050 (66%)

Epoch: 31
Training set [0/6430 (0%)] Loss: 0.046721
Training set [2560/6430 (38%)] Loss: 0.030214
Training set [5120/6430 (77%)] Loss: 0.058761
Training set: Average loss: 0.033365
Training set: Average accuracy: 98.88%
Validation set: Average loss: 1.513293, Accuracy: 701/1050 (67%)

Epoch: 32
Training set [0/6430 (0%)] Loss: 0.036716
Training set [2560/6430 (38%)] Loss: 0.022165
Training set [5120/6430 (77%)] Loss: 0.027627
Training set: Average loss: 0.034102
Training set: Average accuracy: 98.79%
Validation set: Average loss: 1.452453, Accuracy: 707/1050 (67%)

Epoch: 33
Training set [0/6430 (0%)] Loss: 0.036012
Training set [2560/6430 (38%)] Loss: 0.051419
Training set [5120/6430 (77%)] Loss: 0.024262
Training set: Average loss: 0.031768
Training set: Average accuracy: 99.02%
Validation set: Average loss: 1.514006, Accuracy: 697/1050 (66%)

Epoch: 34
Training set [0/6430 (0%)] Loss: 0.041072
Training set [2560/6430 (38%)] Loss: 0.029243
Training set [5120/6430 (77%)] Loss: 0.040845
Training set: Average loss: 0.035093
Training set: Average accuracy: 98.80%
Validation set: Average loss: 1.690553, Accuracy: 699/1050 (67%)

Epoch: 35
Training set [0/6430 (0%)] Loss: 0.072067
Training set [2560/6430 (38%)] Loss: 0.019595
Training set [5120/6430 (77%)] Loss: 0.024356
Training set: Average loss: 0.035146
Training set: Average accuracy: 98.82%
Validation set: Average loss: 1.718150, Accuracy: 699/1050 (67%)

Epoch: 36
Training set [0/6430 (0%)] Loss: 0.031992
Training set [2560/6430 (38%)] Loss: 0.045288
Training set [5120/6430 (77%)] Loss: 0.021885
Training set: Average loss: 0.032341
Training set: Average accuracy: 98.85%
Validation set: Average loss: 1.616014, Accuracy: 699/1050 (67%)

Epoch: 37
Training set [0/6430 (0%)] Loss: 0.033596
Training set [2560/6430 (38%)] Loss: 0.035515
Training set [5120/6430 (77%)] Loss: 0.050007
Training set: Average loss: 0.032842
Training set: Average accuracy: 98.99%
Validation set: Average loss: 1.704959, Accuracy: 718/1050 (68%)

Epoch: 38
Training set [0/6430 (0%)] Loss: 0.060750
Training set [2560/6430 (38%)] Loss: 0.014419
Training set [5120/6430 (77%)] Loss: 0.028579
Training set: Average loss: 0.029839
Training set: Average accuracy: 98.94%
Validation set: Average loss: 1.687476, Accuracy: 702/1050 (67%)

Epoch: 39
Training set [0/6430 (0%)] Loss: 0.013903
Training set [2560/6430 (38%)] Loss: 0.044158
Training set [5120/6430 (77%)] Loss: 0.023694
Training set: Average loss: 0.028868
Training set: Average accuracy: 99.13%
Validation set: Average loss: 1.702475, Accuracy: 698/1050 (66%)

Epoch: 40
Training set [0/6430 (0%)] Loss: 0.034527
Training set [2560/6430 (38%)] Loss: 0.030722
Training set [5120/6430 (77%)] Loss: 0.022067
Training set: Average loss: 0.035895
Training set: Average accuracy: 98.74%
Validation set: Average loss: 1.666761, Accuracy: 712/1050 (68%)

Epoch: 41
Training set [0/6430 (0%)] Loss: 0.050488
Training set [2560/6430 (38%)] Loss: 0.030030
Training set [5120/6430 (77%)] Loss: 0.017742
Training set: Average loss: 0.028718
Training set: Average accuracy: 99.18%
Validation set: Average loss: 1.509366, Accuracy: 701/1050 (67%)

Epoch: 42
Training set [0/6430 (0%)] Loss: 0.021531
Training set [2560/6430 (38%)] Loss: 0.017699
Training set [5120/6430 (77%)] Loss: 0.035535
Training set: Average loss: 0.020960
Training set: Average accuracy: 99.36%
Validation set: Average loss: 1.742658, Accuracy: 693/1050 (66%)

Epoch: 43
Training set [0/6430 (0%)] Loss: 0.032966
Training set [2560/6430 (38%)] Loss: 0.024300
Training set [5120/6430 (77%)] Loss: 0.022952
Training set: Average loss: 0.025827
Training set: Average accuracy: 99.21%
Validation set: Average loss: 1.640144, Accuracy: 709/1050 (68%)

Epoch: 44
Training set [0/6430 (0%)] Loss: 0.008617
Training set [2560/6430 (38%)] Loss: 0.007442
Training set [5120/6430 (77%)] Loss: 0.008179
Training set: Average loss: 0.020962
Training set: Average accuracy: 99.38%
Validation set: Average loss: 1.778393, Accuracy: 711/1050 (68%)

Epoch: 45
Training set [0/6430 (0%)] Loss: 0.018818
Training set [2560/6430 (38%)] Loss: 0.033072
Training set [5120/6430 (77%)] Loss: 0.013755
Training set: Average loss: 0.026110
Training set: Average accuracy: 99.11%
Validation set: Average loss: 1.702212, Accuracy: 707/1050 (67%)

Epoch: 46
Training set [0/6430 (0%)] Loss: 0.012137
Training set [2560/6430 (38%)] Loss: 0.009354
Training set [5120/6430 (77%)] Loss: 0.012004
Training set: Average loss: 0.023190
Training set: Average accuracy: 99.27%
Validation set: Average loss: 1.608813, Accuracy: 705/1050 (67%)

Epoch: 47
Training set [0/6430 (0%)] Loss: 0.028109
Training set [2560/6430 (38%)] Loss: 0.044708
Training set [5120/6430 (77%)] Loss: 0.024513
Training set: Average loss: 0.021812
Training set: Average accuracy: 99.22%
Validation set: Average loss: 1.750035, Accuracy: 697/1050 (66%)

Epoch: 48
Training set [0/6430 (0%)] Loss: 0.011309
Training set [2560/6430 (38%)] Loss: 0.012039
Training set [5120/6430 (77%)] Loss: 0.017388
Training set: Average loss: 0.020849
Training set: Average accuracy: 99.35%
Validation set: Average loss: 1.788925, Accuracy: 707/1050 (67%)

Epoch: 49
Training set [0/6430 (0%)] Loss: 0.016512
Training set [2560/6430 (38%)] Loss: 0.021028
Training set [5120/6430 (77%)] Loss: 0.018562
Training set: Average loss: 0.023330
Training set: Average accuracy: 99.16%
Validation set: Average loss: 1.796754, Accuracy: 691/1050 (66%)

Epoch: 50
Training set [0/6430 (0%)] Loss: 0.010243
Training set [2560/6430 (38%)] Loss: 0.017703
Training set [5120/6430 (77%)] Loss: 0.048035
Training set: Average loss: 0.025949
Training set: Average accuracy: 99.16%
Validation set: Average loss: 1.689695, Accuracy: 704/1050 (67%)

Epoch: 51
Training set [0/6430 (0%)] Loss: 0.024615
Training set [2560/6430 (38%)] Loss: 0.044295
Training set [5120/6430 (77%)] Loss: 0.006332
Training set: Average loss: 0.021360
Training set: Average accuracy: 99.28%
Validation set: Average loss: 1.905787, Accuracy: 682/1050 (65%)

Epoch: 52
Training set [0/6430 (0%)] Loss: 0.004852
Training set [2560/6430 (38%)] Loss: 0.015366
Training set [5120/6430 (77%)] Loss: 0.013854
Training set: Average loss: 0.017739
Training set: Average accuracy: 99.47%
Validation set: Average loss: 1.713885, Accuracy: 710/1050 (68%)

Epoch: 53
Training set [0/6430 (0%)] Loss: 0.032269
Training set [2560/6430 (38%)] Loss: 0.023574
Training set [5120/6430 (77%)] Loss: 0.005269
Training set: Average loss: 0.023661
Training set: Average accuracy: 99.42%
Validation set: Average loss: 1.745452, Accuracy: 709/1050 (68%)

Epoch: 54
Training set [0/6430 (0%)] Loss: 0.041421
Training set [2560/6430 (38%)] Loss: 0.023266
Training set [5120/6430 (77%)] Loss: 0.030245
Training set: Average loss: 0.032036
Training set: Average accuracy: 98.93%
Validation set: Average loss: 1.630259, Accuracy: 712/1050 (68%)

Epoch: 55
Training set [0/6430 (0%)] Loss: 0.007048
Training set [2560/6430 (38%)] Loss: 0.011852
Training set [5120/6430 (77%)] Loss: 0.018243
Training set: Average loss: 0.023792
Training set: Average accuracy: 99.07%
Validation set: Average loss: 1.690724, Accuracy: 707/1050 (67%)

Epoch: 56
Training set [0/6430 (0%)] Loss: 0.018091
Training set [2560/6430 (38%)] Loss: 0.014833
Training set [5120/6430 (77%)] Loss: 0.011045
Training set: Average loss: 0.019911
Training set: Average accuracy: 99.30%
Validation set: Average loss: 1.867950, Accuracy: 712/1050 (68%)

Epoch: 57
Training set [0/6430 (0%)] Loss: 0.024668
Training set [2560/6430 (38%)] Loss: 0.024987
Training set [5120/6430 (77%)] Loss: 0.019347
Training set: Average loss: 0.023879
Training set: Average accuracy: 99.16%
Validation set: Average loss: 1.887424, Accuracy: 714/1050 (68%)

Epoch: 58
Training set [0/6430 (0%)] Loss: 0.033259
Training set [2560/6430 (38%)] Loss: 0.033388
Training set [5120/6430 (77%)] Loss: 0.043885
Training set: Average loss: 0.027581
Training set: Average accuracy: 99.11%
Validation set: Average loss: 1.715342, Accuracy: 700/1050 (67%)

Epoch: 59
Training set [0/6430 (0%)] Loss: 0.012524
Training set [2560/6430 (38%)] Loss: 0.033889
Training set [5120/6430 (77%)] Loss: 0.010908
Training set: Average loss: 0.023010
Training set: Average accuracy: 99.22%
Validation set: Average loss: 1.930244, Accuracy: 701/1050 (67%)

Epoch: 60
Training set [0/6430 (0%)] Loss: 0.067846
Training set [2560/6430 (38%)] Loss: 0.010479
Training set [5120/6430 (77%)] Loss: 0.023333
Training set: Average loss: 0.018346
Training set: Average accuracy: 99.41%
Validation set: Average loss: 1.900649, Accuracy: 713/1050 (68%)

Epoch: 61
Training set [0/6430 (0%)] Loss: 0.025288
Training set [2560/6430 (38%)] Loss: 0.024247
Training set [5120/6430 (77%)] Loss: 0.040488
Training set: Average loss: 0.016377
Training set: Average accuracy: 99.52%
Validation set: Average loss: 1.775413, Accuracy: 725/1050 (69%)

Epoch: 62
Training set [0/6430 (0%)] Loss: 0.019405
Training set [2560/6430 (38%)] Loss: 0.014033
Training set [5120/6430 (77%)] Loss: 0.018475
Training set: Average loss: 0.016007
Training set: Average accuracy: 99.42%
Validation set: Average loss: 1.711220, Accuracy: 711/1050 (68%)

Epoch: 63
Training set [0/6430 (0%)] Loss: 0.003378
Training set [2560/6430 (38%)] Loss: 0.016939
Training set [5120/6430 (77%)] Loss: 0.020039
Training set: Average loss: 0.022538
Training set: Average accuracy: 99.22%
Validation set: Average loss: 1.710955, Accuracy: 714/1050 (68%)

Epoch: 64
Training set [0/6430 (0%)] Loss: 0.021462
Training set [2560/6430 (38%)] Loss: 0.019796
Training set [5120/6430 (77%)] Loss: 0.011777
Training set: Average loss: 0.020889
Training set: Average accuracy: 99.44%
Validation set: Average loss: 1.901073, Accuracy: 711/1050 (68%)

Epoch: 65
Training set [0/6430 (0%)] Loss: 0.006902
Training set [2560/6430 (38%)] Loss: 0.025668
Training set [5120/6430 (77%)] Loss: 0.023744
Training set: Average loss: 0.020549
Training set: Average accuracy: 99.25%
Validation set: Average loss: 1.690827, Accuracy: 713/1050 (68%)

Epoch: 66
Training set [0/6430 (0%)] Loss: 0.050826
Training set [2560/6430 (38%)] Loss: 0.011896
Training set [5120/6430 (77%)] Loss: 0.013983
Training set: Average loss: 0.016322
Training set: Average accuracy: 99.33%
Validation set: Average loss: 1.700288, Accuracy: 727/1050 (69%)

Epoch: 67
Training set [0/6430 (0%)] Loss: 0.010391
Training set [2560/6430 (38%)] Loss: 0.010289
Training set [5120/6430 (77%)] Loss: 0.009819
Training set: Average loss: 0.018651
Training set: Average accuracy: 99.35%
Validation set: Average loss: 1.961570, Accuracy: 699/1050 (67%)

Epoch: 68
Training set [0/6430 (0%)] Loss: 0.009670
Training set [2560/6430 (38%)] Loss: 0.021714
Training set [5120/6430 (77%)] Loss: 0.020552
Training set: Average loss: 0.022546
Training set: Average accuracy: 99.24%
Validation set: Average loss: 1.704291, Accuracy: 715/1050 (68%)

Epoch: 69
Training set [0/6430 (0%)] Loss: 0.024665
Training set [2560/6430 (38%)] Loss: 0.005758
Training set [5120/6430 (77%)] Loss: 0.034178
Training set: Average loss: 0.018344
Training set: Average accuracy: 99.38%
Validation set: Average loss: 1.818981, Accuracy: 725/1050 (69%)

Epoch: 70
Training set [0/6430 (0%)] Loss: 0.005689
Training set [2560/6430 (38%)] Loss: 0.030932
Training set [5120/6430 (77%)] Loss: 0.027112
Training set: Average loss: 0.022428
Training set: Average accuracy: 99.41%
Validation set: Average loss: 1.925849, Accuracy: 711/1050 (68%)

Epoch: 71
Training set [0/6430 (0%)] Loss: 0.020326
Training set [2560/6430 (38%)] Loss: 0.016194
Training set [5120/6430 (77%)] Loss: 0.029182
Training set: Average loss: 0.029099
Training set: Average accuracy: 99.04%
Validation set: Average loss: 1.686863, Accuracy: 714/1050 (68%)

Epoch: 72
Training set [0/6430 (0%)] Loss: 0.013875
Training set [2560/6430 (38%)] Loss: 0.008118
Training set [5120/6430 (77%)] Loss: 0.048102
Training set: Average loss: 0.030404
Training set: Average accuracy: 98.97%
Validation set: Average loss: 1.853110, Accuracy: 696/1050 (66%)

Early stopping: no improvement for 10 epochs
ImprovedNet
training_loss -- validation_loss
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72]
[1.9356238796160772, 1.710392979475168, 1.54613747046544, 1.3850011550463164, 1.1850806841483483, 0.9867400572850153, 0.8138167422551376, 0.6349189281463623, 0.5253107696771622, 0.4307483549301441, 0.3299804822756694, 0.2789682551072194, 0.20985043679292387, 0.16816701711370394, 0.14757939112874177, 0.12428795947478367, 0.11879260909671967, 0.09082329283969906, 0.07937723369552539, 0.08632480897582494, 0.07160452352120326, 0.06408058980909678, 0.06281622363111147, 0.05442225861434753, 0.04167102083850365, 0.047777036419854715, 0.04155762307345867, 0.04383667458135348, 0.04483671833832677, 0.048378415405750275, 0.04005920005818972, 0.03336467092426924, 0.03410203783557965, 0.03176835673646285, 0.03509332399027279, 0.035145772549395375, 0.03234051884366916, 0.03284234858046357, 0.029839168638528254, 0.028868147386954382, 0.0358952851428722, 0.028717820066958666, 0.020960413188172076, 0.02582712475067148, 0.020961907441512898, 0.02611034048291353, 0.023190003891403858, 0.021811930525403183, 0.02084904318102277, 0.02333018180126181, 0.025948812110492818, 0.02136000702963569, 0.017738990736408874, 0.023661231299718984, 0.032036312766229876, 0.023791650417619027, 0.0199105615924614, 0.023879464966459915, 0.027581092773918778, 0.023009784412212096, 0.01834636241591607, 0.01637744048359589, 0.01600705843884498, 0.022537982986810114, 0.02088949216816288, 0.02054902971184884, 0.016322429484437004, 0.01865139953756275, 0.022545679579847135, 0.018344484269618988, 0.022427881655928034, 0.02909882689038148, 0.030403942013016112]
[1.8256699323654175, 1.6902759790420532, 1.5113112449645996, 1.4087871313095093, 1.4134778261184693, 1.2261950492858886, 1.1818262934684753, 1.099090564250946, 1.2876137256622315, 1.0749039053916931, 1.0930608272552491, 1.1108879923820496, 1.2545879006385803, 1.2837223291397095, 1.2871362566947937, 1.2339253544807434, 1.3240928292274474, 1.348021101951599, 1.3596800446510315, 1.4329936146736144, 1.4685374975204468, 1.4057432770729066, 1.5147577047348022, 1.448330283164978, 1.603377604484558, 1.5936313152313233, 1.5923128962516784, 1.4996281504631042, 1.4530838489532472, 1.4891275614500046, 1.511756581068039, 1.5132926642894744, 1.4524534165859222, 1.5140056252479552, 1.6905532598495483, 1.718149733543396, 1.61601402759552, 1.7049588680267334, 1.6874755382537843, 1.702475368976593, 1.6667606353759765, 1.5093664169311523, 1.742658293247223, 1.6401437878608705, 1.778392767906189, 1.7022123098373414, 1.6088125824928283, 1.7500354290008544, 1.788925051689148, 1.7967540740966796, 1.6896952390670776, 1.905787217617035, 1.713884711265564, 1.745452344417572, 1.6302588701248169, 1.6907235503196716, 1.867949903011322, 1.887423586845398, 1.7153415560722352, 1.9302436232566833, 1.90064936876297, 1.7754132866859436, 1.7112195491790771, 1.7109547853469849, 1.9010730147361756, 1.6908265411853791, 1.7002875357866287, 1.9615701198577882, 1.7042911767959594, 1.8189813017845153, 1.9258485794067384, 1.686863398551941, 1.8531097054481507]
ImprovedNet
training_accuracy -- validation_accuracy
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72]
[20.248833592534993, 34.16796267496112, 41.80404354587869, 49.813374805598755, 56.85847589424572, 64.97667185069984, 71.83514774494557, 78.80248833592535, 81.81959564541214, 85.42768273716952, 89.42457231726283, 90.82426127527216, 93.06376360808709, 94.41679626749611, 95.31881804043546, 96.15863141524106, 95.97200622083982, 96.95178849144635, 97.44945567651634, 97.41835147744946, 97.54276827371694, 97.88491446345256, 97.96267496111975, 98.25816485225505, 98.77138413685847, 98.46034214618973, 98.63141524105754, 98.77138413685847, 98.55365474339035, 98.63141524105754, 98.77138413685847, 98.88024883359253, 98.78693623639191, 99.02021772939347, 98.80248833592535, 98.81804043545878, 98.84914463452566, 98.98911353032659, 98.94245723172628, 99.12908242612752, 98.7402799377916, 99.17573872472784, 99.36236391912908, 99.20684292379471, 99.37791601866252, 99.11353032659409, 99.26905132192846, 99.22239502332815, 99.34681181959564, 99.1601866251944, 99.1601866251944, 99.2846034214619, 99.47122861586314, 99.42457231726283, 98.92690513219284, 99.06687402799378, 99.30015552099533, 99.1601866251944, 99.11353032659409, 99.22239502332815, 99.40902021772939, 99.51788491446345, 99.42457231726283, 99.22239502332815, 99.44012441679627, 99.25349922239502, 99.3312597200622, 99.34681181959564, 99.23794712286158, 99.37791601866252, 99.40902021772939, 99.0357698289269, 98.97356143079315]
[31.047619047619047, 39.142857142857146, 42.857142857142854, 49.904761904761905, 51.61904761904762, 57.42857142857143, 60.38095238095238, 63.142857142857146, 58.0, 64.0, 63.04761904761905, 65.33333333333333, 65.9047619047619, 65.42857142857143, 66.76190476190476, 67.04761904761905, 66.47619047619048, 65.9047619047619, 66.57142857142857, 66.19047619047619, 66.28571428571429, 66.66666666666667, 65.52380952380952, 65.42857142857143, 65.52380952380952, 65.23809523809524, 66.0952380952381, 66.0952380952381, 66.47619047619048, 65.80952380952381, 65.9047619047619, 66.76190476190476, 67.33333333333333, 66.38095238095238, 66.57142857142857, 66.57142857142857, 66.57142857142857, 68.38095238095238, 66.85714285714286, 66.47619047619048, 67.80952380952381, 66.76190476190476, 66.0, 67.52380952380952, 67.71428571428571, 67.33333333333333, 67.14285714285714, 66.38095238095238, 67.33333333333333, 65.80952380952381, 67.04761904761905, 64.95238095238095, 67.61904761904762, 67.52380952380952, 67.80952380952381, 67.33333333333333, 67.80952380952381, 68.0, 66.66666666666667, 66.76190476190476, 67.9047619047619, 69.04761904761905, 67.71428571428571, 68.0, 67.71428571428571, 67.9047619047619, 69.23809523809524, 66.57142857142857, 68.0952380952381, 69.04761904761905, 67.71428571428571, 68.0, 66.28571428571429]
model saved as model_store_256/cnn_car_ImprovedNet.pt
Getting predictions from test set...
ImprovedNet
[[ 71   6   0  35  21   9   8]
 [  2  83   6   8  25   4  22]
 [  4   6  99   7   6   8  20]
 [ 32   0   7  74  14  12  11]
 [  3   2   0   2 131   2  10]
 [  1   1   3  13   5 121   6]
 [  3   5   7   3  13   2 117]]
=============================
ImprovedNetLite
=============================
Epoch: 0
Training set [0/6430 (0%)] Loss: 2.019675
Training set [2560/6430 (38%)] Loss: 1.903054
Training set [5120/6430 (77%)] Loss: 1.833655
Training set: Average loss: 2.504512
Training set: Average accuracy: 21.40%
Validation set: Average loss: 1.925766, Accuracy: 215/1050 (20%)

Epoch: 1
Training set [0/6430 (0%)] Loss: 1.804288
Training set [2560/6430 (38%)] Loss: 1.789419
Training set [5120/6430 (77%)] Loss: 1.785439
Training set: Average loss: 1.783474
Training set: Average accuracy: 26.81%
Validation set: Average loss: 1.765022, Accuracy: 332/1050 (32%)

Epoch: 2
Training set [0/6430 (0%)] Loss: 1.774235
Training set [2560/6430 (38%)] Loss: 1.725044
Training set [5120/6430 (77%)] Loss: 1.652660
Training set: Average loss: 1.691966
Training set: Average accuracy: 32.74%
Validation set: Average loss: 1.595441, Accuracy: 427/1050 (41%)

Epoch: 3
Training set [0/6430 (0%)] Loss: 1.658939
Training set [2560/6430 (38%)] Loss: 1.550048
Training set [5120/6430 (77%)] Loss: 1.494363
Training set: Average loss: 1.571853
Training set: Average accuracy: 38.13%
Validation set: Average loss: 1.496962, Accuracy: 465/1050 (44%)

Epoch: 4
Training set [0/6430 (0%)] Loss: 1.526486
Training set [2560/6430 (38%)] Loss: 1.494305
Training set [5120/6430 (77%)] Loss: 1.434410
Training set: Average loss: 1.495047
Training set: Average accuracy: 41.73%
Validation set: Average loss: 1.395208, Accuracy: 531/1050 (51%)

Epoch: 5
Training set [0/6430 (0%)] Loss: 1.483771
Training set [2560/6430 (38%)] Loss: 1.469805
Training set [5120/6430 (77%)] Loss: 1.368240
Training set: Average loss: 1.427459
Training set: Average accuracy: 44.29%
Validation set: Average loss: 1.376291, Accuracy: 524/1050 (50%)

Epoch: 6
Training set [0/6430 (0%)] Loss: 1.352000
Training set [2560/6430 (38%)] Loss: 1.373388
Training set [5120/6430 (77%)] Loss: 1.328453
Training set: Average loss: 1.332310
Training set: Average accuracy: 48.71%
Validation set: Average loss: 1.256025, Accuracy: 601/1050 (57%)

Epoch: 7
Training set [0/6430 (0%)] Loss: 1.263709
Training set [2560/6430 (38%)] Loss: 1.250755
Training set [5120/6430 (77%)] Loss: 1.287778
Training set: Average loss: 1.262604
Training set: Average accuracy: 50.30%
Validation set: Average loss: 1.285473, Accuracy: 575/1050 (55%)

Epoch: 8
Training set [0/6430 (0%)] Loss: 1.247943
Training set [2560/6430 (38%)] Loss: 1.247592
Training set [5120/6430 (77%)] Loss: 1.073405
Training set: Average loss: 1.197825
Training set: Average accuracy: 53.48%
Validation set: Average loss: 1.195286, Accuracy: 602/1050 (57%)

Epoch: 9
Training set [0/6430 (0%)] Loss: 1.119496
Training set [2560/6430 (38%)] Loss: 1.157066
Training set [5120/6430 (77%)] Loss: 1.052012
Training set: Average loss: 1.149226
Training set: Average accuracy: 55.79%
Validation set: Average loss: 1.205673, Accuracy: 602/1050 (57%)

Epoch: 10
Training set [0/6430 (0%)] Loss: 1.233671
Training set [2560/6430 (38%)] Loss: 1.150776
Training set [5120/6430 (77%)] Loss: 1.116248
Training set: Average loss: 1.143072
Training set: Average accuracy: 56.28%
Validation set: Average loss: 1.237315, Accuracy: 591/1050 (56%)

Epoch: 11
Training set [0/6430 (0%)] Loss: 1.006763
Training set [2560/6430 (38%)] Loss: 1.126966
Training set [5120/6430 (77%)] Loss: 1.153133
Training set: Average loss: 1.058601
Training set: Average accuracy: 58.80%
Validation set: Average loss: 1.456989, Accuracy: 528/1050 (50%)

Epoch: 12
Training set [0/6430 (0%)] Loss: 0.984277
Training set [2560/6430 (38%)] Loss: 1.076417
Training set [5120/6430 (77%)] Loss: 1.005595
Training set: Average loss: 1.018323
Training set: Average accuracy: 59.38%
Validation set: Average loss: 1.084505, Accuracy: 657/1050 (63%)

Epoch: 13
Training set [0/6430 (0%)] Loss: 1.002902
Training set [2560/6430 (38%)] Loss: 0.969106
Training set [5120/6430 (77%)] Loss: 1.094765
Training set: Average loss: 0.989833
Training set: Average accuracy: 61.85%
Validation set: Average loss: 1.425506, Accuracy: 557/1050 (53%)

Epoch: 14
Training set [0/6430 (0%)] Loss: 0.882595
Training set [2560/6430 (38%)] Loss: 0.949061
Training set [5120/6430 (77%)] Loss: 0.910333
Training set: Average loss: 0.929114
Training set: Average accuracy: 63.92%
Validation set: Average loss: 1.030365, Accuracy: 680/1050 (65%)

Epoch: 15
Training set [0/6430 (0%)] Loss: 0.992949
Training set [2560/6430 (38%)] Loss: 0.952066
Training set [5120/6430 (77%)] Loss: 0.852137
Training set: Average loss: 0.930732
Training set: Average accuracy: 62.81%
Validation set: Average loss: 0.928223, Accuracy: 707/1050 (67%)

Epoch: 16
Training set [0/6430 (0%)] Loss: 0.952238
Training set [2560/6430 (38%)] Loss: 0.834604
Training set [5120/6430 (77%)] Loss: 0.743148
Training set: Average loss: 0.859453
Training set: Average accuracy: 66.70%
Validation set: Average loss: 1.061741, Accuracy: 683/1050 (65%)

Epoch: 17
Training set [0/6430 (0%)] Loss: 0.907706
Training set [2560/6430 (38%)] Loss: 0.781651
Training set [5120/6430 (77%)] Loss: 0.731492
Training set: Average loss: 0.851861
Training set: Average accuracy: 66.53%
Validation set: Average loss: 0.998066, Accuracy: 675/1050 (64%)

Epoch: 18
Training set [0/6430 (0%)] Loss: 0.721067
Training set [2560/6430 (38%)] Loss: 0.776863
Training set [5120/6430 (77%)] Loss: 0.888291
Training set: Average loss: 0.830560
Training set: Average accuracy: 67.88%
Validation set: Average loss: 1.079551, Accuracy: 664/1050 (63%)

Epoch: 19
Training set [0/6430 (0%)] Loss: 0.735525
Training set [2560/6430 (38%)] Loss: 0.802928
Training set [5120/6430 (77%)] Loss: 0.803850
Training set: Average loss: 0.810874
Training set: Average accuracy: 67.87%
Validation set: Average loss: 0.863870, Accuracy: 762/1050 (73%)

Epoch: 20
Training set [0/6430 (0%)] Loss: 0.728234
Training set [2560/6430 (38%)] Loss: 0.775070
Training set [5120/6430 (77%)] Loss: 0.738649
Training set: Average loss: 0.779261
Training set: Average accuracy: 68.90%
Validation set: Average loss: 1.011870, Accuracy: 696/1050 (66%)

Epoch: 21
Training set [0/6430 (0%)] Loss: 0.697268
Training set [2560/6430 (38%)] Loss: 0.849492
Training set [5120/6430 (77%)] Loss: 0.678908
Training set: Average loss: 0.755011
Training set: Average accuracy: 70.00%
Validation set: Average loss: 0.904234, Accuracy: 744/1050 (71%)

Epoch: 22
Training set [0/6430 (0%)] Loss: 0.693048
Training set [2560/6430 (38%)] Loss: 0.830613
Training set [5120/6430 (77%)] Loss: 0.734862
Training set: Average loss: 0.742218
Training set: Average accuracy: 70.23%
Validation set: Average loss: 0.870034, Accuracy: 714/1050 (68%)

Epoch: 23
Training set [0/6430 (0%)] Loss: 0.800117
Training set [2560/6430 (38%)] Loss: 0.658526
Training set [5120/6430 (77%)] Loss: 0.678151
Training set: Average loss: 0.715105
Training set: Average accuracy: 71.17%
Validation set: Average loss: 0.761840, Accuracy: 761/1050 (72%)

Epoch: 24
Training set [0/6430 (0%)] Loss: 0.618176
Training set [2560/6430 (38%)] Loss: 0.631604
Training set [5120/6430 (77%)] Loss: 0.611386
Training set: Average loss: 0.658973
Training set: Average accuracy: 73.61%
Validation set: Average loss: 0.803501, Accuracy: 751/1050 (72%)

Epoch: 25
Training set [0/6430 (0%)] Loss: 0.657311
Training set [2560/6430 (38%)] Loss: 0.720293
Training set [5120/6430 (77%)] Loss: 0.626963
Training set: Average loss: 0.681544
Training set: Average accuracy: 72.94%
Validation set: Average loss: 0.726079, Accuracy: 788/1050 (75%)

Epoch: 26
Training set [0/6430 (0%)] Loss: 0.612747
Training set [2560/6430 (38%)] Loss: 0.615009
Training set [5120/6430 (77%)] Loss: 0.647110
Training set: Average loss: 0.659906
Training set: Average accuracy: 74.12%
Validation set: Average loss: 1.550117, Accuracy: 606/1050 (58%)

Epoch: 27
Training set [0/6430 (0%)] Loss: 0.645708
Training set [2560/6430 (38%)] Loss: 0.724220
Training set [5120/6430 (77%)] Loss: 0.639493
Training set: Average loss: 0.659838
Training set: Average accuracy: 72.94%
Validation set: Average loss: 0.786317, Accuracy: 752/1050 (72%)

Epoch: 28
Training set [0/6430 (0%)] Loss: 0.487794
Training set [2560/6430 (38%)] Loss: 0.625820
Training set [5120/6430 (77%)] Loss: 0.651032
Training set: Average loss: 0.635707
Training set: Average accuracy: 75.18%
Validation set: Average loss: 1.020640, Accuracy: 723/1050 (69%)

Epoch: 29
Training set [0/6430 (0%)] Loss: 0.594394
Training set [2560/6430 (38%)] Loss: 0.626716
Training set [5120/6430 (77%)] Loss: 0.602907
Training set: Average loss: 0.616808
Training set: Average accuracy: 75.30%
Validation set: Average loss: 0.780794, Accuracy: 764/1050 (73%)

Epoch: 30
Training set [0/6430 (0%)] Loss: 0.640130
Training set [2560/6430 (38%)] Loss: 0.576303
Training set [5120/6430 (77%)] Loss: 0.565290
Training set: Average loss: 0.577617
Training set: Average accuracy: 76.66%
Validation set: Average loss: 0.890739, Accuracy: 748/1050 (71%)

Epoch: 31
Training set [0/6430 (0%)] Loss: 0.485185
Training set [2560/6430 (38%)] Loss: 0.540422
Training set [5120/6430 (77%)] Loss: 0.597673
Training set: Average loss: 0.581696
Training set: Average accuracy: 76.55%
Validation set: Average loss: 0.768736, Accuracy: 767/1050 (73%)

Epoch: 32
Training set [0/6430 (0%)] Loss: 0.599109
Training set [2560/6430 (38%)] Loss: 0.597600
Training set [5120/6430 (77%)] Loss: 0.540136
Training set: Average loss: 0.564155
Training set: Average accuracy: 76.47%
Validation set: Average loss: 0.757692, Accuracy: 769/1050 (73%)

Epoch: 33
Training set [0/6430 (0%)] Loss: 0.610398
Training set [2560/6430 (38%)] Loss: 0.586237
Training set [5120/6430 (77%)] Loss: 0.522849
Training set: Average loss: 0.568946
Training set: Average accuracy: 76.81%
Validation set: Average loss: 0.694138, Accuracy: 780/1050 (74%)

Epoch: 34
Training set [0/6430 (0%)] Loss: 0.560799
Training set [2560/6430 (38%)] Loss: 0.495445
Training set [5120/6430 (77%)] Loss: 0.589415
Training set: Average loss: 0.556804
Training set: Average accuracy: 76.80%
Validation set: Average loss: 1.015627, Accuracy: 692/1050 (66%)

Epoch: 35
Training set [0/6430 (0%)] Loss: 0.587807
Training set [2560/6430 (38%)] Loss: 0.441708
Training set [5120/6430 (77%)] Loss: 0.513703
Training set: Average loss: 0.546928
Training set: Average accuracy: 78.06%
Validation set: Average loss: 0.810298, Accuracy: 749/1050 (71%)

Epoch: 36
Training set [0/6430 (0%)] Loss: 0.542085
Training set [2560/6430 (38%)] Loss: 0.566498
Training set [5120/6430 (77%)] Loss: 0.499340
Training set: Average loss: 0.536471
Training set: Average accuracy: 78.66%
Validation set: Average loss: 0.788036, Accuracy: 791/1050 (75%)

Epoch: 37
Training set [0/6430 (0%)] Loss: 0.501426
Training set [2560/6430 (38%)] Loss: 0.520352
Training set [5120/6430 (77%)] Loss: 0.568068
Training set: Average loss: 0.560259
Training set: Average accuracy: 77.08%
Validation set: Average loss: 0.661350, Accuracy: 800/1050 (76%)

Epoch: 38
Training set [0/6430 (0%)] Loss: 0.531158
Training set [2560/6430 (38%)] Loss: 0.476057
Training set [5120/6430 (77%)] Loss: 0.455487
Training set: Average loss: 0.506488
Training set: Average accuracy: 80.02%
Validation set: Average loss: 0.867951, Accuracy: 746/1050 (71%)

Epoch: 39
Training set [0/6430 (0%)] Loss: 0.534441
Training set [2560/6430 (38%)] Loss: 0.527884
Training set [5120/6430 (77%)] Loss: 0.557910
Training set: Average loss: 0.553893
Training set: Average accuracy: 77.43%
Validation set: Average loss: 1.249503, Accuracy: 702/1050 (67%)

Epoch: 40
Training set [0/6430 (0%)] Loss: 0.521367
Training set [2560/6430 (38%)] Loss: 0.522043
Training set [5120/6430 (77%)] Loss: 0.539671
Training set: Average loss: 0.551861
Training set: Average accuracy: 76.91%
Validation set: Average loss: 1.023365, Accuracy: 704/1050 (67%)

Epoch: 41
Training set [0/6430 (0%)] Loss: 0.505245
Training set [2560/6430 (38%)] Loss: 0.535608
Training set [5120/6430 (77%)] Loss: 0.506802
Training set: Average loss: 0.498633
Training set: Average accuracy: 79.81%
Validation set: Average loss: 1.939620, Accuracy: 579/1050 (55%)

Epoch: 42
Training set [0/6430 (0%)] Loss: 0.521832
Training set [2560/6430 (38%)] Loss: 0.520114
Training set [5120/6430 (77%)] Loss: 0.507805
Training set: Average loss: 0.511973
Training set: Average accuracy: 79.50%
Validation set: Average loss: 1.002749, Accuracy: 737/1050 (70%)

Epoch: 43
Training set [0/6430 (0%)] Loss: 0.461959
Training set [2560/6430 (38%)] Loss: 0.571630
Training set [5120/6430 (77%)] Loss: 0.421552
Training set: Average loss: 0.501543
Training set: Average accuracy: 79.19%
Validation set: Average loss: 0.700063, Accuracy: 784/1050 (75%)

Epoch: 44
Training set [0/6430 (0%)] Loss: 0.544347
Training set [2560/6430 (38%)] Loss: 0.553532
Training set [5120/6430 (77%)] Loss: 0.488760
Training set: Average loss: 0.485847
Training set: Average accuracy: 80.05%
Validation set: Average loss: 0.714594, Accuracy: 795/1050 (76%)

Epoch: 45
Training set [0/6430 (0%)] Loss: 0.419419
Training set [2560/6430 (38%)] Loss: 0.485106
Training set [5120/6430 (77%)] Loss: 0.435274
Training set: Average loss: 0.476793
Training set: Average accuracy: 80.12%
Validation set: Average loss: 0.901264, Accuracy: 769/1050 (73%)

Epoch: 46
Training set [0/6430 (0%)] Loss: 0.427963
Training set [2560/6430 (38%)] Loss: 0.455880
Training set [5120/6430 (77%)] Loss: 0.461296
Training set: Average loss: 0.475575
Training set: Average accuracy: 80.79%
Validation set: Average loss: 0.866289, Accuracy: 778/1050 (74%)

Epoch: 47
Training set [0/6430 (0%)] Loss: 0.512304
Training set [2560/6430 (38%)] Loss: 0.540850
Training set [5120/6430 (77%)] Loss: 0.586520
Training set: Average loss: 0.498109
Training set: Average accuracy: 79.49%
Validation set: Average loss: 0.767849, Accuracy: 807/1050 (77%)

Epoch: 48
Training set [0/6430 (0%)] Loss: 0.502960
Training set [2560/6430 (38%)] Loss: 0.396453
Training set [5120/6430 (77%)] Loss: 0.459632
Training set: Average loss: 0.449661
Training set: Average accuracy: 81.40%
Validation set: Average loss: 0.759950, Accuracy: 809/1050 (77%)

Epoch: 49
Training set [0/6430 (0%)] Loss: 0.413083
Training set [2560/6430 (38%)] Loss: 0.484982
Training set [5120/6430 (77%)] Loss: 0.406678
Training set: Average loss: 0.464569
Training set: Average accuracy: 81.32%
Validation set: Average loss: 0.839849, Accuracy: 779/1050 (74%)

Epoch: 50
Training set [0/6430 (0%)] Loss: 0.458322
Training set [2560/6430 (38%)] Loss: 0.467729
Training set [5120/6430 (77%)] Loss: 0.419313
Training set: Average loss: 0.460913
Training set: Average accuracy: 80.95%
Validation set: Average loss: 0.660106, Accuracy: 810/1050 (77%)

Epoch: 51
Training set [0/6430 (0%)] Loss: 0.418585
Training set [2560/6430 (38%)] Loss: 0.562568
Training set [5120/6430 (77%)] Loss: 0.436303
Training set: Average loss: 0.454342
Training set: Average accuracy: 81.73%
Validation set: Average loss: 0.773630, Accuracy: 803/1050 (76%)

Epoch: 52
Training set [0/6430 (0%)] Loss: 0.450770
Training set [2560/6430 (38%)] Loss: 0.421015
Training set [5120/6430 (77%)] Loss: 0.359708
Training set: Average loss: 0.425902
Training set: Average accuracy: 81.84%
Validation set: Average loss: 0.662184, Accuracy: 822/1050 (78%)

Epoch: 53
Training set [0/6430 (0%)] Loss: 0.335573
Training set [2560/6430 (38%)] Loss: 0.443181
Training set [5120/6430 (77%)] Loss: 0.454091
Training set: Average loss: 0.393087
Training set: Average accuracy: 83.16%
Validation set: Average loss: 0.878098, Accuracy: 767/1050 (73%)

Epoch: 54
Training set [0/6430 (0%)] Loss: 0.357287
Training set [2560/6430 (38%)] Loss: 0.452295
Training set [5120/6430 (77%)] Loss: 0.488193
Training set: Average loss: 0.423670
Training set: Average accuracy: 82.29%
Validation set: Average loss: 0.774984, Accuracy: 821/1050 (78%)

Epoch: 55
Training set [0/6430 (0%)] Loss: 0.419738
Training set [2560/6430 (38%)] Loss: 0.476592
Training set [5120/6430 (77%)] Loss: 0.413797
Training set: Average loss: 0.416443
Training set: Average accuracy: 82.46%
Validation set: Average loss: 0.879609, Accuracy: 798/1050 (76%)

Epoch: 56
Training set [0/6430 (0%)] Loss: 0.398902
Training set [2560/6430 (38%)] Loss: 0.476942
Training set [5120/6430 (77%)] Loss: 0.387428
Training set: Average loss: 0.425495
Training set: Average accuracy: 82.92%
Validation set: Average loss: 0.676573, Accuracy: 828/1050 (79%)

Epoch: 57
Training set [0/6430 (0%)] Loss: 0.344626
Training set [2560/6430 (38%)] Loss: 0.488611
Training set [5120/6430 (77%)] Loss: 0.389912
Training set: Average loss: 0.453385
Training set: Average accuracy: 81.32%
Validation set: Average loss: 1.051830, Accuracy: 727/1050 (69%)

Epoch: 58
Training set [0/6430 (0%)] Loss: 0.331150
Training set [2560/6430 (38%)] Loss: 0.469499
Training set [5120/6430 (77%)] Loss: 0.374647
Training set: Average loss: 0.440567
Training set: Average accuracy: 82.83%
Validation set: Average loss: 0.935628, Accuracy: 762/1050 (73%)

Epoch: 59
Training set [0/6430 (0%)] Loss: 0.391953
Training set [2560/6430 (38%)] Loss: 0.436493
Training set [5120/6430 (77%)] Loss: 0.464982
Training set: Average loss: 0.406769
Training set: Average accuracy: 82.99%
Validation set: Average loss: 0.703059, Accuracy: 831/1050 (79%)

Epoch: 60
Training set [0/6430 (0%)] Loss: 0.315248
Training set [2560/6430 (38%)] Loss: 0.472011
Training set [5120/6430 (77%)] Loss: 0.373675
Training set: Average loss: 0.417374
Training set: Average accuracy: 82.74%
Validation set: Average loss: 0.641328, Accuracy: 833/1050 (79%)

Epoch: 61
Training set [0/6430 (0%)] Loss: 0.310979
Training set [2560/6430 (38%)] Loss: 0.381498
Training set [5120/6430 (77%)] Loss: 0.407603
Training set: Average loss: 0.391457
Training set: Average accuracy: 83.44%
Validation set: Average loss: 0.852293, Accuracy: 796/1050 (76%)

Epoch: 62
Training set [0/6430 (0%)] Loss: 0.294628
Training set [2560/6430 (38%)] Loss: 0.465785
Training set [5120/6430 (77%)] Loss: 0.429147
Training set: Average loss: 0.378922
Training set: Average accuracy: 83.92%
Validation set: Average loss: 0.725999, Accuracy: 805/1050 (77%)

Epoch: 63
Training set [0/6430 (0%)] Loss: 0.413005
Training set [2560/6430 (38%)] Loss: 0.408772
Training set [5120/6430 (77%)] Loss: 0.300524
Training set: Average loss: 0.365410
Training set: Average accuracy: 84.95%
Validation set: Average loss: 0.692935, Accuracy: 818/1050 (78%)

Epoch: 64
Training set [0/6430 (0%)] Loss: 0.485254
Training set [2560/6430 (38%)] Loss: 0.326898
Training set [5120/6430 (77%)] Loss: 0.386454
Training set: Average loss: 0.379756
Training set: Average accuracy: 84.32%
Validation set: Average loss: 0.763703, Accuracy: 802/1050 (76%)

Epoch: 65
Training set [0/6430 (0%)] Loss: 0.333130
Training set [2560/6430 (38%)] Loss: 0.434161
Training set [5120/6430 (77%)] Loss: 0.375516
Training set: Average loss: 0.392970
Training set: Average accuracy: 83.25%
Validation set: Average loss: 0.743654, Accuracy: 802/1050 (76%)

Epoch: 66
Training set [0/6430 (0%)] Loss: 0.314834
Training set [2560/6430 (38%)] Loss: 0.477159
Training set [5120/6430 (77%)] Loss: 0.356096
Training set: Average loss: 0.365352
Training set: Average accuracy: 84.26%
Validation set: Average loss: 1.196703, Accuracy: 751/1050 (72%)

Epoch: 67
Training set [0/6430 (0%)] Loss: 0.305534
Training set [2560/6430 (38%)] Loss: 0.459255
Training set [5120/6430 (77%)] Loss: 0.405472
Training set: Average loss: 0.377622
Training set: Average accuracy: 84.34%
Validation set: Average loss: 0.664178, Accuracy: 824/1050 (78%)

Epoch: 68
Training set [0/6430 (0%)] Loss: 0.250690
Training set [2560/6430 (38%)] Loss: 0.433290
Training set [5120/6430 (77%)] Loss: 0.306526
Training set: Average loss: 0.353359
Training set: Average accuracy: 85.21%
Validation set: Average loss: 0.736742, Accuracy: 831/1050 (79%)

Epoch: 69
Training set [0/6430 (0%)] Loss: 0.384238
Training set [2560/6430 (38%)] Loss: 0.319618
Training set [5120/6430 (77%)] Loss: 0.393421
Training set: Average loss: 0.375434
Training set: Average accuracy: 84.51%
Validation set: Average loss: 0.803916, Accuracy: 829/1050 (79%)

Epoch: 70
Training set [0/6430 (0%)] Loss: 0.363108
Training set [2560/6430 (38%)] Loss: 0.410441
Training set [5120/6430 (77%)] Loss: 0.309894
Training set: Average loss: 0.339881
Training set: Average accuracy: 85.93%
Validation set: Average loss: 0.856522, Accuracy: 786/1050 (75%)

Epoch: 71
Training set [0/6430 (0%)] Loss: 0.386137
Training set [2560/6430 (38%)] Loss: 0.326394
Training set [5120/6430 (77%)] Loss: 0.304908
Training set: Average loss: 0.351819
Training set: Average accuracy: 85.32%
Validation set: Average loss: 0.661161, Accuracy: 836/1050 (80%)

Epoch: 72
Training set [0/6430 (0%)] Loss: 0.343211
Training set [2560/6430 (38%)] Loss: 0.267160
Training set [5120/6430 (77%)] Loss: 0.405609
Training set: Average loss: 0.332643
Training set: Average accuracy: 86.14%
Validation set: Average loss: 0.740905, Accuracy: 839/1050 (80%)

Epoch: 73
Training set [0/6430 (0%)] Loss: 0.332213
Training set [2560/6430 (38%)] Loss: 0.315230
Training set [5120/6430 (77%)] Loss: 0.292548
Training set: Average loss: 0.343241
Training set: Average accuracy: 85.68%
Validation set: Average loss: 0.817524, Accuracy: 829/1050 (79%)

Epoch: 74
Training set [0/6430 (0%)] Loss: 0.218849
Training set [2560/6430 (38%)] Loss: 0.350269
Training set [5120/6430 (77%)] Loss: 0.343978
Training set: Average loss: 0.345011
Training set: Average accuracy: 85.58%
Validation set: Average loss: 0.743235, Accuracy: 839/1050 (80%)

Epoch: 75
Training set [0/6430 (0%)] Loss: 0.395220
Training set [2560/6430 (38%)] Loss: 0.288995
Training set [5120/6430 (77%)] Loss: 0.320566
Training set: Average loss: 0.336358
Training set: Average accuracy: 85.69%
Validation set: Average loss: 0.814431, Accuracy: 817/1050 (78%)

Epoch: 76
Training set [0/6430 (0%)] Loss: 0.356835
Training set [2560/6430 (38%)] Loss: 0.365150
Training set [5120/6430 (77%)] Loss: 0.353958
Training set: Average loss: 0.316215
Training set: Average accuracy: 86.67%
Validation set: Average loss: 0.770153, Accuracy: 831/1050 (79%)

Epoch: 77
Training set [0/6430 (0%)] Loss: 0.300835
Training set [2560/6430 (38%)] Loss: 0.470291
Training set [5120/6430 (77%)] Loss: 0.393929
Training set: Average loss: 0.359080
Training set: Average accuracy: 85.94%
Validation set: Average loss: 0.984114, Accuracy: 784/1050 (75%)

Epoch: 78
Training set [0/6430 (0%)] Loss: 0.375985
Training set [2560/6430 (38%)] Loss: 0.228830
Training set [5120/6430 (77%)] Loss: 0.327663
Training set: Average loss: 0.344074
Training set: Average accuracy: 85.57%
Validation set: Average loss: 0.664343, Accuracy: 834/1050 (79%)

Epoch: 79
Training set [0/6430 (0%)] Loss: 0.269588
Training set [2560/6430 (38%)] Loss: 0.298878
Training set [5120/6430 (77%)] Loss: 0.371369
Training set: Average loss: 0.302721
Training set: Average accuracy: 87.36%
Validation set: Average loss: 0.779314, Accuracy: 833/1050 (79%)

Epoch: 80
Training set [0/6430 (0%)] Loss: 0.278115
Training set [2560/6430 (38%)] Loss: 0.302415
Training set [5120/6430 (77%)] Loss: 0.290697
Training set: Average loss: 0.329854
Training set: Average accuracy: 86.41%
Validation set: Average loss: 0.924864, Accuracy: 821/1050 (78%)

Epoch: 81
Training set [0/6430 (0%)] Loss: 0.287152
Training set [2560/6430 (38%)] Loss: 0.270970
Training set [5120/6430 (77%)] Loss: 0.273885
Training set: Average loss: 0.324083
Training set: Average accuracy: 86.98%
Validation set: Average loss: 1.352837, Accuracy: 729/1050 (69%)

Epoch: 82
Training set [0/6430 (0%)] Loss: 0.314820
Training set [2560/6430 (38%)] Loss: 0.306708
Training set [5120/6430 (77%)] Loss: 0.449019
Training set: Average loss: 0.341178
Training set: Average accuracy: 86.25%
Validation set: Average loss: 0.684407, Accuracy: 815/1050 (78%)

Epoch: 83
Training set [0/6430 (0%)] Loss: 0.296384
Training set [2560/6430 (38%)] Loss: 0.276998
Training set [5120/6430 (77%)] Loss: 0.263332
Training set: Average loss: 0.319214
Training set: Average accuracy: 86.86%
Validation set: Average loss: 0.859673, Accuracy: 792/1050 (75%)

Epoch: 84
Training set [0/6430 (0%)] Loss: 0.408511
Training set [2560/6430 (38%)] Loss: 0.321363
Training set [5120/6430 (77%)] Loss: 0.332595
Training set: Average loss: 0.319806
Training set: Average accuracy: 86.81%
Validation set: Average loss: 0.914014, Accuracy: 807/1050 (77%)

Epoch: 85
Training set [0/6430 (0%)] Loss: 0.257584
Training set [2560/6430 (38%)] Loss: 0.231795
Training set [5120/6430 (77%)] Loss: 0.268297
Training set: Average loss: 0.292054
Training set: Average accuracy: 88.24%
Validation set: Average loss: 0.803601, Accuracy: 822/1050 (78%)

Epoch: 86
Training set [0/6430 (0%)] Loss: 0.279921
Training set [2560/6430 (38%)] Loss: 0.269117
Training set [5120/6430 (77%)] Loss: 0.277402
Training set: Average loss: 0.294963
Training set: Average accuracy: 87.88%
Validation set: Average loss: 0.833507, Accuracy: 833/1050 (79%)

Epoch: 87
Training set [0/6430 (0%)] Loss: 0.338554
Training set [2560/6430 (38%)] Loss: 0.322953
Training set [5120/6430 (77%)] Loss: 0.353367
Training set: Average loss: 0.303371
Training set: Average accuracy: 87.34%
Validation set: Average loss: 0.909321, Accuracy: 801/1050 (76%)

Epoch: 88
Training set [0/6430 (0%)] Loss: 0.363136
Training set [2560/6430 (38%)] Loss: 0.266619
Training set [5120/6430 (77%)] Loss: 0.288100
Training set: Average loss: 0.289635
Training set: Average accuracy: 87.68%
Validation set: Average loss: 0.924087, Accuracy: 823/1050 (78%)

Epoch: 89
Training set [0/6430 (0%)] Loss: 0.324018
Training set [2560/6430 (38%)] Loss: 0.313256
Training set [5120/6430 (77%)] Loss: 0.257392
Training set: Average loss: 0.272426
Training set: Average accuracy: 88.80%
Validation set: Average loss: 0.952755, Accuracy: 803/1050 (76%)

Epoch: 90
Training set [0/6430 (0%)] Loss: 0.306227
Training set [2560/6430 (38%)] Loss: 0.322044
Training set [5120/6430 (77%)] Loss: 0.287224
Training set: Average loss: 0.273246
Training set: Average accuracy: 88.60%
Validation set: Average loss: 0.867034, Accuracy: 827/1050 (79%)

Epoch: 91
Training set [0/6430 (0%)] Loss: 0.197523
Training set [2560/6430 (38%)] Loss: 0.246442
Training set [5120/6430 (77%)] Loss: 0.338450
Training set: Average loss: 0.271170
Training set: Average accuracy: 89.38%
Validation set: Average loss: 0.848741, Accuracy: 820/1050 (78%)

Epoch: 92
Training set [0/6430 (0%)] Loss: 0.288662
Training set [2560/6430 (38%)] Loss: 0.247267
Training set [5120/6430 (77%)] Loss: 0.292982
Training set: Average loss: 0.287158
Training set: Average accuracy: 88.52%
Validation set: Average loss: 1.000193, Accuracy: 774/1050 (74%)

Epoch: 93
Training set [0/6430 (0%)] Loss: 0.311163
Training set [2560/6430 (38%)] Loss: 0.351357
Training set [5120/6430 (77%)] Loss: 0.287790
Training set: Average loss: 0.289529
Training set: Average accuracy: 88.23%
Validation set: Average loss: 1.748223, Accuracy: 712/1050 (68%)

Epoch: 94
Training set [0/6430 (0%)] Loss: 0.299649
Training set [2560/6430 (38%)] Loss: 0.275514
Training set [5120/6430 (77%)] Loss: 0.330545
Training set: Average loss: 0.280500
Training set: Average accuracy: 89.10%
Validation set: Average loss: 1.051515, Accuracy: 775/1050 (74%)

Epoch: 95
Training set [0/6430 (0%)] Loss: 0.275309
Training set [2560/6430 (38%)] Loss: 0.344448
Training set [5120/6430 (77%)] Loss: 0.350751
Training set: Average loss: 0.291783
Training set: Average accuracy: 87.93%
Validation set: Average loss: 1.040392, Accuracy: 796/1050 (76%)

Epoch: 96
Training set [0/6430 (0%)] Loss: 0.253984
Training set [2560/6430 (38%)] Loss: 0.244779
Training set [5120/6430 (77%)] Loss: 0.359454
Training set: Average loss: 0.267550
Training set: Average accuracy: 89.00%
Validation set: Average loss: 0.658403, Accuracy: 856/1050 (82%)

Epoch: 97
Training set [0/6430 (0%)] Loss: 0.264186
Training set [2560/6430 (38%)] Loss: 0.313403
Training set [5120/6430 (77%)] Loss: 0.313159
Training set: Average loss: 0.269467
Training set: Average accuracy: 89.47%
Validation set: Average loss: 0.769822, Accuracy: 846/1050 (81%)

Epoch: 98
Training set [0/6430 (0%)] Loss: 0.229663
Training set [2560/6430 (38%)] Loss: 0.233736
Training set [5120/6430 (77%)] Loss: 0.254328
Training set: Average loss: 0.277803
Training set: Average accuracy: 88.46%
Validation set: Average loss: 0.740165, Accuracy: 844/1050 (80%)

Epoch: 99
Training set [0/6430 (0%)] Loss: 0.254565
Training set [2560/6430 (38%)] Loss: 0.303902
Training set [5120/6430 (77%)] Loss: 0.238805
Training set: Average loss: 0.242155
Training set: Average accuracy: 90.16%
Validation set: Average loss: 0.951851, Accuracy: 825/1050 (79%)

Epoch: 100
Training set [0/6430 (0%)] Loss: 0.231887
Training set [2560/6430 (38%)] Loss: 0.277652
Training set [5120/6430 (77%)] Loss: 0.252521
Training set: Average loss: 0.271786
Training set: Average accuracy: 89.50%
Validation set: Average loss: 1.303374, Accuracy: 763/1050 (73%)

Epoch: 101
Training set [0/6430 (0%)] Loss: 0.280676
Training set [2560/6430 (38%)] Loss: 0.424232
Training set [5120/6430 (77%)] Loss: 0.365850
Training set: Average loss: 0.391473
Training set: Average accuracy: 84.40%
Validation set: Average loss: 0.846694, Accuracy: 827/1050 (79%)

Epoch: 102
Training set [0/6430 (0%)] Loss: 0.238756
Training set [2560/6430 (38%)] Loss: 0.326949
Training set [5120/6430 (77%)] Loss: 0.254885
Training set: Average loss: 0.317281
Training set: Average accuracy: 86.80%
Validation set: Average loss: 0.705233, Accuracy: 834/1050 (79%)

Epoch: 103
Training set [0/6430 (0%)] Loss: 0.269110
Training set [2560/6430 (38%)] Loss: 0.326129
Training set [5120/6430 (77%)] Loss: 0.227646
Training set: Average loss: 0.290588
Training set: Average accuracy: 88.16%
Validation set: Average loss: 0.771230, Accuracy: 846/1050 (81%)

Epoch: 104
Training set [0/6430 (0%)] Loss: 0.257529
Training set [2560/6430 (38%)] Loss: 0.265360
Training set [5120/6430 (77%)] Loss: 0.255317
Training set: Average loss: 0.281252
Training set: Average accuracy: 88.07%
Validation set: Average loss: 0.984642, Accuracy: 801/1050 (76%)

Epoch: 105
Training set [0/6430 (0%)] Loss: 0.248748
Training set [2560/6430 (38%)] Loss: 0.232680
Training set [5120/6430 (77%)] Loss: 0.304270
Training set: Average loss: 0.274423
Training set: Average accuracy: 89.39%
Validation set: Average loss: 0.710186, Accuracy: 835/1050 (80%)

Epoch: 106
Training set [0/6430 (0%)] Loss: 0.258059
Training set [2560/6430 (38%)] Loss: 0.352251
Training set [5120/6430 (77%)] Loss: 0.214155
Training set: Average loss: 0.291598
Training set: Average accuracy: 88.62%
Validation set: Average loss: 0.848016, Accuracy: 811/1050 (77%)

Epoch: 107
Training set [0/6430 (0%)] Loss: 0.282539
Training set [2560/6430 (38%)] Loss: 0.262375
Training set [5120/6430 (77%)] Loss: 0.249394
Training set: Average loss: 0.267423
Training set: Average accuracy: 89.27%
Validation set: Average loss: 0.675379, Accuracy: 848/1050 (81%)

Epoch: 108
Training set [0/6430 (0%)] Loss: 0.237352
Training set [2560/6430 (38%)] Loss: 0.254234
Training set [5120/6430 (77%)] Loss: 0.395396
Training set: Average loss: 0.257738
Training set: Average accuracy: 89.13%
Validation set: Average loss: 0.943159, Accuracy: 809/1050 (77%)

Epoch: 109
Training set [0/6430 (0%)] Loss: 0.258660
Training set [2560/6430 (38%)] Loss: 0.282355
Training set [5120/6430 (77%)] Loss: 0.241627
Training set: Average loss: 0.258447
Training set: Average accuracy: 89.72%
Validation set: Average loss: 2.184100, Accuracy: 673/1050 (64%)

Early stopping: no improvement for 10 epochs
ImprovedNetLite
training_loss -- validation_loss
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109]
[2.504511677301847, 1.7834739501659687, 1.6919655616466815, 1.5718529270245478, 1.4950470878527715, 1.427458717272832, 1.332310323531811, 1.2626039523344774, 1.1978247096905341, 1.1492258998063893, 1.1430723346196687, 1.0586012166280012, 1.0183228323092828, 0.9898330660966727, 0.9291143165184901, 0.93073243361253, 0.8594529697528253, 0.8518611307327564, 0.8305600927426264, 0.8108742970686692, 0.7792612107900473, 0.7550112215372232, 0.7422184611742313, 0.7151047724943894, 0.65897336602211, 0.681544154882431, 0.6599064927834731, 0.6598383784294128, 0.6357068591392957, 0.6168075708242563, 0.5776172417860764, 0.5816958294464991, 0.5641546616187463, 0.5689457712265161, 0.5568039016081736, 0.5469276205851481, 0.5364714574355346, 0.5602585994280301, 0.5064878417895391, 0.553893200480021, 0.5518614271512399, 0.49863307292644793, 0.5119734165760187, 0.5015427252421012, 0.48584677508244145, 0.4767932112400348, 0.4755746997319735, 0.49810884262506777, 0.4496607677294658, 0.4645686470545255, 0.4609127308313663, 0.45434196637226987, 0.42590225430635303, 0.39308675206624544, 0.4236700471777182, 0.4164427094734632, 0.4254954606294632, 0.45338461834650773, 0.44056733411092025, 0.4067686853500513, 0.4173737340248548, 0.39145704874625575, 0.37892175293885744, 0.365410450559396, 0.37975607697780317, 0.39297021524264264, 0.3653519107745244, 0.37762249547701615, 0.3533594631231748, 0.3754335366762601, 0.3398811255510037, 0.35181862574357253, 0.33264335646079135, 0.34324060953580415, 0.34501095975820834, 0.3363575144455983, 0.3162151202559471, 0.35908032609866214, 0.34407356725289273, 0.3027210911879173, 0.32985429580395037, 0.3240825797502811, 0.341177778175244, 0.3192144471865434, 0.31980603761397874, 0.2920539453625679, 0.29496279244239515, 0.30337087695415205, 0.2896351252610867, 0.27242621836753994, 0.27324558336001176, 0.2711704144111046, 0.2871580066589209, 0.2895291418983386, 0.2805000228377489, 0.2917831087341675, 0.26755044150810975, 0.26946723747711915, 0.2778029745587936, 0.2421551879781943, 0.27178550511598587, 0.39147346867964816, 0.31728071375535083, 0.29058758455973405, 0.281252017387977, 0.2744230175247559, 0.2915975875579394, 0.2674229540503942, 0.2577376612103902, 0.2584474550989958]
[1.9257664442062379, 1.7650216102600098, 1.5954408645629883, 1.4969621419906616, 1.3952083826065063, 1.3762911081314086, 1.2560252666473388, 1.2854730367660523, 1.1952856659889222, 1.2056733131408692, 1.237314558029175, 1.4569892883300781, 1.084504771232605, 1.4255057573318481, 1.0303647875785829, 0.9282228708267212, 1.0617406964302063, 0.9980656385421753, 1.0795512676239014, 0.863869595527649, 1.0118696451187135, 0.9042335748672485, 0.8700340151786804, 0.7618404448032379, 0.8035013794898986, 0.7260789632797241, 1.5501166820526122, 0.7863170385360718, 1.020640343427658, 0.780793821811676, 0.8907387673854827, 0.768735921382904, 0.7576922297477722, 0.6941383332014084, 1.0156265497207642, 0.8102981656789779, 0.7880361914634705, 0.6613498836755752, 0.8679512083530426, 1.249503254890442, 1.02336505651474, 1.9396202087402343, 1.0027486443519593, 0.7000630319118499, 0.7145944833755493, 0.901263639330864, 0.8662893533706665, 0.7678492218255997, 0.7599503591656684, 0.8398493885993957, 0.6601063698530197, 0.7736301079392434, 0.6621836371719837, 0.87809838950634, 0.7749842345714569, 0.8796089999377728, 0.6765733018517495, 1.0518300637602807, 0.9356278002262115, 0.7030586421489715, 0.6413278087973595, 0.8522928982973099, 0.725998830795288, 0.6929346024990082, 0.763703478872776, 0.7436541795730591, 1.1967025339603423, 0.6641779460012913, 0.7367419391870499, 0.8039163403213024, 0.8565215245820582, 0.6611605554819107, 0.7409050315618515, 0.8175235524773597, 0.7432352617383003, 0.8144306659698486, 0.7701527446508407, 0.9841143131256104, 0.6643425635993481, 0.7793136566877366, 0.9248644351959229, 1.352837324142456, 0.6844067186117172, 0.8596727013587951, 0.9140135698020458, 0.8036013171076775, 0.8335067003965377, 0.9093209862709045, 0.9240870356559754, 0.9527548551559448, 0.8670341968536377, 0.8487413734197616, 1.0001929849386215, 1.7482229709625243, 1.0515154331922532, 1.0403919100761414, 0.6584026962518692, 0.7698224253952504, 0.7401646941900253, 0.9518509149551392, 1.3033741593360901, 0.8466944217681884, 0.7052333123981953, 0.7712297409772872, 0.9846420824527741, 0.7101861938834191, 0.8480161517858505, 0.6753785759210587, 0.9431586503982544, 2.1841004490852356]
ImprovedNetLite
training_accuracy -- validation_accuracy
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109]
[21.39968895800933, 26.811819595645414, 32.737169517884915, 38.13374805598756, 41.726283048211506, 44.292379471228614, 48.70917573872473, 50.295489891135304, 53.483670295489894, 55.78538102643857, 56.28304821150855, 58.80248833592535, 59.37791601866252, 61.850699844479, 63.919129082426124, 62.8149300155521, 66.70295489891136, 66.53188180404355, 67.88491446345256, 67.86936236391912, 68.89580093312597, 70.0, 70.23328149300156, 71.16640746500778, 73.60808709175738, 72.93934681181959, 74.1213063763608, 72.93934681181959, 75.17884914463453, 75.30326594090202, 76.65629860031105, 76.54743390357699, 76.4696734059098, 76.81181959564542, 76.79626749611198, 78.05598755832037, 78.66251944012441, 77.07620528771385, 80.01555209953344, 77.4339035769829, 76.90513219284604, 79.81337480559876, 79.50233281493001, 79.19129082426127, 80.04665629860031, 80.1244167962675, 80.79315707620529, 79.48678071539658, 81.39968895800934, 81.32192846034215, 80.94867807153966, 81.72628304821151, 81.83514774494557, 83.15707620528771, 82.28615863141525, 82.45723172628306, 82.92379471228615, 81.32192846034215, 82.83048211508553, 82.9860031104199, 82.73716951788491, 83.43701399688958, 83.91912908242612, 84.94556765163297, 84.32348367029549, 83.25038880248833, 84.26127527216174, 84.33903576982893, 85.2099533437014, 84.51010886469673, 85.9253499222395, 85.31881804043546, 86.14307931570762, 85.67651632970451, 85.58320373250389, 85.69206842923795, 86.67185069984448, 85.94090202177294, 85.56765163297045, 87.35614307931571, 86.40746500777605, 86.98289269051322, 86.25194401244168, 86.85847589424573, 86.81181959564542, 88.24261275272161, 87.88491446345256, 87.34059097978228, 87.68273716951788, 88.80248833592535, 88.60031104199066, 89.37791601866252, 88.52255054432348, 88.22706065318818, 89.09797822706065, 87.93157076205287, 89.00466562986003, 89.47122861586314, 88.46034214618973, 90.15552099533437, 89.50233281493001, 84.40124416796267, 86.79626749611198, 88.16485225505443, 88.0715396578538, 89.39346811819595, 88.6158631415241, 89.26905132192846, 89.12908242612752, 89.72006220839813]
[20.476190476190474, 31.61904761904762, 40.666666666666664, 44.285714285714285, 50.57142857142857, 49.904761904761905, 57.23809523809524, 54.76190476190476, 57.333333333333336, 57.333333333333336, 56.285714285714285, 50.285714285714285, 62.57142857142857, 53.04761904761905, 64.76190476190476, 67.33333333333333, 65.04761904761905, 64.28571428571429, 63.23809523809524, 72.57142857142857, 66.28571428571429, 70.85714285714286, 68.0, 72.47619047619048, 71.52380952380952, 75.04761904761905, 57.714285714285715, 71.61904761904762, 68.85714285714286, 72.76190476190476, 71.23809523809524, 73.04761904761905, 73.23809523809524, 74.28571428571429, 65.9047619047619, 71.33333333333333, 75.33333333333333, 76.19047619047619, 71.04761904761905, 66.85714285714286, 67.04761904761905, 55.142857142857146, 70.19047619047619, 74.66666666666667, 75.71428571428571, 73.23809523809524, 74.0952380952381, 76.85714285714286, 77.04761904761905, 74.19047619047619, 77.14285714285714, 76.47619047619048, 78.28571428571429, 73.04761904761905, 78.19047619047619, 76.0, 78.85714285714286, 69.23809523809524, 72.57142857142857, 79.14285714285714, 79.33333333333333, 75.80952380952381, 76.66666666666667, 77.9047619047619, 76.38095238095238, 76.38095238095238, 71.52380952380952, 78.47619047619048, 79.14285714285714, 78.95238095238095, 74.85714285714286, 79.61904761904762, 79.9047619047619, 78.95238095238095, 79.9047619047619, 77.80952380952381, 79.14285714285714, 74.66666666666667, 79.42857142857143, 79.33333333333333, 78.19047619047619, 69.42857142857143, 77.61904761904762, 75.42857142857143, 76.85714285714286, 78.28571428571429, 79.33333333333333, 76.28571428571429, 78.38095238095238, 76.47619047619048, 78.76190476190476, 78.0952380952381, 73.71428571428571, 67.80952380952381, 73.80952380952381, 75.80952380952381, 81.52380952380952, 80.57142857142857, 80.38095238095238, 78.57142857142857, 72.66666666666667, 78.76190476190476, 79.42857142857143, 80.57142857142857, 76.28571428571429, 79.52380952380952, 77.23809523809524, 80.76190476190476, 77.04761904761905, 64.0952380952381]
model saved as model_store_256/cnn_car_ImprovedNetLite.pt
Getting predictions from test set...
ImprovedNetLite
[[105   0   0  45   0   0   0]
 [ 42  43   6  29   4   3  23]
 [  5   0 105  38   1   1   0]
 [  7   0   0 143   0   0   0]
 [ 26   0   0  24  91   1   8]
 [ 22   0   2  38   0  85   3]
 [  7   1   7  33   1   0 101]]
